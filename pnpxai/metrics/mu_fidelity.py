from typing import Callable, Optional

import torch
from torch import nn
from torchvision import transforms
from scipy.stats import spearmanr

from .base import Metric


class MuFidelity(Metric):
    def __init__(
        self,
        model: nn.Module,
        n_perturb: int = 150,
        noise_scale: float = 0.2,
        batch_size: int = 32,
        grid_size: int = 9,
        baseline: float = 0.,
    ):
        super().__init__(model)
        self.n_perturb = n_perturb
        self.noise_scale = noise_scale
        self.batch_size = batch_size
        self.grid_size = grid_size
        self.baseline = baseline
    
    def evaluate(
        self,
        inputs: torch.Tensor,
        targets: torch.Tensor,
        attributions: torch.Tensor,
        explain_func: Optional[Callable[[torch.Tensor, torch.Tensor], torch.Tensor]],
    ) -> torch.Tensor:
        attributions = attributions.to(self.device)

        outputs = self.model(inputs)
        n_classes = outputs.shape[-1]
        predictions = (
            outputs * torch.eye(n_classes).to(self.device)[targets]
        ).sum(dim=-1).detach()

        # input, target, attr, pred
        evaluations = []
        zipped = zip(inputs, targets, attributions, predictions)
        for input, target, attr, pred in zipped:
            repeated = torch.stack([input]*self.n_perturb)
            # Add Gaussian random noise
            std, mean = torch.std_mean(repeated)
            noise = torch.randn_like(repeated).to(self.device) * std + mean
            perturbed = self.noise_scale * noise + repeated
            perturbed = torch.minimum(repeated, perturbed)
            perturbed = torch.maximum(repeated-1, perturbed)

            # prepare the random masks that will designate the modified subset (S in original equation)
            subset_size = int(self.grid_size ** 2 * self.noise_scale)
            subset_mask = torch.randn(
                (self.n_perturb, self.grid_size ** 2)).to(self.device)
            subset_mask = torch.argsort(subset_mask, dim=-1) > subset_size
            subset_mask = torch.reshape(subset_mask.type(
                torch.float32), (self.n_perturb, 1, self.grid_size, self.grid_size))
            subset_mask = transforms.Resize(
                perturbed.shape[-2:],
                transforms.InterpolationMode("nearest")
            ).forward(subset_mask)

            # Use the masks to set the selected subsets to baseline state
            masked = perturbed * subset_mask + \
                (1.0 - subset_mask) * self.baseline
            
            masked_output = _forward_batch(self.model, masked, self.batch_size)
            pred_diff = pred - masked_output[:, target]

            masked_attr = (attr * (1.0 - subset_mask)).sum(dim=tuple(range(1, subset_mask.ndim)))
            corr, _ = spearmanr(
                pred_diff.cpu().detach().numpy(),
                masked_attr.cpu().detach().numpy(),
            )
            evaluations.append(corr)
        return torch.tensor(evaluations)


def _forward_batch(model, inputs, batch_size) -> torch.Tensor:
    training_mode = model.training
    model.eval()
    outputs = []
    indices = list(range(len(inputs)))
    while indices:
        curr_indices, indices = indices[:batch_size], indices[batch_size:]
        outputs.append(model(inputs[curr_indices]))
    model.training = training_mode
    return torch.cat(outputs).detach()

# def pnpxai_mu_fidelity(
#         model: nn.Module,
#         inputs: torch.Tensor,
#         targets: torch.Tensor,
#         attributions: torch.Tensor,
#         n_perturbations: int=150,
#         noise_scale: float=0.2,
#         batch_size: int=32,
#         grid_size: int=9,
#         baseline: float=0.,
#         **kwargs
#     ) -> torch.Tensor:
#     """
#     Computes the MuFidelity metric for attributions.
    
#     Given a `model` and `inputs`, mufidelity of `model` to an explainer at `inputs` is calculated by 
#     a correlation between difference of predictions and attributions of maked inputs,
#     ``evaluation = corr(pred_diff, masked_attr)``.
    
#     The masked inputs are generated by masking `subset_mask` to noised `inputs`,
#     ``masked = perturbed * subset_mask + (1.0 - subset_mask) * baseline``
    
#     Args:
#         model (Model): The model to evaluate.
#         inputs (torch.Tensor): The input data (N x C x H x W).
#         targets (torch.Tensor): The target labels for the inputs (N x 1).
#         attributions (torch.Tensor): The attributions of the inputs.
#         n_perturbations (int): Number of perturbations to generate.
#         noise_scale (int): Scale factor for Gaussian random noise.
#         batch_size (int): Batch size for model evaluation.
#         grid_size (int): Size of the grid for creating subsets.
#         baseline (Union[float, torch.Tensor]): Baseline value for masked subsets.
#         **kwargs: Additional kwargs to compute metric in an evaluator. Not required for single usage.
        
#     Reference:
#         U. Bhatt, A. Weller, and J. M. F. Moura. Evaluating and aggregating feature-based model attributions. In Proceedings of the IJCAI (2020).
#     """
#     device = next(model.parameters()).device
#     inputs = inputs.to(device)
#     targets = targets.to(device)
#     attributions = attributions.to(device)

#     # get predictions
#     outputs = model(inputs)
#     _, n_classes = outputs.shape
#     preds = (outputs * torch.eye(n_classes).to(device)[targets]).sum(dim=-1).detach()

#     # input, target, attr, pred
#     evaluations = []
#     for input, target, attr, pred in zip(
#         inputs, targets, attributions, preds,
#     ):
#         repeated = torch.stack([input]*n_perturbations)
#         # Add Gaussian random noise
#         std, mean = torch.std_mean(repeated)
#         noise = torch.randn_like(repeated).to(device) * std + mean
#         perturbed = noise_scale * noise + repeated
#         perturbed = torch.minimum(repeated, perturbed)
#         perturbed = torch.maximum(repeated-1, perturbed)

#         # prepare the random masks that will designate the modified subset (S in original equation)
#         subset_size = int(grid_size ** 2 * noise_scale)
#         subset_mask = torch.randn(
#             (n_perturbations, grid_size ** 2)).to(device)
#         subset_mask = torch.argsort(subset_mask, dim=-1) > subset_size
#         subset_mask = torch.reshape(subset_mask.type(
#             torch.float32), (n_perturbations, 1, grid_size, grid_size))
#         subset_mask = transforms.Resize(
#             perturbed.shape[-2:],
#             transforms.InterpolationMode("nearest")
#         ).forward(subset_mask)

#         # Use the masks to set the selected subsets to baseline state
#         masked = perturbed * subset_mask + \
#             (1.0 - subset_mask) * baseline
        
#         masked_output = _forward_batch(model, masked, batch_size)
#         pred_diff = pred - masked_output[:, target]

#         masked_attr = (attr * (1.0 - subset_mask)).sum(dim=tuple(range(1, subset_mask.ndim)))
#         corr, _ = spearmanr(
#             pred_diff.cpu().detach().numpy(),
#             masked_attr.cpu().detach().numpy(),
#         )
#         evaluations.append(corr)
#     return torch.tensor(evaluations)

