{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HPO experiment: Grid Search on LRP-epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gkim/Projects/pnp/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torchvision\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from open_xai import Project\n",
    "from open_xai.explainers import LRPEpsilon\n",
    "\n",
    "\n",
    "# models\n",
    "def get_model(model_name):\n",
    "    weights = torchvision.models.get_model_weights(model_name).DEFAULT\n",
    "    model = torchvision.models.get_model(model_name, weights=weights).eval()\n",
    "    transform = weights.transforms()\n",
    "    return model, transform\n",
    "\n",
    "# input images\n",
    "def get_images(num_images):\n",
    "    IMG_DIR = \"../data/imagenet/images/\"\n",
    "    imgs = torch.stack([\n",
    "        torchvision.io.read_image(os.path.join(IMG_DIR, fnm))\n",
    "        for fnm in os.listdir(IMG_DIR)[:num_images]\n",
    "    ])\n",
    "    return imgs\n",
    "\n",
    "img_to_np = lambda img: img.permute(1,2,0).detach().numpy()\n",
    "\n",
    "# get infd from run\n",
    "def get_infd_from_run(model, run, n_perturb=200, noise_scale=.2, batch_size=32):\n",
    "    t = run.explainer_config.kwargs[\"target\"]\n",
    "    x = run.inputs.detach()\n",
    "    y = model(run.inputs)[:, t].detach()\n",
    "    a = run.outputs[0].detach()\n",
    "    std, mean = torch.std_mean(x)\n",
    "\n",
    "    # def _perturb(x, m, s, ns):\n",
    "    #     x_p = x + ns * torch.normal(mean=m, std=s, size=x.shape)\n",
    "    #     x_p = torch.minimum(x, x_p)\n",
    "    #     x_p = torch.maximum(x-1, x_p)\n",
    "    #     return x_p\n",
    "    # x_p = torch.cat([\n",
    "    #     _perturb(x, mean, std, noise_scale)\n",
    "    #     for _ in range(n_perturb)\n",
    "    # ])\n",
    "\n",
    "    x_p = x.repeat(n_perturb, 1, 1, 1)\n",
    "    noise = torch.normal(mean=mean, std=std, size=x_p.shape)\n",
    "    x_p = x + noise_scale * noise\n",
    "    x_p = torch.minimum(x, x_p)\n",
    "    x_p = torch.maximum(x-1, x_p)\n",
    "\n",
    "    y_p = torch.cat([\n",
    "        model(x_p[i*batch_size:(i+1)*batch_size])[:, t].detach()\n",
    "        for i, _ in enumerate(range(n_perturb)[::batch_size])\n",
    "    ])\n",
    "    y_d = y - y_p\n",
    "\n",
    "    dot_prod = torch.mul(x_p, a).sum(dim=(1,2,3))\n",
    "    mu = torch.ones(n_perturb)\n",
    "    scaling_factor = torch.mean(mu*y_d*dot_prod)/torch.mean(mu*dot_prod*dot_prod)\n",
    "    dot_prod *= scaling_factor\n",
    "    return torch.mean(mu*torch.square(y_d-dot_prod)) / torch.mean(mu)\n",
    "\n",
    "# get sens from run\n",
    "def get_sens_from_run(model, run, epsilon=.2, n_perturb=10):\n",
    "    x = run.inputs.detach()\n",
    "    a = run.outputs[0].detach()\n",
    "    def _perturb(x):\n",
    "        noise = torch.rand(size=x.shape)\n",
    "        noise = noise * epsilon * 2 - epsilon\n",
    "        return x + noise\n",
    "    a_p = torch.cat([\n",
    "        run.explainer.run(\n",
    "            data = _perturb(x),\n",
    "            **run.explainer_config.kwargs\n",
    "        )[0] for _ in range(n_perturb)\n",
    "    ])\n",
    "    lb = torch.tensor(-torch.inf)\n",
    "    sens = torch.linalg.norm(a-a_p) / torch.linalg.norm(a)\n",
    "    return torch.max(lb, sens)\n",
    "\n",
    "# run\n",
    "def implement_by_project_of_model(project_name, model, inputs, grid):\n",
    "    proj = Project(project_name)\n",
    "    for eps in grid:\n",
    "        experiment = proj.explain(LRPEpsilon(model, epsilon=eps))\n",
    "        for input in tqdm(inputs, total=len(inputs)):\n",
    "            x = input.unsqueeze(0)#.detach()\n",
    "            target = model(x).argmax(1).item()\n",
    "            run = experiment.run(x, target=target)\n",
    "            run.explainer_config.epsilon = eps\n",
    "            run.infd = get_infd_from_run(model, run)\n",
    "            run.sens = get_sens_from_run(model, run)\n",
    "    return proj\n",
    "\n",
    "# rearrange result to visualize and tabulate\n",
    "def rearrange_by_input(proj):\n",
    "    rearranged = defaultdict(list)\n",
    "    for experiment in proj.experiments:\n",
    "        for input_idx, run in enumerate(experiment.runs):\n",
    "            rearranged[input_idx].append(dict(\n",
    "                epsilon = run.explainer_config.epsilon,\n",
    "                target = run.explainer_config.kwargs[\"target\"],\n",
    "                outputs = run.outputs[0],\n",
    "                infd = run.infd,\n",
    "                sens = run.sens,\n",
    "            ))\n",
    "    return rearranged\n",
    "\n",
    "# post process for viz\n",
    "def post_process(attr):\n",
    "    attr = torch.nn.functional.relu(attr)\n",
    "    postprocessed = attr.permute((1, 2, 0)).sum(dim=-1)\n",
    "    attr_max = torch.max(postprocessed)\n",
    "    attr_min = torch.min(postprocessed)\n",
    "    postprocessed = (postprocessed - attr_min) / (attr_max - attr_min)\n",
    "    return postprocessed.cpu().detach().numpy()\n",
    "\n",
    "# viz\n",
    "def visualize_proj(project, imgs):\n",
    "    rearranged = rearrange_by_input(project)\n",
    "    ncols = 1 + len(list(rearranged.values())[0])\n",
    "    nrows = len(rearranged.keys())\n",
    "    fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(4*ncols, 4*nrows), gridspec_kw={\"width_ratios\": [1]*ncols})\n",
    "\n",
    "    for input_idx, runinfos in rearranged.items():\n",
    "        axes[input_idx, 0].imshow(img_to_np(imgs[input_idx]))\n",
    "        for c_1, runinfo in enumerate(runinfos):\n",
    "            if input_idx == 0:\n",
    "                axes[input_idx, c_1+1].set_title(f\"lrp-e={runinfo['epsilon']}\")\n",
    "            axes[input_idx, c_1+1].set_xlabel(\n",
    "                f\"infd: {runinfo['infd'].item():.4f} / sens: {runinfo['sens'].item():.4f}\",\n",
    "                fontsize=15,\n",
    "            )\n",
    "            axes[input_idx, c_1+1].imshow(post_process(runinfo[\"outputs\"].squeeze()), cmap=\"gray\")\n",
    "\n",
    "    for ax in axes.flatten():\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "\n",
    "# summary table\n",
    "def tabulate_proj(project):\n",
    "    rearranged = rearrange_by_input(project)\n",
    "    summary = []\n",
    "    for input_idx, runinfos in rearranged.items():\n",
    "        for runinfo in runinfos:\n",
    "            summary.append({\n",
    "                \"input_idx\": input_idx,\n",
    "                \"epsilon\": runinfo[\"epsilon\"],\n",
    "                \"infd\": runinfo[\"infd\"].item(),\n",
    "                \"sens\": runinfo[\"sens\"].item(),\n",
    "            })\n",
    "    return pd.DataFrame.from_records(summary).set_index([\"input_idx\", \"epsilon\"]).groupby(\"epsilon\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_result(model_name, num_images, grid=[1e-2, .25, .5, 1.]):\n",
    "    model, transform = get_model(model_name)\n",
    "    imgs = get_images(num_images)\n",
    "    inputs = transform(imgs)\n",
    "    proj_name = f\"hpo_lrpe_{model_name}\"\n",
    "    proj = implement_by_project_of_model(proj_name, model, inputs, grid)\n",
    "    visualize_proj(proj, imgs)\n",
    "    return tabulate_proj(proj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(action=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [01:56<00:00, 29.22s/it]\n",
      " 25%|██▌       | 1/4 [00:31<01:35, 31.79s/it]"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "get_result(\"vgg16\", 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_result(\"resnet18\", 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_result(\"vit_b_16\", 4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
