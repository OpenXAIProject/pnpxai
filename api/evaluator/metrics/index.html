
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
        <link rel="canonical" href="https://openxaiproject.github.io/pnpxai/api/evaluator/metrics/">
      
      
        <link rel="prev" href="../../core/detector/">
      
      
        <link rel="next" href="../optimizer/">
      
      
      <link rel="icon" href="../../../assets/favicon.ico">
      <meta name="generator" content="mkdocs-1.6.0, mkdocs-material-9.5.33">
    
    
      
        <title>Metrics - PnP XAI Docs</title>
      
    
    
      <link rel="stylesheet" href="../../../assets/stylesheets/main.3cba04c6.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../../assets/_mkdocstrings.css">
    
    <script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    <body dir="ltr">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#pnpxai.evaluator.metrics.complexity" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../.." title="PnP XAI Docs" class="md-header__button md-logo" aria-label="PnP XAI Docs" data-md-component="logo">
      
  <img src="../../../assets/logo.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            PnP XAI Docs
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Metrics
            
          </span>
        </div>
      </div>
    </div>
    
    
      <script>var media,input,key,value,palette=__md_get("__palette");if(palette&&palette.color){"(prefers-color-scheme)"===palette.color.media&&(media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']"),palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent"));for([key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../.." title="PnP XAI Docs" class="md-nav__button md-logo" aria-label="PnP XAI Docs" data-md-component="logo">
      
  <img src="../../../assets/logo.png" alt="logo">

    </a>
    PnP XAI Docs
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../.." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Home
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" checked>
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    API
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            API
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2_1" >
        
          
          <label class="md-nav__link" for="__nav_2_1" id="__nav_2_1_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Core
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_1">
            <span class="md-nav__icon md-icon"></span>
            Core
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../core/experiment/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Experiment
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../core/auto_explanation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Auto Explanation
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../core/modality/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Modality
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../core/recommender/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Recommender
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../core/detector/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Detector
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
    
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_2" checked>
        
          
          <label class="md-nav__link" for="__nav_2_2" id="__nav_2_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Evaluator
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_2_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_2_2">
            <span class="md-nav__icon md-icon"></span>
            Evaluator
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    Metrics
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    Metrics
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#pnpxai.evaluator.metrics.complexity" class="md-nav__link">
    <span class="md-ellipsis">
      complexity
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#pnpxai.evaluator.metrics.complexity.Complexity" class="md-nav__link">
    <span class="md-ellipsis">
      Complexity
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Complexity">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#pnpxai.evaluator.metrics.complexity.Complexity.evaluate" class="md-nav__link">
    <span class="md-ellipsis">
      evaluate
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#pnpxai.evaluator.metrics.mu_fidelity" class="md-nav__link">
    <span class="md-ellipsis">
      mu_fidelity
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#pnpxai.evaluator.metrics.mu_fidelity.MuFidelity" class="md-nav__link">
    <span class="md-ellipsis">
      MuFidelity
    </span>
  </a>
  
    <nav class="md-nav" aria-label="MuFidelity">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#pnpxai.evaluator.metrics.mu_fidelity.MuFidelity.evaluate" class="md-nav__link">
    <span class="md-ellipsis">
      evaluate
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#pnpxai.evaluator.metrics.sensitivity" class="md-nav__link">
    <span class="md-ellipsis">
      sensitivity
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#pnpxai.evaluator.metrics.sensitivity.Sensitivity" class="md-nav__link">
    <span class="md-ellipsis">
      Sensitivity
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Sensitivity">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#pnpxai.evaluator.metrics.sensitivity.Sensitivity.evaluate" class="md-nav__link">
    <span class="md-ellipsis">
      evaluate
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#pnpxai.evaluator.metrics.pixel_flipping" class="md-nav__link">
    <span class="md-ellipsis">
      pixel_flipping
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#pnpxai.evaluator.metrics.pixel_flipping.AbPC" class="md-nav__link">
    <span class="md-ellipsis">
      AbPC
    </span>
  </a>
  
    <nav class="md-nav" aria-label="AbPC">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#pnpxai.evaluator.metrics.pixel_flipping.AbPC.evaluate" class="md-nav__link">
    <span class="md-ellipsis">
      evaluate
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#pnpxai.evaluator.metrics.pixel_flipping.LeRF" class="md-nav__link">
    <span class="md-ellipsis">
      LeRF
    </span>
  </a>
  
    <nav class="md-nav" aria-label="LeRF">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#pnpxai.evaluator.metrics.pixel_flipping.LeRF.evaluate" class="md-nav__link">
    <span class="md-ellipsis">
      evaluate
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#pnpxai.evaluator.metrics.pixel_flipping.MoRF" class="md-nav__link">
    <span class="md-ellipsis">
      MoRF
    </span>
  </a>
  
    <nav class="md-nav" aria-label="MoRF">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#pnpxai.evaluator.metrics.pixel_flipping.MoRF.evaluate" class="md-nav__link">
    <span class="md-ellipsis">
      evaluate
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#pnpxai.evaluator.metrics.pixel_flipping.PixelFlipping" class="md-nav__link">
    <span class="md-ellipsis">
      PixelFlipping
    </span>
  </a>
  
    <nav class="md-nav" aria-label="PixelFlipping">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#pnpxai.evaluator.metrics.pixel_flipping.PixelFlipping.evaluate" class="md-nav__link">
    <span class="md-ellipsis">
      evaluate
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../optimizer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Optimizer
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../detector/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Detector
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../recommender/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Recommender
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../evaluator/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Evaluator
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../optimizer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Optimizer
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#pnpxai.evaluator.metrics.complexity" class="md-nav__link">
    <span class="md-ellipsis">
      complexity
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#pnpxai.evaluator.metrics.complexity.Complexity" class="md-nav__link">
    <span class="md-ellipsis">
      Complexity
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Complexity">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#pnpxai.evaluator.metrics.complexity.Complexity.evaluate" class="md-nav__link">
    <span class="md-ellipsis">
      evaluate
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#pnpxai.evaluator.metrics.mu_fidelity" class="md-nav__link">
    <span class="md-ellipsis">
      mu_fidelity
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#pnpxai.evaluator.metrics.mu_fidelity.MuFidelity" class="md-nav__link">
    <span class="md-ellipsis">
      MuFidelity
    </span>
  </a>
  
    <nav class="md-nav" aria-label="MuFidelity">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#pnpxai.evaluator.metrics.mu_fidelity.MuFidelity.evaluate" class="md-nav__link">
    <span class="md-ellipsis">
      evaluate
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#pnpxai.evaluator.metrics.sensitivity" class="md-nav__link">
    <span class="md-ellipsis">
      sensitivity
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#pnpxai.evaluator.metrics.sensitivity.Sensitivity" class="md-nav__link">
    <span class="md-ellipsis">
      Sensitivity
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Sensitivity">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#pnpxai.evaluator.metrics.sensitivity.Sensitivity.evaluate" class="md-nav__link">
    <span class="md-ellipsis">
      evaluate
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#pnpxai.evaluator.metrics.pixel_flipping" class="md-nav__link">
    <span class="md-ellipsis">
      pixel_flipping
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#pnpxai.evaluator.metrics.pixel_flipping.AbPC" class="md-nav__link">
    <span class="md-ellipsis">
      AbPC
    </span>
  </a>
  
    <nav class="md-nav" aria-label="AbPC">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#pnpxai.evaluator.metrics.pixel_flipping.AbPC.evaluate" class="md-nav__link">
    <span class="md-ellipsis">
      evaluate
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#pnpxai.evaluator.metrics.pixel_flipping.LeRF" class="md-nav__link">
    <span class="md-ellipsis">
      LeRF
    </span>
  </a>
  
    <nav class="md-nav" aria-label="LeRF">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#pnpxai.evaluator.metrics.pixel_flipping.LeRF.evaluate" class="md-nav__link">
    <span class="md-ellipsis">
      evaluate
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#pnpxai.evaluator.metrics.pixel_flipping.MoRF" class="md-nav__link">
    <span class="md-ellipsis">
      MoRF
    </span>
  </a>
  
    <nav class="md-nav" aria-label="MoRF">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#pnpxai.evaluator.metrics.pixel_flipping.MoRF.evaluate" class="md-nav__link">
    <span class="md-ellipsis">
      evaluate
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#pnpxai.evaluator.metrics.pixel_flipping.PixelFlipping" class="md-nav__link">
    <span class="md-ellipsis">
      PixelFlipping
    </span>
  </a>
  
    <nav class="md-nav" aria-label="PixelFlipping">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#pnpxai.evaluator.metrics.pixel_flipping.PixelFlipping.evaluate" class="md-nav__link">
    <span class="md-ellipsis">
      evaluate
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


  <h1>Metrics</h1>

<div class="doc doc-object doc-module">



<a id="pnpxai.evaluator.metrics.complexity"></a>
    <div class="doc doc-contents first">



  <div class="doc doc-children">








<div class="doc doc-object doc-class">



<h2 id="pnpxai.evaluator.metrics.complexity.Complexity" class="doc doc-heading">
            <code>Complexity</code>


</h2>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="pnpxai.evaluator.metrics.base.Metric">Metric</span></code></p>


      <p>Computes the complexity of attributions.</p>
<p>Given <code>attributions</code>, calculates a fractional contribution distribution <code>prob_mass</code>,
<code>prob_mass[i] = hist[i] / sum(hist)</code>. where <code>hist[i] = histogram(attributions[i])</code>.</p>
<p>The complexity is defined by the entropy,
<code>evaluation = -sum(hist * ln(hist))</code></p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>model</code></td>
            <td>
                  <code><span title="pnpxai.core._types.Model">Model</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The model used for evaluation</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>explainer</code></td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="pnpxai.explainers.base.Explainer">Explainer</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The explainer used for evaluation.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>n_bins</code></td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The number of bins for histogram computation.</p>
              </div>
            </td>
            <td>
                  <code>10</code>
            </td>
          </tr>
      </tbody>
    </table>


<details class="reference" open>
  <summary>Reference</summary>
  <p>U. Bhatt, A. Weller, and J. M. F. Moura. Evaluating and aggregating feature-based model attributions. In Proceedings of the IJCAI (2020).</p>
</details>
              <details class="quote">
                <summary>Source code in <code>pnpxai/evaluator/metrics/complexity.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">Complexity</span><span class="p">(</span><span class="n">Metric</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Computes the complexity of attributions.</span>

<span class="sd">    Given `attributions`, calculates a fractional contribution distribution `prob_mass`,</span>
<span class="sd">    ``prob_mass[i] = hist[i] / sum(hist)``. where ``hist[i] = histogram(attributions[i])``.</span>

<span class="sd">    The complexity is defined by the entropy,</span>
<span class="sd">    ``evaluation = -sum(hist * ln(hist))``</span>


<span class="sd">    Args:</span>
<span class="sd">        model (Model): The model used for evaluation</span>
<span class="sd">        explainer (Optional[Explainer]): The explainer used for evaluation.</span>
<span class="sd">        n_bins (int): The number of bins for histogram computation.</span>

<span class="sd">    Reference:</span>
<span class="sd">        U. Bhatt, A. Weller, and J. M. F. Moura. Evaluating and aggregating feature-based model attributions. In Proceedings of the IJCAI (2020).</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">model</span><span class="p">:</span> <span class="n">Model</span><span class="p">,</span>
        <span class="n">explainer</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Explainer</span><span class="p">]</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">n_bins</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">explainer</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_bins</span> <span class="o">=</span> <span class="n">n_bins</span>

    <span class="k">def</span> <span class="nf">evaluate</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">inputs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">targets</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">attributions</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Evaluate the explainer&#39;s complexity based on their probability masses.</span>

<span class="sd">        Args:</span>
<span class="sd">            inputs (Optional[Tensor]): The input tensors to the model.</span>
<span class="sd">            targets (Optional[Tensor]): The target labels for the inputs.</span>
<span class="sd">            attributions (Optional[Tensor]): The attributions for the inputs.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Tensor: A tensor of the complexity evaluations.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="n">attributions</span><span class="o">.</span><span class="n">ndim</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="s2">&quot;Must have 2D or 3D attributions&quot;</span>
        <span class="k">if</span> <span class="n">attributions</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">4</span><span class="p">:</span>
            <span class="n">attributions</span> <span class="o">=</span> <span class="n">rgb_to_grayscale</span><span class="p">(</span><span class="n">attributions</span><span class="p">)</span>
        <span class="n">evaluations</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">attr</span> <span class="ow">in</span> <span class="n">attributions</span><span class="p">:</span>
            <span class="n">hist</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">histogram</span><span class="p">(</span><span class="n">attr</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">(),</span> <span class="n">bins</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_bins</span><span class="p">)</span>
            <span class="n">prob_mass</span> <span class="o">=</span> <span class="n">hist</span> <span class="o">/</span> <span class="n">hist</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
            <span class="n">evaluations</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">entropy</span><span class="p">(</span><span class="n">prob_mass</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">evaluations</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h3 id="pnpxai.evaluator.metrics.complexity.Complexity.evaluate" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">evaluate</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">targets</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">attributions</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

      <p>Evaluate the explainer's complexity based on their probability masses.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>inputs</code></td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[Tensor]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The input tensors to the model.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>targets</code></td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[Tensor]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The target labels for the inputs.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>attributions</code></td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[Tensor]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The attributions for the inputs.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>Tensor</code></td>            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>A tensor of the complexity evaluations.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>pnpxai/evaluator/metrics/complexity.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">evaluate</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">inputs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">targets</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">attributions</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Evaluate the explainer&#39;s complexity based on their probability masses.</span>

<span class="sd">    Args:</span>
<span class="sd">        inputs (Optional[Tensor]): The input tensors to the model.</span>
<span class="sd">        targets (Optional[Tensor]): The target labels for the inputs.</span>
<span class="sd">        attributions (Optional[Tensor]): The attributions for the inputs.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tensor: A tensor of the complexity evaluations.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">assert</span> <span class="n">attributions</span><span class="o">.</span><span class="n">ndim</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="s2">&quot;Must have 2D or 3D attributions&quot;</span>
    <span class="k">if</span> <span class="n">attributions</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">4</span><span class="p">:</span>
        <span class="n">attributions</span> <span class="o">=</span> <span class="n">rgb_to_grayscale</span><span class="p">(</span><span class="n">attributions</span><span class="p">)</span>
    <span class="n">evaluations</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">attr</span> <span class="ow">in</span> <span class="n">attributions</span><span class="p">:</span>
        <span class="n">hist</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">histogram</span><span class="p">(</span><span class="n">attr</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">(),</span> <span class="n">bins</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_bins</span><span class="p">)</span>
        <span class="n">prob_mass</span> <span class="o">=</span> <span class="n">hist</span> <span class="o">/</span> <span class="n">hist</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
        <span class="n">evaluations</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">entropy</span><span class="p">(</span><span class="n">prob_mass</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">evaluations</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>




  </div>

    </div>

</div>

<div class="doc doc-object doc-module">



<a id="pnpxai.evaluator.metrics.mu_fidelity"></a>
    <div class="doc doc-contents first">



  <div class="doc doc-children">








<div class="doc doc-object doc-class">



<h2 id="pnpxai.evaluator.metrics.mu_fidelity.MuFidelity" class="doc doc-heading">
            <code>MuFidelity</code>


</h2>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="pnpxai.evaluator.metrics.base.Metric">Metric</span></code></p>


      <p>Computes the MuFidelity metric for attributions.</p>
<p>Given a <code>model</code> and <code>inputs</code>, mufidelity of <code>model</code> to an explainer at <code>inputs</code> is calculated by
a correlation between difference of predictions and attributions of maked inputs,
<code>evaluation = corr(pred_diff, masked_attr)</code>.</p>
<p>The masked inputs are generated by masking <code>subset_mask</code> to noised <code>inputs</code>,
<code>masked = perturbed * subset_mask + (1.0 - subset_mask) * baseline</code></p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>model</code></td>
            <td>
                  <code><span title="pnpxai.core._types.Model">Model</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The model to evaluate.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>explainer</code></td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="pnpxai.explainers.base.Explainer">Explainer</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The explainer to evaluate.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>n_perturb</code></td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of perturbations to generate.</p>
              </div>
            </td>
            <td>
                  <code>150</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>noise_scale</code></td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Scale factor for Gaussian random noise.</p>
              </div>
            </td>
            <td>
                  <code>0.2</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>batch_size</code></td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Batch size for model evaluation.</p>
              </div>
            </td>
            <td>
                  <code>32</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>grid_size</code></td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Size of the grid for creating subsets.</p>
              </div>
            </td>
            <td>
                  <code>9</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>baseline</code></td>
            <td>
                  <code>Union[float, <span title="torch.Tensor">Tensor</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Baseline value for masked subsets.</p>
              </div>
            </td>
            <td>
                  <code>0.0</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>mask_agg_dim</code></td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[int]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Dimension to aggregate masks.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>**kwargs</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Additional kwargs to compute metric in an evaluator. Not required for single usage.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


<details class="reference" open>
  <summary>Reference</summary>
  <p>U. Bhatt, A. Weller, and J. M. F. Moura. Evaluating and aggregating feature-based model attributions. In Proceedings of the IJCAI (2020).</p>
</details>
              <details class="quote">
                <summary>Source code in <code>pnpxai/evaluator/metrics/mu_fidelity.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 12</span>
<span class="normal"> 13</span>
<span class="normal"> 14</span>
<span class="normal"> 15</span>
<span class="normal"> 16</span>
<span class="normal"> 17</span>
<span class="normal"> 18</span>
<span class="normal"> 19</span>
<span class="normal"> 20</span>
<span class="normal"> 21</span>
<span class="normal"> 22</span>
<span class="normal"> 23</span>
<span class="normal"> 24</span>
<span class="normal"> 25</span>
<span class="normal"> 26</span>
<span class="normal"> 27</span>
<span class="normal"> 28</span>
<span class="normal"> 29</span>
<span class="normal"> 30</span>
<span class="normal"> 31</span>
<span class="normal"> 32</span>
<span class="normal"> 33</span>
<span class="normal"> 34</span>
<span class="normal"> 35</span>
<span class="normal"> 36</span>
<span class="normal"> 37</span>
<span class="normal"> 38</span>
<span class="normal"> 39</span>
<span class="normal"> 40</span>
<span class="normal"> 41</span>
<span class="normal"> 42</span>
<span class="normal"> 43</span>
<span class="normal"> 44</span>
<span class="normal"> 45</span>
<span class="normal"> 46</span>
<span class="normal"> 47</span>
<span class="normal"> 48</span>
<span class="normal"> 49</span>
<span class="normal"> 50</span>
<span class="normal"> 51</span>
<span class="normal"> 52</span>
<span class="normal"> 53</span>
<span class="normal"> 54</span>
<span class="normal"> 55</span>
<span class="normal"> 56</span>
<span class="normal"> 57</span>
<span class="normal"> 58</span>
<span class="normal"> 59</span>
<span class="normal"> 60</span>
<span class="normal"> 61</span>
<span class="normal"> 62</span>
<span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">MuFidelity</span><span class="p">(</span><span class="n">Metric</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Computes the MuFidelity metric for attributions.</span>

<span class="sd">    Given a `model` and `inputs`, mufidelity of `model` to an explainer at `inputs` is calculated by</span>
<span class="sd">    a correlation between difference of predictions and attributions of maked inputs,</span>
<span class="sd">    ``evaluation = corr(pred_diff, masked_attr)``.</span>

<span class="sd">    The masked inputs are generated by masking `subset_mask` to noised `inputs`,</span>
<span class="sd">    ``masked = perturbed * subset_mask + (1.0 - subset_mask) * baseline``</span>

<span class="sd">    Args:</span>
<span class="sd">        model (Model): The model to evaluate.</span>
<span class="sd">        explainer (Optional[Explainer]): The explainer to evaluate.</span>
<span class="sd">        n_perturb (int): Number of perturbations to generate.</span>
<span class="sd">        noise_scale (int): Scale factor for Gaussian random noise.</span>
<span class="sd">        batch_size (int): Batch size for model evaluation.</span>
<span class="sd">        grid_size (int): Size of the grid for creating subsets.</span>
<span class="sd">        baseline (Union[float, torch.Tensor]): Baseline value for masked subsets.</span>
<span class="sd">        mask_agg_dim (Optional[int]): Dimension to aggregate masks.</span>
<span class="sd">        **kwargs: Additional kwargs to compute metric in an evaluator. Not required for single usage.</span>

<span class="sd">    Reference:</span>
<span class="sd">        U. Bhatt, A. Weller, and J. M. F. Moura. Evaluating and aggregating feature-based model attributions. In Proceedings of the IJCAI (2020).</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">model</span><span class="p">:</span> <span class="n">Model</span><span class="p">,</span>
        <span class="n">explainer</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Explainer</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">n_perturb</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">150</span><span class="p">,</span>
        <span class="n">noise_scale</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.2</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">32</span><span class="p">,</span>
        <span class="n">grid_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">9</span><span class="p">,</span>
        <span class="n">baseline</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.</span><span class="p">,</span>
        <span class="n">mask_agg_dim</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">explainer</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_perturb</span> <span class="o">=</span> <span class="n">n_perturb</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">noise_scale</span> <span class="o">=</span> <span class="n">noise_scale</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">grid_size</span> <span class="o">=</span> <span class="n">grid_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">baseline</span> <span class="o">=</span> <span class="n">baseline</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mask_agg_dim</span> <span class="o">=</span> <span class="n">mask_agg_dim</span>

    <span class="k">def</span> <span class="nf">evaluate</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">inputs</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">targets</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">attributions</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Args:</span>
<span class="sd">            inputs (torch.Tensor): The input data (N x C x H x W).</span>
<span class="sd">            targets (torch.Tensor): The target labels for the inputs (N x 1).</span>
<span class="sd">            attributions (torch.Tensor): The attributions of the inputs.</span>

<span class="sd">        Returns:</span>
<span class="sd">            torch.Tensor: The result of the metric evaluation.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">attributions</span> <span class="o">=</span> <span class="n">attributions</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

        <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
        <span class="n">n_classes</span> <span class="o">=</span> <span class="n">outputs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">predictions</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">outputs</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">n_classes</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)[</span><span class="n">targets</span><span class="p">]</span>
        <span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>

        <span class="c1"># input, target, attr, pred</span>
        <span class="n">evaluations</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">zipped</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">attributions</span><span class="p">,</span> <span class="n">predictions</span><span class="p">)</span>
        <span class="k">for</span> <span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">attr</span><span class="p">,</span> <span class="n">pred</span> <span class="ow">in</span> <span class="n">zipped</span><span class="p">:</span>
            <span class="n">repeated</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="nb">input</span><span class="p">]</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">n_perturb</span><span class="p">)</span>
            <span class="c1"># Add Gaussian random noise</span>
            <span class="n">std</span><span class="p">,</span> <span class="n">mean</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">std_mean</span><span class="p">(</span><span class="n">repeated</span><span class="p">)</span>
            <span class="n">noise</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn_like</span><span class="p">(</span><span class="n">repeated</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span> <span class="o">*</span> <span class="n">std</span> <span class="o">+</span> <span class="n">mean</span>
            <span class="n">perturbed</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">noise_scale</span> <span class="o">*</span> <span class="n">noise</span> <span class="o">+</span> <span class="n">repeated</span>
            <span class="n">perturbed</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">minimum</span><span class="p">(</span><span class="n">repeated</span><span class="p">,</span> <span class="n">perturbed</span><span class="p">)</span>
            <span class="n">perturbed</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="n">repeated</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">perturbed</span><span class="p">)</span>

            <span class="c1"># prepare the random masks that will designate the modified subset (S in original equation)</span>
            <span class="n">subset_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">grid_size</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">noise_scale</span><span class="p">)</span>
            <span class="n">subset_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span>
                <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_perturb</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">grid_size</span> <span class="o">**</span> <span class="mi">2</span><span class="p">))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
            <span class="n">subset_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">subset_mask</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">subset_size</span>
            <span class="n">subset_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">subset_mask</span><span class="o">.</span><span class="n">type</span><span class="p">(</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_perturb</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">grid_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">grid_size</span><span class="p">))</span>
            <span class="n">subset_mask</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Resize</span><span class="p">(</span>
                <span class="n">perturbed</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">:],</span>
                <span class="n">transforms</span><span class="o">.</span><span class="n">InterpolationMode</span><span class="p">(</span><span class="s2">&quot;nearest&quot;</span><span class="p">)</span>
            <span class="p">)</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">subset_mask</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">mask_agg_dim</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">subset_mask</span> <span class="o">=</span> <span class="n">subset_mask</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">mask_agg_dim</span><span class="p">)</span>

            <span class="c1"># Use the masks to set the selected subsets to baseline state</span>
            <span class="n">masked</span> <span class="o">=</span> <span class="n">perturbed</span> <span class="o">*</span> <span class="n">subset_mask</span> <span class="o">+</span> \
                <span class="p">(</span><span class="mf">1.0</span> <span class="o">-</span> <span class="n">subset_mask</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">baseline</span>

            <span class="n">masked_output</span> <span class="o">=</span> <span class="n">_forward_batch</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="n">masked</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span>
            <span class="n">pred_diff</span> <span class="o">=</span> <span class="n">pred</span> <span class="o">-</span> <span class="n">masked_output</span><span class="p">[:,</span> <span class="n">target</span><span class="p">]</span>

            <span class="n">masked_attr</span> <span class="o">=</span> <span class="p">(</span><span class="n">attr</span> <span class="o">*</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">-</span> <span class="n">subset_mask</span><span class="p">))</span>\
                <span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="nb">tuple</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">subset_mask</span><span class="o">.</span><span class="n">ndim</span><span class="p">)))</span>

            <span class="n">corr</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">spearmanr</span><span class="p">(</span>
                <span class="n">pred_diff</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span>
                <span class="n">masked_attr</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span>
            <span class="p">)</span>
            <span class="n">evaluations</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">corr</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">evaluations</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h3 id="pnpxai.evaluator.metrics.mu_fidelity.MuFidelity.evaluate" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">evaluate</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">attributions</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">



<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>inputs</code></td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The input data (N x C x H x W).</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>targets</code></td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The target labels for the inputs (N x 1).</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>attributions</code></td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The attributions of the inputs.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>torch.Tensor: The result of the metric evaluation.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>pnpxai/evaluator/metrics/mu_fidelity.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 57</span>
<span class="normal"> 58</span>
<span class="normal"> 59</span>
<span class="normal"> 60</span>
<span class="normal"> 61</span>
<span class="normal"> 62</span>
<span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">evaluate</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">inputs</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">targets</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">attributions</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Args:</span>
<span class="sd">        inputs (torch.Tensor): The input data (N x C x H x W).</span>
<span class="sd">        targets (torch.Tensor): The target labels for the inputs (N x 1).</span>
<span class="sd">        attributions (torch.Tensor): The attributions of the inputs.</span>

<span class="sd">    Returns:</span>
<span class="sd">        torch.Tensor: The result of the metric evaluation.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">attributions</span> <span class="o">=</span> <span class="n">attributions</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

    <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
    <span class="n">n_classes</span> <span class="o">=</span> <span class="n">outputs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">predictions</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">outputs</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">n_classes</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)[</span><span class="n">targets</span><span class="p">]</span>
    <span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>

    <span class="c1"># input, target, attr, pred</span>
    <span class="n">evaluations</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">zipped</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">attributions</span><span class="p">,</span> <span class="n">predictions</span><span class="p">)</span>
    <span class="k">for</span> <span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">attr</span><span class="p">,</span> <span class="n">pred</span> <span class="ow">in</span> <span class="n">zipped</span><span class="p">:</span>
        <span class="n">repeated</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="nb">input</span><span class="p">]</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">n_perturb</span><span class="p">)</span>
        <span class="c1"># Add Gaussian random noise</span>
        <span class="n">std</span><span class="p">,</span> <span class="n">mean</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">std_mean</span><span class="p">(</span><span class="n">repeated</span><span class="p">)</span>
        <span class="n">noise</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn_like</span><span class="p">(</span><span class="n">repeated</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span> <span class="o">*</span> <span class="n">std</span> <span class="o">+</span> <span class="n">mean</span>
        <span class="n">perturbed</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">noise_scale</span> <span class="o">*</span> <span class="n">noise</span> <span class="o">+</span> <span class="n">repeated</span>
        <span class="n">perturbed</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">minimum</span><span class="p">(</span><span class="n">repeated</span><span class="p">,</span> <span class="n">perturbed</span><span class="p">)</span>
        <span class="n">perturbed</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="n">repeated</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">perturbed</span><span class="p">)</span>

        <span class="c1"># prepare the random masks that will designate the modified subset (S in original equation)</span>
        <span class="n">subset_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">grid_size</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">noise_scale</span><span class="p">)</span>
        <span class="n">subset_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span>
            <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_perturb</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">grid_size</span> <span class="o">**</span> <span class="mi">2</span><span class="p">))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">subset_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">subset_mask</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">subset_size</span>
        <span class="n">subset_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">subset_mask</span><span class="o">.</span><span class="n">type</span><span class="p">(</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_perturb</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">grid_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">grid_size</span><span class="p">))</span>
        <span class="n">subset_mask</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Resize</span><span class="p">(</span>
            <span class="n">perturbed</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">:],</span>
            <span class="n">transforms</span><span class="o">.</span><span class="n">InterpolationMode</span><span class="p">(</span><span class="s2">&quot;nearest&quot;</span><span class="p">)</span>
        <span class="p">)</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">subset_mask</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">mask_agg_dim</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">subset_mask</span> <span class="o">=</span> <span class="n">subset_mask</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">mask_agg_dim</span><span class="p">)</span>

        <span class="c1"># Use the masks to set the selected subsets to baseline state</span>
        <span class="n">masked</span> <span class="o">=</span> <span class="n">perturbed</span> <span class="o">*</span> <span class="n">subset_mask</span> <span class="o">+</span> \
            <span class="p">(</span><span class="mf">1.0</span> <span class="o">-</span> <span class="n">subset_mask</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">baseline</span>

        <span class="n">masked_output</span> <span class="o">=</span> <span class="n">_forward_batch</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="n">masked</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span>
        <span class="n">pred_diff</span> <span class="o">=</span> <span class="n">pred</span> <span class="o">-</span> <span class="n">masked_output</span><span class="p">[:,</span> <span class="n">target</span><span class="p">]</span>

        <span class="n">masked_attr</span> <span class="o">=</span> <span class="p">(</span><span class="n">attr</span> <span class="o">*</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">-</span> <span class="n">subset_mask</span><span class="p">))</span>\
            <span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="nb">tuple</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">subset_mask</span><span class="o">.</span><span class="n">ndim</span><span class="p">)))</span>

        <span class="n">corr</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">spearmanr</span><span class="p">(</span>
            <span class="n">pred_diff</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span>
            <span class="n">masked_attr</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span>
        <span class="p">)</span>
        <span class="n">evaluations</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">corr</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">evaluations</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>




  </div>

    </div>

</div>

<div class="doc doc-object doc-module">



<a id="pnpxai.evaluator.metrics.sensitivity"></a>
    <div class="doc doc-contents first">



  <div class="doc doc-children">








<div class="doc doc-object doc-class">



<h2 id="pnpxai.evaluator.metrics.sensitivity.Sensitivity" class="doc doc-heading">
            <code>Sensitivity</code>


</h2>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="pnpxai.evaluator.metrics.base.Metric">Metric</span></code></p>


      <p>Computes the complexity of attributions.</p>
<p>Given <code>attributions</code>, calculates a fractional contribution distribution <code>prob_mass</code>,
<code>prob_mass[i] = hist[i] / sum(hist)</code>. where <code>hist[i] = histogram(attributions[i])</code>.</p>
<p>The complexity is defined by the entropy,
<code>evaluation = -sum(hist * ln(hist))</code></p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>model</code></td>
            <td>
                  <code><span title="pnpxai.core._types.Model">Model</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The model used for evaluation</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>explainer</code></td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="pnpxai.explainers.base.Explainer">Explainer</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The explainer used for evaluation.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>n_iter</code></td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[int]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The number of iterations for perturbation.</p>
              </div>
            </td>
            <td>
                  <code>8</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>epsilon</code></td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[float]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The magnitude of random uniform noise.</p>
              </div>
            </td>
            <td>
                  <code>0.2</code>
            </td>
          </tr>
      </tbody>
    </table>

              <details class="quote">
                <summary>Source code in <code>pnpxai/evaluator/metrics/sensitivity.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span>
<span class="normal">67</span>
<span class="normal">68</span>
<span class="normal">69</span>
<span class="normal">70</span>
<span class="normal">71</span>
<span class="normal">72</span>
<span class="normal">73</span>
<span class="normal">74</span>
<span class="normal">75</span>
<span class="normal">76</span>
<span class="normal">77</span>
<span class="normal">78</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">Sensitivity</span><span class="p">(</span><span class="n">Metric</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Computes the complexity of attributions.</span>

<span class="sd">    Given `attributions`, calculates a fractional contribution distribution `prob_mass`,</span>
<span class="sd">    ``prob_mass[i] = hist[i] / sum(hist)``. where ``hist[i] = histogram(attributions[i])``.</span>

<span class="sd">    The complexity is defined by the entropy,</span>
<span class="sd">    ``evaluation = -sum(hist * ln(hist))``</span>


<span class="sd">    Args:</span>
<span class="sd">        model (Model): The model used for evaluation</span>
<span class="sd">        explainer (Optional[Explainer]): The explainer used for evaluation.</span>
<span class="sd">        n_iter (Optional[int]): The number of iterations for perturbation.</span>
<span class="sd">        epsilon (Optional[float]): The magnitude of random uniform noise.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">model</span><span class="p">:</span> <span class="n">Model</span><span class="p">,</span>
        <span class="n">explainer</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Explainer</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">n_iter</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="mi">8</span><span class="p">,</span>
        <span class="n">epsilon</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.2</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">explainer</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_iter</span> <span class="o">=</span> <span class="n">n_iter</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span> <span class="o">=</span> <span class="n">epsilon</span>
        <span class="k">if</span> <span class="n">explainer</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s1">&#39;[Sensitivity] explainer is not provided. Please set explainer before evaluate.&#39;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">evaluate</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">inputs</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">targets</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">attributions</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Args:</span>
<span class="sd">            inputs (torch.Tensor): The input data.</span>
<span class="sd">            targets (torch.Tensor): The target labels for the inputs.</span>
<span class="sd">            attributions (Optional[torch.Tensor]): The attributions of the inputs.</span>

<span class="sd">        Returns:</span>
<span class="sd">            torch.Tensor: The result of the metric evaluation.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">attributions</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">attributions</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">explainer</span><span class="o">.</span><span class="n">attribute</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span>
        <span class="n">attributions</span> <span class="o">=</span> <span class="n">attributions</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">evaluations</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">inp</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">attr</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">attributions</span><span class="p">):</span>
            <span class="c1"># Add random uniform noise which ranges [-epsilon, epsilon]</span>
            <span class="n">perturbed</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">inp</span><span class="p">]</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">n_iter</span><span class="p">)</span>
            <span class="n">noise</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">rand_like</span><span class="p">(</span><span class="n">perturbed</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span> <span class="o">*</span> <span class="mi">2</span> \
                <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span>
            <span class="p">)</span>
            <span class="n">perturbed</span> <span class="o">+=</span> <span class="n">noise</span>
            <span class="c1"># Get perturbed attribution results</span>
            <span class="n">perturbed_attr</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">explainer</span><span class="o">.</span><span class="n">attribute</span><span class="p">(</span>
                <span class="n">inputs</span><span class="o">=</span><span class="n">perturbed</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">),</span>
                <span class="n">targets</span><span class="o">=</span><span class="n">target</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_iter</span><span class="p">),</span>
            <span class="p">)</span>
            <span class="c1"># Get maximum of the difference between the perturbed attribution and the original attribution</span>
            <span class="n">attr_norm</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">attr</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
            <span class="n">attr_diff</span> <span class="o">=</span> <span class="n">attr</span> <span class="o">-</span> <span class="n">perturbed_attr</span>
            <span class="n">sens</span> <span class="o">=</span> <span class="nb">max</span><span class="p">([</span><span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">diff</span><span class="p">)</span><span class="o">/</span><span class="n">attr_norm</span> <span class="k">for</span> <span class="n">diff</span> <span class="ow">in</span> <span class="n">attr_diff</span><span class="p">])</span>
            <span class="n">evaluations</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">sens</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">evaluations</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h3 id="pnpxai.evaluator.metrics.sensitivity.Sensitivity.evaluate" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">evaluate</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">attributions</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">



<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>inputs</code></td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The input data.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>targets</code></td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The target labels for the inputs.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>attributions</code></td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="torch.Tensor">Tensor</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The attributions of the inputs.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>torch.Tensor: The result of the metric evaluation.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>pnpxai/evaluator/metrics/sensitivity.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span>
<span class="normal">67</span>
<span class="normal">68</span>
<span class="normal">69</span>
<span class="normal">70</span>
<span class="normal">71</span>
<span class="normal">72</span>
<span class="normal">73</span>
<span class="normal">74</span>
<span class="normal">75</span>
<span class="normal">76</span>
<span class="normal">77</span>
<span class="normal">78</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">evaluate</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">inputs</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">targets</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">attributions</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Args:</span>
<span class="sd">        inputs (torch.Tensor): The input data.</span>
<span class="sd">        targets (torch.Tensor): The target labels for the inputs.</span>
<span class="sd">        attributions (Optional[torch.Tensor]): The attributions of the inputs.</span>

<span class="sd">    Returns:</span>
<span class="sd">        torch.Tensor: The result of the metric evaluation.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">attributions</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">attributions</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">explainer</span><span class="o">.</span><span class="n">attribute</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span>
    <span class="n">attributions</span> <span class="o">=</span> <span class="n">attributions</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
    <span class="n">evaluations</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">inp</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">attr</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">attributions</span><span class="p">):</span>
        <span class="c1"># Add random uniform noise which ranges [-epsilon, epsilon]</span>
        <span class="n">perturbed</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">inp</span><span class="p">]</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">n_iter</span><span class="p">)</span>
        <span class="n">noise</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">rand_like</span><span class="p">(</span><span class="n">perturbed</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span> <span class="o">*</span> <span class="mi">2</span> \
            <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span>
        <span class="p">)</span>
        <span class="n">perturbed</span> <span class="o">+=</span> <span class="n">noise</span>
        <span class="c1"># Get perturbed attribution results</span>
        <span class="n">perturbed_attr</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">explainer</span><span class="o">.</span><span class="n">attribute</span><span class="p">(</span>
            <span class="n">inputs</span><span class="o">=</span><span class="n">perturbed</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">),</span>
            <span class="n">targets</span><span class="o">=</span><span class="n">target</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_iter</span><span class="p">),</span>
        <span class="p">)</span>
        <span class="c1"># Get maximum of the difference between the perturbed attribution and the original attribution</span>
        <span class="n">attr_norm</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">attr</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">attr_diff</span> <span class="o">=</span> <span class="n">attr</span> <span class="o">-</span> <span class="n">perturbed_attr</span>
        <span class="n">sens</span> <span class="o">=</span> <span class="nb">max</span><span class="p">([</span><span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">diff</span><span class="p">)</span><span class="o">/</span><span class="n">attr_norm</span> <span class="k">for</span> <span class="n">diff</span> <span class="ow">in</span> <span class="n">attr_diff</span><span class="p">])</span>
        <span class="n">evaluations</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">sens</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">evaluations</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>




  </div>

    </div>

</div>

<div class="doc doc-object doc-module">



<a id="pnpxai.evaluator.metrics.pixel_flipping"></a>
    <div class="doc doc-contents first">



  <div class="doc doc-children">








<div class="doc doc-object doc-class">



<h2 id="pnpxai.evaluator.metrics.pixel_flipping.AbPC" class="doc doc-heading">
            <code>AbPC</code>


</h2>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="pnpxai.evaluator.metrics.pixel_flipping.PixelFlipping" href="#pnpxai.evaluator.metrics.pixel_flipping.PixelFlipping">PixelFlipping</a></code></p>


      <p>A metric class for evaluating the correctness of explanations or attributions using the 
Area between Perturbation Curves (AbPC) technique.</p>
<p>This class inherits from the PixelFlipping class and assesses the quality of attributions by comparing 
the area between the perturbation curves obtained by perturbing input features (e.g., pixels) in both 
ascending and descending order of their attributed importance. The average probability change is 
measured, providing a comprehensive evaluation of the explainer's correctness.</p>


<p><span class="doc-section-title">Attributes:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code><span title="pnpxai.evaluator.metrics.pixel_flipping.AbPC.model">model</span></code></td>
            <td>
                  <code><span title="torch.nn.modules.Module">Module</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The model.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="pnpxai.evaluator.metrics.pixel_flipping.AbPC.explainer">explainer</span></code></td>
            <td>
                  <code>Optional[Explainer]=None</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The explainer whose explanations are being evaluated.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="pnpxai.evaluator.metrics.pixel_flipping.AbPC.channel_dim">channel_dim</span></code></td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Target channel dimension.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="pnpxai.evaluator.metrics.pixel_flipping.AbPC.n_steps">n_steps</span></code></td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The number of perturbation steps.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="pnpxai.evaluator.metrics.pixel_flipping.AbPC.baseline_fn">baseline_fn</span></code></td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="pnpxai.evaluator.metrics.pixel_flipping.BaselineFunction">BaselineFunction</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Function to generate baseline inputs for perturbation.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="pnpxai.evaluator.metrics.pixel_flipping.AbPC.prob_fn">prob_fn</span></code></td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="typing.Callable">Callable</span>[[<span title="pnpxai.explainers.types.Tensor">Tensor</span>], <span title="pnpxai.explainers.types.Tensor">Tensor</span>]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Function to compute probabilities from model outputs.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="pnpxai.evaluator.metrics.pixel_flipping.AbPC.pred_fn">pred_fn</span></code></td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="typing.Callable">Callable</span>[[<span title="pnpxai.explainers.types.Tensor">Tensor</span>], <span title="pnpxai.explainers.types.Tensor">Tensor</span>]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Function to compute predictions from model outputs.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="pnpxai.evaluator.metrics.pixel_flipping.AbPC.lb">lb</span></code></td>
            <td>
                  <code>float</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The lower bound for clamping the probability differences.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Methods:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
            <tr class="doc-section-item">
              <td><code><a class="autorefs autorefs-internal" title="pnpxai.evaluator.metrics.pixel_flipping.AbPC.evaluate" href="#pnpxai.evaluator.metrics.pixel_flipping.AbPC.evaluate">evaluate</a></code></td>
              <td>
                <div class="doc-md-description">
                  <p>Evaluate the explainer's correctness using the AbPC technique by observing changes in model predictions.</p>
                </div>
              </td>
            </tr>
      </tbody>
    </table>

              <details class="quote">
                <summary>Source code in <code>pnpxai/evaluator/metrics/pixel_flipping.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span>
<span class="normal">330</span>
<span class="normal">331</span>
<span class="normal">332</span>
<span class="normal">333</span>
<span class="normal">334</span>
<span class="normal">335</span>
<span class="normal">336</span>
<span class="normal">337</span>
<span class="normal">338</span>
<span class="normal">339</span>
<span class="normal">340</span>
<span class="normal">341</span>
<span class="normal">342</span>
<span class="normal">343</span>
<span class="normal">344</span>
<span class="normal">345</span>
<span class="normal">346</span>
<span class="normal">347</span>
<span class="normal">348</span>
<span class="normal">349</span>
<span class="normal">350</span>
<span class="normal">351</span>
<span class="normal">352</span>
<span class="normal">353</span>
<span class="normal">354</span>
<span class="normal">355</span>
<span class="normal">356</span>
<span class="normal">357</span>
<span class="normal">358</span>
<span class="normal">359</span>
<span class="normal">360</span>
<span class="normal">361</span>
<span class="normal">362</span>
<span class="normal">363</span>
<span class="normal">364</span>
<span class="normal">365</span>
<span class="normal">366</span>
<span class="normal">367</span>
<span class="normal">368</span>
<span class="normal">369</span>
<span class="normal">370</span>
<span class="normal">371</span>
<span class="normal">372</span>
<span class="normal">373</span>
<span class="normal">374</span>
<span class="normal">375</span>
<span class="normal">376</span>
<span class="normal">377</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">AbPC</span><span class="p">(</span><span class="n">PixelFlipping</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A metric class for evaluating the correctness of explanations or attributions using the </span>
<span class="sd">    Area between Perturbation Curves (AbPC) technique.</span>

<span class="sd">    This class inherits from the PixelFlipping class and assesses the quality of attributions by comparing </span>
<span class="sd">    the area between the perturbation curves obtained by perturbing input features (e.g., pixels) in both </span>
<span class="sd">    ascending and descending order of their attributed importance. The average probability change is </span>
<span class="sd">    measured, providing a comprehensive evaluation of the explainer&#39;s correctness.</span>

<span class="sd">    Attributes:</span>
<span class="sd">        model (Module): The model.</span>
<span class="sd">        explainer (Optional[Explainer]=None): The explainer whose explanations are being evaluated.</span>
<span class="sd">        channel_dim (int): Target channel dimension.</span>
<span class="sd">        n_steps (int): The number of perturbation steps.</span>
<span class="sd">        baseline_fn (Optional[BaselineFunction]): Function to generate baseline inputs for perturbation.</span>
<span class="sd">        prob_fn (Optional[Callable[[Tensor], Tensor]]): Function to compute probabilities from model outputs.</span>
<span class="sd">        pred_fn (Optional[Callable[[Tensor], Tensor]]): Function to compute predictions from model outputs.</span>
<span class="sd">        lb (float): The lower bound for clamping the probability differences.</span>

<span class="sd">    Methods:</span>
<span class="sd">        evaluate(inputs, targets, attributions, attention_mask=None):</span>
<span class="sd">            Evaluate the explainer&#39;s correctness using the AbPC technique by observing changes in model predictions.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">model</span><span class="p">:</span> <span class="n">Module</span><span class="p">,</span>
        <span class="n">explainer</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Explainer</span><span class="p">]</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">channel_dim</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">n_steps</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
        <span class="n">baseline_fn</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">BaselineFunction</span><span class="p">]</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">prob_fn</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">Tensor</span><span class="p">]]</span><span class="o">=</span><span class="k">lambda</span> <span class="n">outputs</span><span class="p">:</span> <span class="n">outputs</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">pred_fn</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">Tensor</span><span class="p">]]</span><span class="o">=</span><span class="k">lambda</span> <span class="n">outputs</span><span class="p">:</span> <span class="n">outputs</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">lb</span><span class="p">:</span> <span class="nb">float</span><span class="o">=-</span><span class="mf">1.</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">model</span><span class="p">,</span> <span class="n">explainer</span><span class="p">,</span> <span class="n">channel_dim</span><span class="p">,</span> <span class="n">n_steps</span><span class="p">,</span>
            <span class="n">baseline_fn</span><span class="p">,</span> <span class="n">prob_fn</span><span class="p">,</span> <span class="n">pred_fn</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lb</span> <span class="o">=</span> <span class="n">lb</span>

    <span class="k">def</span> <span class="nf">evaluate</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">inputs</span><span class="p">:</span> <span class="n">TensorOrTupleOfTensors</span><span class="p">,</span>
        <span class="n">targets</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
        <span class="n">attributions</span><span class="p">:</span> <span class="n">TensorOrTupleOfTensors</span><span class="p">,</span>
        <span class="n">attention_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">TensorOrTupleOfTensors</span><span class="p">]</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">return_pf</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorOrTupleOfTensors</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Evaluate the explainer&#39;s correctness using the AbPC technique by observing changes in model predictions.</span>

<span class="sd">        Args:</span>
<span class="sd">            inputs (TensorOrTupleOfTensors): The input tensors to the model.</span>
<span class="sd">            targets (Tensor): The target labels for the inputs.</span>
<span class="sd">            attributions (TensorOrTupleOfTensors): The attributions for the inputs.</span>
<span class="sd">            attention_mask (Optional[TensorOrTupleOfTensors], optional): Attention masks for the inputs.</span>
<span class="sd">            return_pf (Optional[bool]): Whether to return the perturbation curves for ascending and descending orders.</span>

<span class="sd">        Returns:</span>
<span class="sd">            TensorOrTupleOfTensors: The mean clamped differences in probabilities at each perturbation step, </span>
<span class="sd">                indicating the impact of perturbing the most and least relevant features.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># pf by ascending order: lerf</span>
        <span class="n">pf_ascs</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">attributions</span><span class="p">,</span> <span class="n">attention_mask</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
        <span class="n">pf_ascs</span> <span class="o">=</span> <span class="n">format_into_tuple</span><span class="p">(</span><span class="n">pf_ascs</span><span class="p">)</span>

        <span class="c1"># pf by descending order: morf</span>
        <span class="n">pf_descs</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">attributions</span><span class="p">,</span> <span class="n">attention_mask</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
        <span class="n">pf_descs</span> <span class="o">=</span> <span class="n">format_into_tuple</span><span class="p">(</span><span class="n">pf_descs</span><span class="p">)</span>

        <span class="c1"># abpc</span>
        <span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">pf_asc</span><span class="p">,</span> <span class="n">pf_desc</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">pf_ascs</span><span class="p">,</span> <span class="n">pf_descs</span><span class="p">):</span>
            <span class="n">result</span> <span class="o">=</span> <span class="p">(</span><span class="n">pf_asc</span><span class="p">[</span><span class="s1">&#39;probs&#39;</span><span class="p">]</span> <span class="o">-</span> <span class="n">pf_desc</span><span class="p">[</span><span class="s1">&#39;probs&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="nb">min</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">lb</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">return_pf</span><span class="p">:</span>
                <span class="n">result</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">([</span><span class="n">result</span><span class="p">,</span> <span class="n">pf_desc</span><span class="p">,</span> <span class="n">pf_asc</span><span class="p">])</span>
            <span class="n">results</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">results</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">results</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">return</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h3 id="pnpxai.evaluator.metrics.pixel_flipping.AbPC.evaluate" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">evaluate</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">attributions</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">return_pf</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

      <p>Evaluate the explainer's correctness using the AbPC technique by observing changes in model predictions.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>inputs</code></td>
            <td>
                  <code><span title="pnpxai.explainers.types.TensorOrTupleOfTensors">TensorOrTupleOfTensors</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The input tensors to the model.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>targets</code></td>
            <td>
                  <code><span title="pnpxai.explainers.types.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The target labels for the inputs.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>attributions</code></td>
            <td>
                  <code><span title="pnpxai.explainers.types.TensorOrTupleOfTensors">TensorOrTupleOfTensors</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The attributions for the inputs.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>attention_mask</code></td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="pnpxai.explainers.types.TensorOrTupleOfTensors">TensorOrTupleOfTensors</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Attention masks for the inputs.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>return_pf</code></td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[bool]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Whether to return the perturbation curves for ascending and descending orders.</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>TensorOrTupleOfTensors</code></td>            <td>
                  <code><span title="pnpxai.explainers.types.TensorOrTupleOfTensors">TensorOrTupleOfTensors</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The mean clamped differences in probabilities at each perturbation step, 
indicating the impact of perturbing the most and least relevant features.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>pnpxai/evaluator/metrics/pixel_flipping.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">338</span>
<span class="normal">339</span>
<span class="normal">340</span>
<span class="normal">341</span>
<span class="normal">342</span>
<span class="normal">343</span>
<span class="normal">344</span>
<span class="normal">345</span>
<span class="normal">346</span>
<span class="normal">347</span>
<span class="normal">348</span>
<span class="normal">349</span>
<span class="normal">350</span>
<span class="normal">351</span>
<span class="normal">352</span>
<span class="normal">353</span>
<span class="normal">354</span>
<span class="normal">355</span>
<span class="normal">356</span>
<span class="normal">357</span>
<span class="normal">358</span>
<span class="normal">359</span>
<span class="normal">360</span>
<span class="normal">361</span>
<span class="normal">362</span>
<span class="normal">363</span>
<span class="normal">364</span>
<span class="normal">365</span>
<span class="normal">366</span>
<span class="normal">367</span>
<span class="normal">368</span>
<span class="normal">369</span>
<span class="normal">370</span>
<span class="normal">371</span>
<span class="normal">372</span>
<span class="normal">373</span>
<span class="normal">374</span>
<span class="normal">375</span>
<span class="normal">376</span>
<span class="normal">377</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">evaluate</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">inputs</span><span class="p">:</span> <span class="n">TensorOrTupleOfTensors</span><span class="p">,</span>
    <span class="n">targets</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
    <span class="n">attributions</span><span class="p">:</span> <span class="n">TensorOrTupleOfTensors</span><span class="p">,</span>
    <span class="n">attention_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">TensorOrTupleOfTensors</span><span class="p">]</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">return_pf</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorOrTupleOfTensors</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Evaluate the explainer&#39;s correctness using the AbPC technique by observing changes in model predictions.</span>

<span class="sd">    Args:</span>
<span class="sd">        inputs (TensorOrTupleOfTensors): The input tensors to the model.</span>
<span class="sd">        targets (Tensor): The target labels for the inputs.</span>
<span class="sd">        attributions (TensorOrTupleOfTensors): The attributions for the inputs.</span>
<span class="sd">        attention_mask (Optional[TensorOrTupleOfTensors], optional): Attention masks for the inputs.</span>
<span class="sd">        return_pf (Optional[bool]): Whether to return the perturbation curves for ascending and descending orders.</span>

<span class="sd">    Returns:</span>
<span class="sd">        TensorOrTupleOfTensors: The mean clamped differences in probabilities at each perturbation step, </span>
<span class="sd">            indicating the impact of perturbing the most and least relevant features.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># pf by ascending order: lerf</span>
    <span class="n">pf_ascs</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">attributions</span><span class="p">,</span> <span class="n">attention_mask</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
    <span class="n">pf_ascs</span> <span class="o">=</span> <span class="n">format_into_tuple</span><span class="p">(</span><span class="n">pf_ascs</span><span class="p">)</span>

    <span class="c1"># pf by descending order: morf</span>
    <span class="n">pf_descs</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">attributions</span><span class="p">,</span> <span class="n">attention_mask</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
    <span class="n">pf_descs</span> <span class="o">=</span> <span class="n">format_into_tuple</span><span class="p">(</span><span class="n">pf_descs</span><span class="p">)</span>

    <span class="c1"># abpc</span>
    <span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">pf_asc</span><span class="p">,</span> <span class="n">pf_desc</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">pf_ascs</span><span class="p">,</span> <span class="n">pf_descs</span><span class="p">):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="p">(</span><span class="n">pf_asc</span><span class="p">[</span><span class="s1">&#39;probs&#39;</span><span class="p">]</span> <span class="o">-</span> <span class="n">pf_desc</span><span class="p">[</span><span class="s1">&#39;probs&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="nb">min</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">lb</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">return_pf</span><span class="p">:</span>
            <span class="n">result</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">([</span><span class="n">result</span><span class="p">,</span> <span class="n">pf_desc</span><span class="p">,</span> <span class="n">pf_asc</span><span class="p">])</span>
        <span class="n">results</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">results</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">results</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">return</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="pnpxai.evaluator.metrics.pixel_flipping.LeRF" class="doc doc-heading">
            <code>LeRF</code>


</h2>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="pnpxai.evaluator.metrics.pixel_flipping.PixelFlipping" href="#pnpxai.evaluator.metrics.pixel_flipping.PixelFlipping">PixelFlipping</a></code></p>


      <p>A metric class for evaluating the correctness of explanations or attributions using the 
Least Relevant First (LeRF) pixel flipping technique.</p>
<p>This class inherits from the PixelFlipping class and evaluates the quality of attributions by perturbing input 
features (e.g., pixels) in ascending order of their attributed importance. The average probability change is 
measured to assess the explainer's correctness.</p>


<p><span class="doc-section-title">Attributes:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code><span title="pnpxai.evaluator.metrics.pixel_flipping.LeRF.model">model</span></code></td>
            <td>
                  <code><span title="torch.nn.modules.Module">Module</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The model.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="pnpxai.evaluator.metrics.pixel_flipping.LeRF.explainer">explainer</span></code></td>
            <td>
                  <code>Optional[Explainer]=None</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The explainer whose explanations are being evaluated.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="pnpxai.evaluator.metrics.pixel_flipping.LeRF.channel_dim">channel_dim</span></code></td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Target channel dimension.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="pnpxai.evaluator.metrics.pixel_flipping.LeRF.n_steps">n_steps</span></code></td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The number of perturbation steps.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="pnpxai.evaluator.metrics.pixel_flipping.LeRF.baseline_fn">baseline_fn</span></code></td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="pnpxai.evaluator.metrics.pixel_flipping.BaselineFunction">BaselineFunction</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Function to generate baseline inputs for perturbation.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="pnpxai.evaluator.metrics.pixel_flipping.LeRF.prob_fn">prob_fn</span></code></td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="typing.Callable">Callable</span>[[<span title="pnpxai.explainers.types.Tensor">Tensor</span>], <span title="pnpxai.explainers.types.Tensor">Tensor</span>]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Function to compute probabilities from model outputs.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="pnpxai.evaluator.metrics.pixel_flipping.LeRF.pred_fn">pred_fn</span></code></td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="typing.Callable">Callable</span>[[<span title="pnpxai.explainers.types.Tensor">Tensor</span>], <span title="pnpxai.explainers.types.Tensor">Tensor</span>]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Function to compute predictions from model outputs.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Methods:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
            <tr class="doc-section-item">
              <td><code><a class="autorefs autorefs-internal" title="pnpxai.evaluator.metrics.pixel_flipping.LeRF.evaluate" href="#pnpxai.evaluator.metrics.pixel_flipping.LeRF.evaluate">evaluate</a></code></td>
              <td>
                <div class="doc-md-description">
                  <p>Evaluate the explainer's correctness using the LeRF technique by observing changes in model predictions.</p>
                </div>
              </td>
            </tr>
      </tbody>
    </table>

              <details class="quote">
                <summary>Source code in <code>pnpxai/evaluator/metrics/pixel_flipping.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">LeRF</span><span class="p">(</span><span class="n">PixelFlipping</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A metric class for evaluating the correctness of explanations or attributions using the </span>
<span class="sd">    Least Relevant First (LeRF) pixel flipping technique.</span>

<span class="sd">    This class inherits from the PixelFlipping class and evaluates the quality of attributions by perturbing input </span>
<span class="sd">    features (e.g., pixels) in ascending order of their attributed importance. The average probability change is </span>
<span class="sd">    measured to assess the explainer&#39;s correctness.</span>

<span class="sd">    Attributes:</span>
<span class="sd">        model (Module): The model.</span>
<span class="sd">        explainer (Optional[Explainer]=None): The explainer whose explanations are being evaluated.</span>
<span class="sd">        channel_dim (int): Target channel dimension.</span>
<span class="sd">        n_steps (int): The number of perturbation steps.</span>
<span class="sd">        baseline_fn (Optional[BaselineFunction]): Function to generate baseline inputs for perturbation.</span>
<span class="sd">        prob_fn (Optional[Callable[[Tensor], Tensor]]): Function to compute probabilities from model outputs.</span>
<span class="sd">        pred_fn (Optional[Callable[[Tensor], Tensor]]): Function to compute predictions from model outputs.</span>

<span class="sd">    Methods:</span>
<span class="sd">        evaluate(inputs, targets, attributions, attention_mask=None):</span>
<span class="sd">            Evaluate the explainer&#39;s correctness using the LeRF technique by observing changes in model predictions.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">model</span><span class="p">:</span> <span class="n">Module</span><span class="p">,</span>
        <span class="n">explainer</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Explainer</span><span class="p">]</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">channel_dim</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">n_steps</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
        <span class="n">baseline_fn</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">BaselineFunction</span><span class="p">]</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">prob_fn</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">Tensor</span><span class="p">]]</span><span class="o">=</span><span class="k">lambda</span> <span class="n">outputs</span><span class="p">:</span> <span class="n">outputs</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">pred_fn</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">Tensor</span><span class="p">]]</span><span class="o">=</span><span class="k">lambda</span> <span class="n">outputs</span><span class="p">:</span> <span class="n">outputs</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">model</span><span class="p">,</span> <span class="n">explainer</span><span class="p">,</span> <span class="n">channel_dim</span><span class="p">,</span> <span class="n">n_steps</span><span class="p">,</span>
            <span class="n">baseline_fn</span><span class="p">,</span> <span class="n">prob_fn</span><span class="p">,</span> <span class="n">pred_fn</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">evaluate</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">inputs</span><span class="p">:</span> <span class="n">TensorOrTupleOfTensors</span><span class="p">,</span>
        <span class="n">targets</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
        <span class="n">attributions</span><span class="p">:</span> <span class="n">TensorOrTupleOfTensors</span><span class="p">,</span>
        <span class="n">attention_mask</span><span class="p">:</span> <span class="n">TensorOrTupleOfTensors</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorOrTupleOfTensors</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Evaluate the explainer&#39;s correctness using the LeRF technique by observing changes in model predictions.</span>

<span class="sd">        Args:</span>
<span class="sd">            inputs (TensorOrTupleOfTensors): The input tensors to the model.</span>
<span class="sd">            targets (Tensor): The target labels for the inputs.</span>
<span class="sd">            attributions (TensorOrTupleOfTensors): The attributions for the inputs.</span>
<span class="sd">            attention_mask (Optional[TensorOrTupleOfTensors], optional): Attention masks for the inputs. Default is None.</span>

<span class="sd">        Returns:</span>
<span class="sd">            TensorOrTupleOfTensors: The mean probabilities at each perturbation step, indicating the impact of </span>
<span class="sd">                perturbing the least relevant features first.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">pf_results</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">attributions</span><span class="p">,</span> <span class="n">attention_mask</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
        <span class="n">pf_results</span> <span class="o">=</span> <span class="n">format_into_tuple</span><span class="p">(</span><span class="n">pf_results</span><span class="p">)</span>
        <span class="n">lerf</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">result</span><span class="p">[</span><span class="s1">&#39;probs&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="k">for</span> <span class="n">result</span> <span class="ow">in</span> <span class="n">pf_results</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">lerf</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">lerf</span> <span class="o">=</span> <span class="n">lerf</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">lerf</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h3 id="pnpxai.evaluator.metrics.pixel_flipping.LeRF.evaluate" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">evaluate</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">attributions</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

      <p>Evaluate the explainer's correctness using the LeRF technique by observing changes in model predictions.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>inputs</code></td>
            <td>
                  <code><span title="pnpxai.explainers.types.TensorOrTupleOfTensors">TensorOrTupleOfTensors</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The input tensors to the model.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>targets</code></td>
            <td>
                  <code><span title="pnpxai.explainers.types.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The target labels for the inputs.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>attributions</code></td>
            <td>
                  <code><span title="pnpxai.explainers.types.TensorOrTupleOfTensors">TensorOrTupleOfTensors</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The attributions for the inputs.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>attention_mask</code></td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="pnpxai.explainers.types.TensorOrTupleOfTensors">TensorOrTupleOfTensors</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Attention masks for the inputs. Default is None.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>TensorOrTupleOfTensors</code></td>            <td>
                  <code><span title="pnpxai.explainers.types.TensorOrTupleOfTensors">TensorOrTupleOfTensors</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The mean probabilities at each perturbation step, indicating the impact of 
perturbing the least relevant features first.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>pnpxai/evaluator/metrics/pixel_flipping.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">evaluate</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">inputs</span><span class="p">:</span> <span class="n">TensorOrTupleOfTensors</span><span class="p">,</span>
    <span class="n">targets</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
    <span class="n">attributions</span><span class="p">:</span> <span class="n">TensorOrTupleOfTensors</span><span class="p">,</span>
    <span class="n">attention_mask</span><span class="p">:</span> <span class="n">TensorOrTupleOfTensors</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorOrTupleOfTensors</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Evaluate the explainer&#39;s correctness using the LeRF technique by observing changes in model predictions.</span>

<span class="sd">    Args:</span>
<span class="sd">        inputs (TensorOrTupleOfTensors): The input tensors to the model.</span>
<span class="sd">        targets (Tensor): The target labels for the inputs.</span>
<span class="sd">        attributions (TensorOrTupleOfTensors): The attributions for the inputs.</span>
<span class="sd">        attention_mask (Optional[TensorOrTupleOfTensors], optional): Attention masks for the inputs. Default is None.</span>

<span class="sd">    Returns:</span>
<span class="sd">        TensorOrTupleOfTensors: The mean probabilities at each perturbation step, indicating the impact of </span>
<span class="sd">            perturbing the least relevant features first.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">pf_results</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">attributions</span><span class="p">,</span> <span class="n">attention_mask</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
    <span class="n">pf_results</span> <span class="o">=</span> <span class="n">format_into_tuple</span><span class="p">(</span><span class="n">pf_results</span><span class="p">)</span>
    <span class="n">lerf</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">result</span><span class="p">[</span><span class="s1">&#39;probs&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="k">for</span> <span class="n">result</span> <span class="ow">in</span> <span class="n">pf_results</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">lerf</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">lerf</span> <span class="o">=</span> <span class="n">lerf</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">lerf</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="pnpxai.evaluator.metrics.pixel_flipping.MoRF" class="doc doc-heading">
            <code>MoRF</code>


</h2>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="pnpxai.evaluator.metrics.pixel_flipping.PixelFlipping" href="#pnpxai.evaluator.metrics.pixel_flipping.PixelFlipping">PixelFlipping</a></code></p>


      <p>A metric class for evaluating the correctness of explanations or attributions using the 
Most Relevant First (MoRF) pixel flipping technique.</p>
<p>This class inherits from the PixelFlipping class and evaluates the quality of attributions by perturbing input 
features (e.g., pixels) in descending order of their attributed importance. The average probability change is 
measured to assess the explainer's correctness (lower better).</p>


<p><span class="doc-section-title">Attributes:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code><span title="pnpxai.evaluator.metrics.pixel_flipping.MoRF.model">model</span></code></td>
            <td>
                  <code><span title="torch.nn.modules.Module">Module</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The model.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="pnpxai.evaluator.metrics.pixel_flipping.MoRF.explainer">explainer</span></code></td>
            <td>
                  <code>Optional[Explainer]=None</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The explainer whose explanations are being evaluated.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="pnpxai.evaluator.metrics.pixel_flipping.MoRF.channel_dim">channel_dim</span></code></td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Target channel dimension.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="pnpxai.evaluator.metrics.pixel_flipping.MoRF.n_steps">n_steps</span></code></td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The number of perturbation steps.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="pnpxai.evaluator.metrics.pixel_flipping.MoRF.baseline_fn">baseline_fn</span></code></td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="pnpxai.evaluator.metrics.pixel_flipping.BaselineFunction">BaselineFunction</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Function to generate baseline inputs for perturbation.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="pnpxai.evaluator.metrics.pixel_flipping.MoRF.prob_fn">prob_fn</span></code></td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="typing.Callable">Callable</span>[[<span title="pnpxai.explainers.types.Tensor">Tensor</span>], <span title="pnpxai.explainers.types.Tensor">Tensor</span>]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Function to compute probabilities from model outputs.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="pnpxai.evaluator.metrics.pixel_flipping.MoRF.pred_fn">pred_fn</span></code></td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="typing.Callable">Callable</span>[[<span title="pnpxai.explainers.types.Tensor">Tensor</span>], <span title="pnpxai.explainers.types.Tensor">Tensor</span>]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Function to compute predictions from model outputs.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Methods:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
            <tr class="doc-section-item">
              <td><code><a class="autorefs autorefs-internal" title="pnpxai.evaluator.metrics.pixel_flipping.MoRF.evaluate" href="#pnpxai.evaluator.metrics.pixel_flipping.MoRF.evaluate">evaluate</a></code></td>
              <td>
                <div class="doc-md-description">
                  <p>Evaluate the explainer's correctness using the MoRF technique by observing changes in model predictions.</p>
                </div>
              </td>
            </tr>
      </tbody>
    </table>

              <details class="quote">
                <summary>Source code in <code>pnpxai/evaluator/metrics/pixel_flipping.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">MoRF</span><span class="p">(</span><span class="n">PixelFlipping</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A metric class for evaluating the correctness of explanations or attributions using the </span>
<span class="sd">    Most Relevant First (MoRF) pixel flipping technique.</span>

<span class="sd">    This class inherits from the PixelFlipping class and evaluates the quality of attributions by perturbing input </span>
<span class="sd">    features (e.g., pixels) in descending order of their attributed importance. The average probability change is </span>
<span class="sd">    measured to assess the explainer&#39;s correctness (lower better).</span>

<span class="sd">    Attributes:</span>
<span class="sd">        model (Module): The model.</span>
<span class="sd">        explainer (Optional[Explainer]=None): The explainer whose explanations are being evaluated.</span>
<span class="sd">        channel_dim (int): Target channel dimension.</span>
<span class="sd">        n_steps (int): The number of perturbation steps.</span>
<span class="sd">        baseline_fn (Optional[BaselineFunction]): Function to generate baseline inputs for perturbation.</span>
<span class="sd">        prob_fn (Optional[Callable[[Tensor], Tensor]]): Function to compute probabilities from model outputs.</span>
<span class="sd">        pred_fn (Optional[Callable[[Tensor], Tensor]]): Function to compute predictions from model outputs.</span>

<span class="sd">    Methods:</span>
<span class="sd">        evaluate(inputs, targets, attributions, attention_mask=None):</span>
<span class="sd">            Evaluate the explainer&#39;s correctness using the MoRF technique by observing changes in model predictions.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">model</span><span class="p">:</span> <span class="n">Module</span><span class="p">,</span>
        <span class="n">explainer</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Explainer</span><span class="p">]</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">channel_dim</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">n_steps</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
        <span class="n">baseline_fn</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">BaselineFunction</span><span class="p">]</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">prob_fn</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">Tensor</span><span class="p">]]</span><span class="o">=</span><span class="k">lambda</span> <span class="n">outputs</span><span class="p">:</span> <span class="n">outputs</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">pred_fn</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">Tensor</span><span class="p">]]</span><span class="o">=</span><span class="k">lambda</span> <span class="n">outputs</span><span class="p">:</span> <span class="n">outputs</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">model</span><span class="p">,</span> <span class="n">explainer</span><span class="p">,</span> <span class="n">channel_dim</span><span class="p">,</span> <span class="n">n_steps</span><span class="p">,</span>
            <span class="n">baseline_fn</span><span class="p">,</span> <span class="n">prob_fn</span><span class="p">,</span> <span class="n">pred_fn</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">evaluate</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">inputs</span><span class="p">:</span> <span class="n">TensorOrTupleOfTensors</span><span class="p">,</span>
        <span class="n">targets</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
        <span class="n">attributions</span><span class="p">:</span> <span class="n">TensorOrTupleOfTensors</span><span class="p">,</span>
        <span class="n">attention_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">TensorOrTupleOfTensors</span><span class="p">]</span><span class="o">=</span><span class="kc">None</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorOrTupleOfTensors</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Evaluate the explainer&#39;s correctness using the MoRF technique by observing changes in model predictions.</span>

<span class="sd">        Args:</span>
<span class="sd">            inputs (TensorOrTupleOfTensors): The input tensors to the model.</span>
<span class="sd">            targets (Tensor): The target labels for the inputs.</span>
<span class="sd">            attributions (TensorOrTupleOfTensors): The attributions for the inputs.</span>
<span class="sd">            attention_mask (Optional[TensorOrTupleOfTensors], optional): Attention masks for the inputs. Default is None.</span>

<span class="sd">        Returns:</span>
<span class="sd">            TensorOrTupleOfTensors: The mean probabilities at each perturbation step, indicating the impact of </span>
<span class="sd">                perturbing the most relevant features first.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">pf_results</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">attributions</span><span class="p">,</span> <span class="n">attention_mask</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
        <span class="n">pf_results</span> <span class="o">=</span> <span class="n">format_into_tuple</span><span class="p">(</span><span class="n">pf_results</span><span class="p">)</span>
        <span class="n">morf</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">result</span><span class="p">[</span><span class="s1">&#39;probs&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="k">for</span> <span class="n">result</span> <span class="ow">in</span> <span class="n">pf_results</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">morf</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">morf</span> <span class="o">=</span> <span class="n">morf</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">morf</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h3 id="pnpxai.evaluator.metrics.pixel_flipping.MoRF.evaluate" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">evaluate</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">attributions</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

      <p>Evaluate the explainer's correctness using the MoRF technique by observing changes in model predictions.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>inputs</code></td>
            <td>
                  <code><span title="pnpxai.explainers.types.TensorOrTupleOfTensors">TensorOrTupleOfTensors</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The input tensors to the model.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>targets</code></td>
            <td>
                  <code><span title="pnpxai.explainers.types.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The target labels for the inputs.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>attributions</code></td>
            <td>
                  <code><span title="pnpxai.explainers.types.TensorOrTupleOfTensors">TensorOrTupleOfTensors</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The attributions for the inputs.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>attention_mask</code></td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="pnpxai.explainers.types.TensorOrTupleOfTensors">TensorOrTupleOfTensors</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Attention masks for the inputs. Default is None.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>TensorOrTupleOfTensors</code></td>            <td>
                  <code><span title="pnpxai.explainers.types.TensorOrTupleOfTensors">TensorOrTupleOfTensors</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The mean probabilities at each perturbation step, indicating the impact of 
perturbing the most relevant features first.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>pnpxai/evaluator/metrics/pixel_flipping.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">evaluate</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">inputs</span><span class="p">:</span> <span class="n">TensorOrTupleOfTensors</span><span class="p">,</span>
    <span class="n">targets</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
    <span class="n">attributions</span><span class="p">:</span> <span class="n">TensorOrTupleOfTensors</span><span class="p">,</span>
    <span class="n">attention_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">TensorOrTupleOfTensors</span><span class="p">]</span><span class="o">=</span><span class="kc">None</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorOrTupleOfTensors</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Evaluate the explainer&#39;s correctness using the MoRF technique by observing changes in model predictions.</span>

<span class="sd">    Args:</span>
<span class="sd">        inputs (TensorOrTupleOfTensors): The input tensors to the model.</span>
<span class="sd">        targets (Tensor): The target labels for the inputs.</span>
<span class="sd">        attributions (TensorOrTupleOfTensors): The attributions for the inputs.</span>
<span class="sd">        attention_mask (Optional[TensorOrTupleOfTensors], optional): Attention masks for the inputs. Default is None.</span>

<span class="sd">    Returns:</span>
<span class="sd">        TensorOrTupleOfTensors: The mean probabilities at each perturbation step, indicating the impact of </span>
<span class="sd">            perturbing the most relevant features first.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">pf_results</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">attributions</span><span class="p">,</span> <span class="n">attention_mask</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
    <span class="n">pf_results</span> <span class="o">=</span> <span class="n">format_into_tuple</span><span class="p">(</span><span class="n">pf_results</span><span class="p">)</span>
    <span class="n">morf</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">result</span><span class="p">[</span><span class="s1">&#39;probs&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="k">for</span> <span class="n">result</span> <span class="ow">in</span> <span class="n">pf_results</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">morf</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">morf</span> <span class="o">=</span> <span class="n">morf</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">morf</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="pnpxai.evaluator.metrics.pixel_flipping.PixelFlipping" class="doc doc-heading">
            <code>PixelFlipping</code>


</h2>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="pnpxai.evaluator.metrics.base.Metric">Metric</span></code></p>


      <p>A metric class for evaluating the correctness of explanations or attributions provided by an explainer 
using the pixel flipping technique.</p>
<p>This class assesses the quality of attributions by perturbing input features (e.g., pixels) in the order 
of their attributed importance and measuring the resulting change in the model's predictions. Correct attributions 
should lead to significant changes in model predictions when the most important features are perturbed.</p>


<p><span class="doc-section-title">Attributes:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code><span title="pnpxai.evaluator.metrics.pixel_flipping.PixelFlipping.model">model</span></code></td>
            <td>
                  <code><span title="torch.nn.modules.Module">Module</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The model.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="pnpxai.evaluator.metrics.pixel_flipping.PixelFlipping.explainer">explainer</span></code></td>
            <td>
                  <code>Optional[Explainer]=None</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The explainer whose explanations are being evaluated.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="pnpxai.evaluator.metrics.pixel_flipping.PixelFlipping.channel_dim">channel_dim</span></code></td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Target channel dimension.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="pnpxai.evaluator.metrics.pixel_flipping.PixelFlipping.n_steps">n_steps</span></code></td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The number of perturbation steps.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="pnpxai.evaluator.metrics.pixel_flipping.PixelFlipping.baseline_fn">baseline_fn</span></code></td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="pnpxai.evaluator.metrics.pixel_flipping.BaselineFunction">BaselineFunction</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Function to generate baseline inputs for perturbation.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="pnpxai.evaluator.metrics.pixel_flipping.PixelFlipping.prob_fn">prob_fn</span></code></td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="typing.Callable">Callable</span>[[<span title="pnpxai.explainers.types.Tensor">Tensor</span>], <span title="pnpxai.explainers.types.Tensor">Tensor</span>]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Function to compute probabilities from model outputs.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="pnpxai.evaluator.metrics.pixel_flipping.PixelFlipping.pred_fn">pred_fn</span></code></td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="typing.Callable">Callable</span>[[<span title="pnpxai.explainers.types.Tensor">Tensor</span>], <span title="pnpxai.explainers.types.Tensor">Tensor</span>]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Function to compute predictions from model outputs.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Methods:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
            <tr class="doc-section-item">
              <td><code><a class="autorefs autorefs-internal" title="pnpxai.evaluator.metrics.pixel_flipping.PixelFlipping.evaluate" href="#pnpxai.evaluator.metrics.pixel_flipping.PixelFlipping.evaluate">evaluate</a></code></td>
              <td>
                <div class="doc-md-description">
                  <p>Evaluate the explainer's correctness based on the attributions by observing changes in model predictions.</p>
                </div>
              </td>
            </tr>
      </tbody>
    </table>

              <details class="quote">
                <summary>Source code in <code>pnpxai/evaluator/metrics/pixel_flipping.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 17</span>
<span class="normal"> 18</span>
<span class="normal"> 19</span>
<span class="normal"> 20</span>
<span class="normal"> 21</span>
<span class="normal"> 22</span>
<span class="normal"> 23</span>
<span class="normal"> 24</span>
<span class="normal"> 25</span>
<span class="normal"> 26</span>
<span class="normal"> 27</span>
<span class="normal"> 28</span>
<span class="normal"> 29</span>
<span class="normal"> 30</span>
<span class="normal"> 31</span>
<span class="normal"> 32</span>
<span class="normal"> 33</span>
<span class="normal"> 34</span>
<span class="normal"> 35</span>
<span class="normal"> 36</span>
<span class="normal"> 37</span>
<span class="normal"> 38</span>
<span class="normal"> 39</span>
<span class="normal"> 40</span>
<span class="normal"> 41</span>
<span class="normal"> 42</span>
<span class="normal"> 43</span>
<span class="normal"> 44</span>
<span class="normal"> 45</span>
<span class="normal"> 46</span>
<span class="normal"> 47</span>
<span class="normal"> 48</span>
<span class="normal"> 49</span>
<span class="normal"> 50</span>
<span class="normal"> 51</span>
<span class="normal"> 52</span>
<span class="normal"> 53</span>
<span class="normal"> 54</span>
<span class="normal"> 55</span>
<span class="normal"> 56</span>
<span class="normal"> 57</span>
<span class="normal"> 58</span>
<span class="normal"> 59</span>
<span class="normal"> 60</span>
<span class="normal"> 61</span>
<span class="normal"> 62</span>
<span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">PixelFlipping</span><span class="p">(</span><span class="n">Metric</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A metric class for evaluating the correctness of explanations or attributions provided by an explainer </span>
<span class="sd">    using the pixel flipping technique.</span>

<span class="sd">    This class assesses the quality of attributions by perturbing input features (e.g., pixels) in the order </span>
<span class="sd">    of their attributed importance and measuring the resulting change in the model&#39;s predictions. Correct attributions </span>
<span class="sd">    should lead to significant changes in model predictions when the most important features are perturbed.</span>

<span class="sd">    Attributes:</span>
<span class="sd">        model (Module): The model.</span>
<span class="sd">        explainer (Optional[Explainer]=None): The explainer whose explanations are being evaluated.</span>
<span class="sd">        channel_dim (int): Target channel dimension.</span>
<span class="sd">        n_steps (int): The number of perturbation steps.</span>
<span class="sd">        baseline_fn (Optional[BaselineFunction]): Function to generate baseline inputs for perturbation.</span>
<span class="sd">        prob_fn (Optional[Callable[[Tensor], Tensor]]): Function to compute probabilities from model outputs.</span>
<span class="sd">        pred_fn (Optional[Callable[[Tensor], Tensor]]): Function to compute predictions from model outputs.</span>

<span class="sd">    Methods:</span>
<span class="sd">        evaluate(inputs, targets, attributions, attention_mask=None, descending=True):</span>
<span class="sd">            Evaluate the explainer&#39;s correctness based on the attributions by observing changes in model predictions.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">model</span><span class="p">:</span> <span class="n">Module</span><span class="p">,</span>
        <span class="n">explainer</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Explainer</span><span class="p">]</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">channel_dim</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">n_steps</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
        <span class="n">baseline_fn</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">BaselineFunction</span><span class="p">]</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">prob_fn</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">Tensor</span><span class="p">]]</span><span class="o">=</span><span class="k">lambda</span> <span class="n">outputs</span><span class="p">:</span> <span class="n">outputs</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">pred_fn</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">Tensor</span><span class="p">]]</span><span class="o">=</span><span class="k">lambda</span> <span class="n">outputs</span><span class="p">:</span> <span class="n">outputs</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">explainer</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">channel_dim</span> <span class="o">=</span> <span class="n">channel_dim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_steps</span> <span class="o">=</span> <span class="n">n_steps</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">baseline_fn</span> <span class="o">=</span> <span class="n">baseline_fn</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prob_fn</span> <span class="o">=</span> <span class="n">prob_fn</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pred_fn</span> <span class="o">=</span> <span class="n">pred_fn</span>

    <span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
    <span class="k">def</span> <span class="nf">evaluate</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">inputs</span><span class="p">:</span> <span class="n">TensorOrTupleOfTensors</span><span class="p">,</span>
        <span class="n">targets</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
        <span class="n">attributions</span><span class="p">:</span> <span class="n">TensorOrTupleOfTensors</span><span class="p">,</span>
        <span class="n">attention_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">TensorOrTupleOfTensors</span><span class="p">]</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">descending</span><span class="p">:</span> <span class="nb">bool</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">],</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">]]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Evaluate the explainer&#39;s correctness based on the attributions by observing changes in model predictions.</span>

<span class="sd">        Args:</span>
<span class="sd">            inputs (TensorOrTupleOfTensors): The input tensors to the model.</span>
<span class="sd">            targets (Tensor): The target labels for the inputs.</span>
<span class="sd">            attributions (TensorOrTupleOfTensors): The attributions for the inputs.</span>
<span class="sd">            attention_mask (Optional[TensorOrTupleOfTensors], optional): Attention masks for the inputs. Default is None.</span>
<span class="sd">            descending (bool, optional): Whether to flip pixels in descending order of attribution. Default is True.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Union[Dict[str, Tensor], Tuple[Dict[str, Tensor]]]: A dictionary or tuple of dictionaries containing</span>
<span class="sd">                the probabilities and predictions at each perturbation step.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">forward_args</span><span class="p">,</span> <span class="n">additional_forward_args</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">explainer</span><span class="o">.</span><span class="n">_extract_forward_args</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
        <span class="n">formatted</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="n">format_into_tuple_all</span><span class="p">(</span>
            <span class="n">forward_args</span><span class="o">=</span><span class="n">forward_args</span><span class="p">,</span>
            <span class="n">additional_forward_args</span><span class="o">=</span><span class="n">additional_forward_args</span><span class="p">,</span>
            <span class="n">attributions</span><span class="o">=</span><span class="n">attributions</span><span class="p">,</span>
            <span class="n">channel_dim</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">channel_dim</span><span class="p">,</span>
            <span class="n">baseline_fn</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">baseline_fn</span><span class="p">,</span>
            <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span> <span class="ow">or</span> <span class="p">(</span><span class="kc">None</span><span class="p">,)</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="n">format_into_tuple</span><span class="p">(</span><span class="n">forward_args</span><span class="p">)),</span>
        <span class="p">)</span>
        <span class="k">assert</span> <span class="nb">all</span><span class="p">(</span>
            <span class="nb">len</span><span class="p">(</span><span class="n">formatted</span><span class="p">[</span><span class="s1">&#39;forward_args&#39;</span><span class="p">])</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">formatted</span><span class="p">[</span><span class="n">k</span><span class="p">])</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">formatted</span>
            <span class="k">if</span> <span class="n">k</span> <span class="o">!=</span> <span class="s1">&#39;additional_forward_args&#39;</span>
        <span class="p">)</span>

        <span class="n">bsz</span> <span class="o">=</span> <span class="n">formatted</span><span class="p">[</span><span class="s1">&#39;forward_args&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span>
            <span class="o">*</span><span class="n">formatted</span><span class="p">[</span><span class="s1">&#39;forward_args&#39;</span><span class="p">],</span>
            <span class="o">*</span><span class="n">formatted</span><span class="p">[</span><span class="s1">&#39;additional_forward_args&#39;</span><span class="p">],</span>
        <span class="p">)</span>
        <span class="n">init_probs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prob_fn</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span>
        <span class="n">init_preds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pred_fn</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">pos</span><span class="p">,</span> <span class="n">forward_arg</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">formatted</span><span class="p">[</span><span class="s1">&#39;forward_args&#39;</span><span class="p">]):</span>
            <span class="n">baseline_fn</span> <span class="o">=</span> <span class="n">formatted</span><span class="p">[</span><span class="s1">&#39;baseline_fn&#39;</span><span class="p">][</span><span class="n">pos</span><span class="p">]</span>
            <span class="n">attrs</span> <span class="o">=</span> <span class="n">formatted</span><span class="p">[</span><span class="s1">&#39;attributions&#39;</span><span class="p">][</span><span class="n">pos</span><span class="p">]</span>
            <span class="n">attrs</span><span class="p">,</span> <span class="n">original_size</span> <span class="o">=</span> <span class="n">_flatten_if_not_1d</span><span class="p">(</span><span class="n">attrs</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">formatted</span><span class="p">[</span><span class="s1">&#39;attention_mask&#39;</span><span class="p">][</span><span class="n">pos</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">attn_mask</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">_flatten_if_not_1d</span><span class="p">(</span><span class="n">formatted</span><span class="p">[</span><span class="s1">&#39;attention_mask&#39;</span><span class="p">][</span><span class="n">pos</span><span class="p">])</span>
                <span class="n">mask_value</span> <span class="o">=</span> <span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">inf</span> <span class="k">if</span> <span class="n">descending</span> <span class="k">else</span> <span class="n">torch</span><span class="o">.</span><span class="n">inf</span>
                <span class="n">attrs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">attn_mask</span> <span class="o">==</span> <span class="mi">1</span><span class="p">,</span> <span class="n">attrs</span><span class="p">,</span> <span class="n">mask_value</span><span class="p">)</span>

            <span class="n">valid_n_features</span> <span class="o">=</span> <span class="p">(</span><span class="o">~</span><span class="n">attrs</span><span class="o">.</span><span class="n">isinf</span><span class="p">())</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">n_flipped_per_step</span> <span class="o">=</span> <span class="n">valid_n_features</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_steps</span>
            <span class="n">n_flipped_per_step</span> <span class="o">=</span> <span class="n">n_flipped_per_step</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="nb">min</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># ensure at least a pixel flipped</span>
            <span class="n">sorted_indices</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span>
                <span class="n">attrs</span><span class="p">,</span>
                <span class="n">descending</span><span class="o">=</span><span class="n">descending</span><span class="p">,</span>
                <span class="n">stable</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">probs</span> <span class="o">=</span> <span class="p">[</span><span class="n">_extract_target_probs</span><span class="p">(</span><span class="n">init_probs</span><span class="p">,</span> <span class="n">targets</span><span class="p">)]</span>
            <span class="n">preds</span> <span class="o">=</span> <span class="p">[</span><span class="n">init_preds</span><span class="p">]</span>
            <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_steps</span><span class="p">):</span>
                <span class="n">n_flipped</span> <span class="o">=</span> <span class="n">n_flipped_per_step</span> <span class="o">*</span> <span class="n">step</span>
                <span class="k">if</span> <span class="n">step</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_steps</span><span class="p">:</span>
                    <span class="n">n_flipped</span> <span class="o">=</span> <span class="n">valid_n_features</span>
                <span class="n">is_index_of_flipped</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="n">F</span><span class="o">.</span><span class="n">one_hot</span><span class="p">(</span><span class="n">n_flipped</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="n">attrs</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
                    <span class="o">.</span><span class="n">flip</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">flip</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
                <span class="p">)</span>
                <span class="n">is_flipped</span> <span class="o">=</span> <span class="n">_sort_by_order</span><span class="p">(</span>
                    <span class="n">is_index_of_flipped</span><span class="p">,</span> <span class="n">sorted_indices</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
                <span class="n">is_flipped</span> <span class="o">=</span> <span class="n">_recover_shape_if_flattened</span><span class="p">(</span><span class="n">is_flipped</span><span class="p">,</span> <span class="n">original_size</span><span class="p">)</span>
                <span class="n">is_flipped</span> <span class="o">=</span> <span class="n">_match_channel_dim_if_pooled</span><span class="p">(</span>
                    <span class="n">is_flipped</span><span class="p">,</span>
                    <span class="n">formatted</span><span class="p">[</span><span class="s1">&#39;channel_dim&#39;</span><span class="p">][</span><span class="n">pos</span><span class="p">],</span>
                    <span class="n">forward_arg</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>
                <span class="p">)</span>

                <span class="n">baseline</span> <span class="o">=</span> <span class="n">baseline_fn</span><span class="p">(</span><span class="n">forward_arg</span><span class="p">)</span>
                <span class="n">flipped_forward_arg</span> <span class="o">=</span> <span class="n">baseline</span> <span class="o">*</span> <span class="n">is_flipped</span> <span class="o">+</span> <span class="n">forward_arg</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">is_flipped</span><span class="p">)</span>

                <span class="n">flipped_forward_args</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span>
                    <span class="n">flipped_forward_arg</span> <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="n">pos</span> <span class="k">else</span> <span class="n">formatted</span><span class="p">[</span><span class="s1">&#39;forward_args&#39;</span><span class="p">][</span><span class="n">i</span><span class="p">]</span>
                    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">formatted</span><span class="p">[</span><span class="s1">&#39;forward_args&#39;</span><span class="p">]))</span>
                <span class="p">)</span>
                <span class="n">flipped_outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span>
                    <span class="o">*</span><span class="n">flipped_forward_args</span><span class="p">,</span>
                    <span class="o">*</span><span class="n">formatted</span><span class="p">[</span><span class="s1">&#39;additional_forward_args&#39;</span><span class="p">],</span>
                <span class="p">)</span>
                <span class="n">probs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">_extract_target_probs</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">prob_fn</span><span class="p">(</span><span class="n">flipped_outputs</span><span class="p">),</span> <span class="n">targets</span><span class="p">))</span>
                <span class="n">preds</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pred_fn</span><span class="p">(</span><span class="n">flipped_outputs</span><span class="p">))</span>
            <span class="n">results</span><span class="o">.</span><span class="n">append</span><span class="p">({</span>
                <span class="s1">&#39;probs&#39;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">probs</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span>
                <span class="s1">&#39;preds&#39;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">preds</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span>
            <span class="p">})</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">results</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">results</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">return</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h3 id="pnpxai.evaluator.metrics.pixel_flipping.PixelFlipping.evaluate" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">evaluate</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">attributions</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">descending</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

      <p>Evaluate the explainer's correctness based on the attributions by observing changes in model predictions.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>inputs</code></td>
            <td>
                  <code><span title="pnpxai.explainers.types.TensorOrTupleOfTensors">TensorOrTupleOfTensors</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The input tensors to the model.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>targets</code></td>
            <td>
                  <code><span title="pnpxai.explainers.types.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The target labels for the inputs.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>attributions</code></td>
            <td>
                  <code><span title="pnpxai.explainers.types.TensorOrTupleOfTensors">TensorOrTupleOfTensors</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The attributions for the inputs.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>attention_mask</code></td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="pnpxai.explainers.types.TensorOrTupleOfTensors">TensorOrTupleOfTensors</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Attention masks for the inputs. Default is None.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>descending</code></td>
            <td>
                  <code>bool</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Whether to flip pixels in descending order of attribution. Default is True.</p>
              </div>
            </td>
            <td>
                  <code>True</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="typing.Union">Union</span>[<span title="typing.Dict">Dict</span>[str, <span title="pnpxai.explainers.types.Tensor">Tensor</span>], <span title="typing.Tuple">Tuple</span>[<span title="typing.Dict">Dict</span>[str, <span title="pnpxai.explainers.types.Tensor">Tensor</span>]]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Union[Dict[str, Tensor], Tuple[Dict[str, Tensor]]]: A dictionary or tuple of dictionaries containing
the probabilities and predictions at each perturbation step.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>pnpxai/evaluator/metrics/pixel_flipping.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 57</span>
<span class="normal"> 58</span>
<span class="normal"> 59</span>
<span class="normal"> 60</span>
<span class="normal"> 61</span>
<span class="normal"> 62</span>
<span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
<span class="k">def</span> <span class="nf">evaluate</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">inputs</span><span class="p">:</span> <span class="n">TensorOrTupleOfTensors</span><span class="p">,</span>
    <span class="n">targets</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
    <span class="n">attributions</span><span class="p">:</span> <span class="n">TensorOrTupleOfTensors</span><span class="p">,</span>
    <span class="n">attention_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">TensorOrTupleOfTensors</span><span class="p">]</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">descending</span><span class="p">:</span> <span class="nb">bool</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">],</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">]]]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Evaluate the explainer&#39;s correctness based on the attributions by observing changes in model predictions.</span>

<span class="sd">    Args:</span>
<span class="sd">        inputs (TensorOrTupleOfTensors): The input tensors to the model.</span>
<span class="sd">        targets (Tensor): The target labels for the inputs.</span>
<span class="sd">        attributions (TensorOrTupleOfTensors): The attributions for the inputs.</span>
<span class="sd">        attention_mask (Optional[TensorOrTupleOfTensors], optional): Attention masks for the inputs. Default is None.</span>
<span class="sd">        descending (bool, optional): Whether to flip pixels in descending order of attribution. Default is True.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Union[Dict[str, Tensor], Tuple[Dict[str, Tensor]]]: A dictionary or tuple of dictionaries containing</span>
<span class="sd">            the probabilities and predictions at each perturbation step.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">forward_args</span><span class="p">,</span> <span class="n">additional_forward_args</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">explainer</span><span class="o">.</span><span class="n">_extract_forward_args</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
    <span class="n">formatted</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="n">format_into_tuple_all</span><span class="p">(</span>
        <span class="n">forward_args</span><span class="o">=</span><span class="n">forward_args</span><span class="p">,</span>
        <span class="n">additional_forward_args</span><span class="o">=</span><span class="n">additional_forward_args</span><span class="p">,</span>
        <span class="n">attributions</span><span class="o">=</span><span class="n">attributions</span><span class="p">,</span>
        <span class="n">channel_dim</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">channel_dim</span><span class="p">,</span>
        <span class="n">baseline_fn</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">baseline_fn</span><span class="p">,</span>
        <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span> <span class="ow">or</span> <span class="p">(</span><span class="kc">None</span><span class="p">,)</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="n">format_into_tuple</span><span class="p">(</span><span class="n">forward_args</span><span class="p">)),</span>
    <span class="p">)</span>
    <span class="k">assert</span> <span class="nb">all</span><span class="p">(</span>
        <span class="nb">len</span><span class="p">(</span><span class="n">formatted</span><span class="p">[</span><span class="s1">&#39;forward_args&#39;</span><span class="p">])</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">formatted</span><span class="p">[</span><span class="n">k</span><span class="p">])</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">formatted</span>
        <span class="k">if</span> <span class="n">k</span> <span class="o">!=</span> <span class="s1">&#39;additional_forward_args&#39;</span>
    <span class="p">)</span>

    <span class="n">bsz</span> <span class="o">=</span> <span class="n">formatted</span><span class="p">[</span><span class="s1">&#39;forward_args&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span>
        <span class="o">*</span><span class="n">formatted</span><span class="p">[</span><span class="s1">&#39;forward_args&#39;</span><span class="p">],</span>
        <span class="o">*</span><span class="n">formatted</span><span class="p">[</span><span class="s1">&#39;additional_forward_args&#39;</span><span class="p">],</span>
    <span class="p">)</span>
    <span class="n">init_probs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prob_fn</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span>
    <span class="n">init_preds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pred_fn</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">pos</span><span class="p">,</span> <span class="n">forward_arg</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">formatted</span><span class="p">[</span><span class="s1">&#39;forward_args&#39;</span><span class="p">]):</span>
        <span class="n">baseline_fn</span> <span class="o">=</span> <span class="n">formatted</span><span class="p">[</span><span class="s1">&#39;baseline_fn&#39;</span><span class="p">][</span><span class="n">pos</span><span class="p">]</span>
        <span class="n">attrs</span> <span class="o">=</span> <span class="n">formatted</span><span class="p">[</span><span class="s1">&#39;attributions&#39;</span><span class="p">][</span><span class="n">pos</span><span class="p">]</span>
        <span class="n">attrs</span><span class="p">,</span> <span class="n">original_size</span> <span class="o">=</span> <span class="n">_flatten_if_not_1d</span><span class="p">(</span><span class="n">attrs</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">formatted</span><span class="p">[</span><span class="s1">&#39;attention_mask&#39;</span><span class="p">][</span><span class="n">pos</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">attn_mask</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">_flatten_if_not_1d</span><span class="p">(</span><span class="n">formatted</span><span class="p">[</span><span class="s1">&#39;attention_mask&#39;</span><span class="p">][</span><span class="n">pos</span><span class="p">])</span>
            <span class="n">mask_value</span> <span class="o">=</span> <span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">inf</span> <span class="k">if</span> <span class="n">descending</span> <span class="k">else</span> <span class="n">torch</span><span class="o">.</span><span class="n">inf</span>
            <span class="n">attrs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">attn_mask</span> <span class="o">==</span> <span class="mi">1</span><span class="p">,</span> <span class="n">attrs</span><span class="p">,</span> <span class="n">mask_value</span><span class="p">)</span>

        <span class="n">valid_n_features</span> <span class="o">=</span> <span class="p">(</span><span class="o">~</span><span class="n">attrs</span><span class="o">.</span><span class="n">isinf</span><span class="p">())</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">n_flipped_per_step</span> <span class="o">=</span> <span class="n">valid_n_features</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_steps</span>
        <span class="n">n_flipped_per_step</span> <span class="o">=</span> <span class="n">n_flipped_per_step</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="nb">min</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># ensure at least a pixel flipped</span>
        <span class="n">sorted_indices</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span>
            <span class="n">attrs</span><span class="p">,</span>
            <span class="n">descending</span><span class="o">=</span><span class="n">descending</span><span class="p">,</span>
            <span class="n">stable</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">probs</span> <span class="o">=</span> <span class="p">[</span><span class="n">_extract_target_probs</span><span class="p">(</span><span class="n">init_probs</span><span class="p">,</span> <span class="n">targets</span><span class="p">)]</span>
        <span class="n">preds</span> <span class="o">=</span> <span class="p">[</span><span class="n">init_preds</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_steps</span><span class="p">):</span>
            <span class="n">n_flipped</span> <span class="o">=</span> <span class="n">n_flipped_per_step</span> <span class="o">*</span> <span class="n">step</span>
            <span class="k">if</span> <span class="n">step</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_steps</span><span class="p">:</span>
                <span class="n">n_flipped</span> <span class="o">=</span> <span class="n">valid_n_features</span>
            <span class="n">is_index_of_flipped</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">F</span><span class="o">.</span><span class="n">one_hot</span><span class="p">(</span><span class="n">n_flipped</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="n">attrs</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
                <span class="o">.</span><span class="n">flip</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">flip</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="n">is_flipped</span> <span class="o">=</span> <span class="n">_sort_by_order</span><span class="p">(</span>
                <span class="n">is_index_of_flipped</span><span class="p">,</span> <span class="n">sorted_indices</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
            <span class="n">is_flipped</span> <span class="o">=</span> <span class="n">_recover_shape_if_flattened</span><span class="p">(</span><span class="n">is_flipped</span><span class="p">,</span> <span class="n">original_size</span><span class="p">)</span>
            <span class="n">is_flipped</span> <span class="o">=</span> <span class="n">_match_channel_dim_if_pooled</span><span class="p">(</span>
                <span class="n">is_flipped</span><span class="p">,</span>
                <span class="n">formatted</span><span class="p">[</span><span class="s1">&#39;channel_dim&#39;</span><span class="p">][</span><span class="n">pos</span><span class="p">],</span>
                <span class="n">forward_arg</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>
            <span class="p">)</span>

            <span class="n">baseline</span> <span class="o">=</span> <span class="n">baseline_fn</span><span class="p">(</span><span class="n">forward_arg</span><span class="p">)</span>
            <span class="n">flipped_forward_arg</span> <span class="o">=</span> <span class="n">baseline</span> <span class="o">*</span> <span class="n">is_flipped</span> <span class="o">+</span> <span class="n">forward_arg</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">is_flipped</span><span class="p">)</span>

            <span class="n">flipped_forward_args</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span>
                <span class="n">flipped_forward_arg</span> <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="n">pos</span> <span class="k">else</span> <span class="n">formatted</span><span class="p">[</span><span class="s1">&#39;forward_args&#39;</span><span class="p">][</span><span class="n">i</span><span class="p">]</span>
                <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">formatted</span><span class="p">[</span><span class="s1">&#39;forward_args&#39;</span><span class="p">]))</span>
            <span class="p">)</span>
            <span class="n">flipped_outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span>
                <span class="o">*</span><span class="n">flipped_forward_args</span><span class="p">,</span>
                <span class="o">*</span><span class="n">formatted</span><span class="p">[</span><span class="s1">&#39;additional_forward_args&#39;</span><span class="p">],</span>
            <span class="p">)</span>
            <span class="n">probs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">_extract_target_probs</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">prob_fn</span><span class="p">(</span><span class="n">flipped_outputs</span><span class="p">),</span> <span class="n">targets</span><span class="p">))</span>
            <span class="n">preds</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pred_fn</span><span class="p">(</span><span class="n">flipped_outputs</span><span class="p">))</span>
        <span class="n">results</span><span class="o">.</span><span class="n">append</span><span class="p">({</span>
            <span class="s1">&#39;probs&#39;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">probs</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span>
            <span class="s1">&#39;preds&#39;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">preds</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span>
        <span class="p">})</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">results</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">results</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">return</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>




  </div>

    </div>

</div>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "../../..", "features": ["navigation.expand"], "search": "../../../assets/javascripts/workers/search.b8dbb3d2.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../../../assets/javascripts/bundle.af256bd8.min.js"></script>
      
    
  </body>
</html>