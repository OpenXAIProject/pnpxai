{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d3813fd-4144-40ec-9743-bdc4516ec248",
   "metadata": {},
   "source": [
    "# Review: Django"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df7d937",
   "metadata": {},
   "source": [
    "Django is a well-known web framework, and I guess the best part of Django is intuitive and object-oriented interfaces on database work. Followings are CRUD examples of `User` objects in Django:\n",
    "\n",
    "```python\n",
    "# create a user\n",
    "user = User.objects.create(name=\"gh\", password=\"1234\")\n",
    "\n",
    "# query all users\n",
    "all_users = User.objects.all()\n",
    "\n",
    "# filter users\n",
    "all_kims = User.objects.filter(name__endswith=\"kim\")\n",
    "\n",
    "# query a user\n",
    "user = User.objects.get(name=\"gh\")\n",
    "\n",
    "# update\n",
    "user.name = \"gkim\"\n",
    "user.save()\n",
    "\n",
    "# delete\n",
    "user.delete()\n",
    "```\n",
    "\n",
    "The point is `objects`, which is a manager to CRUD objects on database table. Actually, a manager is also an API component itself. For example, the only thing to make a *sign-up* API component is wrapping a manager to let it request and response data:\n",
    "\n",
    "```python\n",
    "class SignUp(API):\n",
    "    def post(self, request):\n",
    "        user, created = User.objects.get_or_create(\n",
    "            name = request.data[\"name\"],\n",
    "            password = request.data[\"password\"]\n",
    "        )\n",
    "        if not created:\n",
    "            # if the user already exists\n",
    "            return HTTP.403\n",
    "        return HTTP.201\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d862b2ab-bc09-4016-a314-8d670f7911cf",
   "metadata": {},
   "source": [
    "# Django-like backend for us"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3fb3ef4",
   "metadata": {},
   "source": [
    "I've tried to rearrange our XAI backend workflow to Django one in this demo.\n",
    "\n",
    "The XAI workflow has some key object types:\n",
    "- `Dataset`: A user has a dataset and its subsets (samples) to be explained\n",
    "- `Model`: A user has a model to be explained\n",
    "- `Project`: An object containing multiple datasets (m), multiple models (n), and finally, multiple experiments (m x n)\n",
    "    - What I actually want to do is defining a proj by a \"dataset\" (one-to-one relationship btw a proj and a dataset)\n",
    "    - and then registering multiple (m) dataset-available preprocesses to the proj, instead of multiple datasets\n",
    "    - This is actually what `wandb` or `mlflow` also does (`Preprocess` is one of `Artifact`)\n",
    "    - However, I used `Dataset` instead of `Preprocess`, just for brief sketch and my convenience\n",
    "- `Experiment` (or `Task`): A combination of a single dataset and a single model to be explained\n",
    "- `Explainer`: An object to explain an experiment\n",
    "- `Explanation`: Results from an explainer on an experiment\n",
    "\n",
    "In this demo, I made `Dataset`, `Model`, `Project`, and `Task` (equivalent to `Experiment`) and did not explicitly make `Explainer` and `Explanation`, not yet. All these are one of (dictionary-like) dataclass consisting of its id and configs. Just for simplicity, the only a few configs are included in this demo:\n",
    "- `Dataset`: [`id`, `name`, `uri`, `origin`]\n",
    "- `Model`: [`id`, `name`, `uri`, `origin`]\n",
    "\n",
    "They are working as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ff92c8",
   "metadata": {},
   "source": [
    "## Overview: demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca10d1e0",
   "metadata": {},
   "source": [
    "### Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b480715f-42d9-4f75-a3e6-291f718a95a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pnpxai.client.objects import Dataset, Model, Project, Task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9088d3a",
   "metadata": {},
   "source": [
    "Just for checking how they look like, let's see `Dataset` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9043e82b-8f0e-430e-8bdc-5006e51187dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataset object without writing it in the database\n",
    "dataset = Dataset(name=\"my_dataset\", uri=\"some_uri\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac2bc02d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset:  <Dataset: my_dataset>\n",
      "dataset.id:  None\n",
      "dataset.name:  my_dataset\n",
      "dataset.uri:  some_uri\n"
     ]
    }
   ],
   "source": [
    "print(\"dataset: \", dataset)\n",
    "print(\"dataset.id: \", dataset.id)\n",
    "print(\"dataset.name: \", dataset.name)\n",
    "print(\"dataset.uri: \", dataset.uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6096ea56-fbcc-4995-8410-d42309df7aa4",
   "metadata": {},
   "source": [
    "'to_dict' and 'to_tuple' methods will be helpful. You can find that I've set \"torch\" as a default value for \"origin\" field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e860a1d-3496-4f6e-b27e-08aede934fc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset.to_dict():  {'id': None, 'name': 'my_dataset', 'uri': 'some_uri', 'origin': 'torch'}\n",
      "dataset.to_tuple():  (None, 'my_dataset', 'some_uri', 'torch')\n"
     ]
    }
   ],
   "source": [
    "print(\"dataset.to_dict(): \", dataset.to_dict())\n",
    "print(\"dataset.to_tuple(): \", dataset.to_tuple())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25850723",
   "metadata": {},
   "source": [
    "### ObjectManager"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611b3807-43b2-4369-81d6-9fd87f8a7a0b",
   "metadata": {},
   "source": [
    "Each object has its manager as a classmethod, named with \"objects\". The manager creates, reads, updates and deletes the object on database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2409ca06-2ec9-40e7-be72-8093047a6476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset.objects:  <pnpxai.client.manager.ObjectManager object at 0x7ffa16e9df60>\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset.objects: \", Dataset.objects)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5501140-4cb3-42e2-b200-0e493b317255",
   "metadata": {},
   "source": [
    "The manager's method \"all\" queries all objects in the database. Since we do not create any object yet, no results are queried as followings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e8f0d177-b066-4819-bf65-9cb9a3efabbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset.objects.all():  []\n",
      "Model.objects.all():  []\n",
      "Project.objects.all():  []\n",
      "Task.objects.all():  []\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset.objects.all(): \", Dataset.objects.all())\n",
    "print(\"Model.objects.all(): \", Model.objects.all())\n",
    "print(\"Project.objects.all(): \", Project.objects.all())\n",
    "print(\"Task.objects.all(): \", Task.objects.all())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0669f67",
   "metadata": {},
   "source": [
    "Now, you can find a file store named with \"xaistore\" is created on your current working directory. If you run some methods of the manager, the file store is automatically created and a database file named with \"db.json\" in the store. The database consists of tables for each object types and relationship tables between objects. This database is just a toy for demo and it should be fixed or replaced to more strict one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9144b1ad-0733-422a-ab67-9b142497c01d",
   "metadata": {},
   "source": [
    "## The XAI Workflow in demo\n",
    "\n",
    "Please make sure the outputs from \"setup_for_notebooks.ipynb\" are in your current working directory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4061fb8-bf2e-4ebf-84a5-5e91b523dc3d",
   "metadata": {},
   "source": [
    "### 1. User creates inputs: a dataset and a model\n",
    "\n",
    "User registers his/her own inputs, a dataset and a model, to our system. I suppose that the user has serialized inputs in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994dc97a",
   "metadata": {},
   "source": [
    "#### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2fa960b9-d660-472c-b95b-d7614e4f4c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_uri = os.path.abspath('imagenet_sample.pt')\n",
    "\n",
    "# the method `get_or_create` gets an obj if it exists else creates, and return obj and bool of created\n",
    "dataset, created = Dataset.objects.get_or_create(name=\"first_dataset\", uri=dataset_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3592d1",
   "metadata": {},
   "source": [
    "Now, you can find the dataset obj was written in the database, using the manager."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a07b5205",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Dataset: first_dataset>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dataset.objects.all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1221b0",
   "metadata": {},
   "source": [
    "And the created obj looks like following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "71105e70-4421-4928-8af4-3b1a3789ec0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset:  <Dataset: first_dataset>\n",
      "dataset.id:  0\n",
      "dataset.name:  first_dataset\n",
      "dataset.uri:  /home/gkim/Projects/pnpxai-demo/notebooks/imagenet_sample.pt\n",
      "dataset.origin:  torch\n",
      "dataset.to_dict():  {'id': 0, 'name': 'first_dataset', 'uri': '/home/gkim/Projects/pnpxai-demo/notebooks/imagenet_sample.pt', 'origin': 'torch'}\n",
      "dataset.to_tuple():  (0, 'first_dataset', '/home/gkim/Projects/pnpxai-demo/notebooks/imagenet_sample.pt', 'torch')\n",
      "dataset.load():  <pnpxai.samples.datasets.ImageNetSample object at 0x7ffaf18455d0>\n",
      "created:  True\n"
     ]
    }
   ],
   "source": [
    "print(\"dataset: \", dataset)\n",
    "print(\"dataset.id: \", dataset.id)\n",
    "print(\"dataset.name: \", dataset.name)\n",
    "print(\"dataset.uri: \", dataset.uri)\n",
    "print(\"dataset.origin: \", dataset.origin)\n",
    "print(\"dataset.to_dict(): \", dataset.to_dict())\n",
    "print(\"dataset.to_tuple(): \", dataset.to_tuple())\n",
    "print(\"dataset.load(): \", dataset.load())\n",
    "print(\"created: \", created)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea7b7f9-bb1d-4d07-bbec-fe4bb4b9ed6c",
   "metadata": {},
   "source": [
    "#### Model\n",
    "\n",
    "By the same way, user registers a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a0ea7118-8d84-4af3-8e87-9dda0e2643e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_uri = os.path.abspath('resnet50.pt')\n",
    "model, created = Model.objects.get_or_create(name=\"first_model\", uri=model_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e553605b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Model: first_model>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Model.objects.all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5230aa2d-c163-4145-8ee5-a99d18ba7576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model:  <Model: first_model>\n",
      "model.id:  0\n",
      "model.name:  first_model\n",
      "model.uri:  /home/gkim/Projects/pnpxai-demo/notebooks/resnet50.pt\n",
      "model.origin:  torch\n",
      "model.to_dict():  {'id': 0, 'name': 'first_model', 'uri': '/home/gkim/Projects/pnpxai-demo/notebooks/resnet50.pt', 'origin': 'torch'}\n",
      "model.load():  <class 'torchvision.models.resnet.ResNet'>\n",
      "created:  True\n"
     ]
    }
   ],
   "source": [
    "print(\"model: \", model)\n",
    "print(\"model.id: \", model.id)\n",
    "print(\"model.name: \", model.name)\n",
    "print(\"model.uri: \", model.uri)\n",
    "print(\"model.origin: \", model.origin)\n",
    "print(\"model.to_dict(): \", model.to_dict())\n",
    "print(\"model.load(): \", model.load().__class__)\n",
    "print(\"created: \", created)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a705331c",
   "metadata": {},
   "source": [
    "Additionally, I've tried to make some methods about `ModelDetector` or `ExplainerRecommender` in task object. These methods are implemented in a task method `run_all_applicables` in step 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0b481c59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.is_cam_applicable():  True\n",
      "model.is_lrp_applicable():  True\n"
     ]
    }
   ],
   "source": [
    "print(\"model.is_cam_applicable(): \", model.is_cam_applicable())\n",
    "print(\"model.is_lrp_applicable(): \", model.is_lrp_applicable())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5265751d-fe4c-43b9-8a9f-d06d0c91d41a",
   "metadata": {},
   "source": [
    "### 2. User composites a project based on the registered inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda9ac1b-8b10-47ea-a5ea-b8348240437f",
   "metadata": {},
   "source": [
    "#### Project\n",
    "\n",
    "By the same way in input cases, user creates a project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5b8df7d3-8963-4976-a94c-6adb66cc1635",
   "metadata": {},
   "outputs": [],
   "source": [
    "project, created = Project.objects.get_or_create(name=\"first_project\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "02411791",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Project: first_project>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Project.objects.all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1258950a",
   "metadata": {},
   "source": [
    "Then, we can find empty spaces for datasets and models in the project. A project object has managers for its related datasets and models, which means `project.datasets` and `project.models` are also \"managers\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ff40b1d6-edfa-44be-bbb5-c2ab374976ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "project:  <Project: first_project>\n",
      "project.id:  0\n",
      "project.name:  first_project\n",
      "project.datasets.all():  []\n",
      "project.models.all():  []\n",
      "created:  True\n"
     ]
    }
   ],
   "source": [
    "print(\"project: \", project)\n",
    "print(\"project.id: \", project.id)\n",
    "print(\"project.name: \", project.name)\n",
    "print(\"project.datasets.all(): \", project.datasets.all())\n",
    "print(\"project.models.all(): \", project.models.all())\n",
    "print(\"created: \", created)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd636441-53c5-4f8d-b5f7-17128758419e",
   "metadata": {},
   "source": [
    "#### Add model and dataset to the project\n",
    "\n",
    "User now registers the inputs to the project using `add_dataset` and `add_model` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "efe49f2d-f675-4ced-b5d3-5e4a598c44c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Project: first_project>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project.add_dataset(dataset)\n",
    "project.add_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aae2dcf",
   "metadata": {},
   "source": [
    "Now we can find that the inputs are registered for the project, using the related managers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e190cb1b-4d42-4c28-a660-a946a583c464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "project.datasets.all():  [<Dataset: first_dataset>]\n",
      "project.models.all():  [<Model: first_model>]\n"
     ]
    }
   ],
   "source": [
    "print(\"project.datasets.all(): \", project.datasets.all())\n",
    "print(\"project.models.all(): \", project.models.all())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f539d0e4-cb09-44de-bf5c-b6093327c01b",
   "metadata": {},
   "source": [
    "### 3. User composites tasks (experiments) based on the project inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c76a15",
   "metadata": {},
   "source": [
    "A project has also task manager who controls its related tasks. It is empty not yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ceb16feb-ca46-42a8-83ea-83dd794fa624",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# no tasks written in database not yet\n",
    "project.tasks.all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45ce38d",
   "metadata": {},
   "source": [
    "However, a single possible task can be defined based on the registered inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ecebf275-9707-4d63-99bd-af5b22cc0f8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(<Dataset: first_dataset>, <Model: first_model>)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# but some tasks can be defined based on dataset and model added\n",
    "# in this case, a single task can be defined\n",
    "project.list_all_task_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83124bbc",
   "metadata": {},
   "source": [
    "User registers all possible tasks by using `update_tasks` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c78e78c4-07fb-45f7-93d0-2fa64dd7ec93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on the added, create tasks and diretory for each task\n",
    "project.update_tasks()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22943801",
   "metadata": {},
   "source": [
    "Then, the task is written in the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "53655240-e3c9-4a25-8ff7-3e14c20984d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Task: task_00_00>]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project.tasks.all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6507beda",
   "metadata": {},
   "source": [
    "And user can get the task under the project easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5825d4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = project.tasks.all()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1e15d072",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 0,\n",
       " 'name': 'task_00_00',\n",
       " 'project_id': 0,\n",
       " 'dataset_id': 0,\n",
       " 'model_id': 0}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d57acdb-5bf3-40fd-b23c-6b3d3f25dd38",
   "metadata": {},
   "source": [
    "### 4. Explain\n",
    "\n",
    "Finally, user gets explanations by all possible explainers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8af79289-b2c3-487e-a14e-1cc75f40b617",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gkim/Projects/pnpxai-demo/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# set common inputs for explainers\n",
    "x_batch, y_batch = dataset.load_random_samples(n_samples=16)\n",
    "p_batch = model.load()(x_batch).argmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f29733bb-b986-46bc-b003-9208971060e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running GradCAM:  58%|█████▊    | 7/12 [01:27<01:06, 13.27s/it]                  /home/gkim/Projects/pnpxai-demo/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "Running LayerCAM: 100%|██████████| 12/12 [01:51<00:00,  9.25s/it]       \n"
     ]
    }
   ],
   "source": [
    "# get all applicable explanations\n",
    "explanations = task.run_all_applicables(x_batch, p_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4228f91a",
   "metadata": {},
   "source": [
    "Now, we can find the results are logged in \"./xaistore\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88e382e",
   "metadata": {},
   "source": [
    "### 5. API (future works)\n",
    "\n",
    "All workflows can be consistently converted to API components using the objects and their managers. For example, a project API in `Flask` may look like\n",
    "\n",
    "```python\n",
    "from flask_restx import Resource, Api\n",
    "\n",
    "app = Flask(__name__)\n",
    "api = Api(app)\n",
    "\n",
    "@api.route(\"/api/projects\")\n",
    "class ProjectPost(Resource):\n",
    "    def post(self):\n",
    "        proj, created = Projects.objects.get_or_create(name=request.json.get(\"data\"))\n",
    "        if created:\n",
    "            return Response(proj.to_json(), status=201)\n",
    "        return Response(status=403)\n",
    "\n",
    "@api.route(\"/api/projects/<int:proj_id>\")\n",
    "class Projects(Resource):\n",
    "    def get_obj(self, proj_id):\n",
    "        proj = Project.objects.get(id=proj_id)\n",
    "        if proj:\n",
    "            return proj\n",
    "        return Response(status=403)\n",
    "\n",
    "    def get(self, proj_id):\n",
    "        proj = self.get_obj(proj_id=proj_id)\n",
    "        return Response(proj.to_json(), status=200)\n",
    "    \n",
    "    def put(self, proj_id):\n",
    "        proj = self.get_obj(proj_id=proj_id)\n",
    "        proj.name = request.json.get(\"data\")\n",
    "        proj.save()\n",
    "        return Response(proj.to_json(), status=204)\n",
    "    \n",
    "    def delete(self, proj_id):\n",
    "        proj = self.get_obj(proj_id=proj_id)\n",
    "        proj.delete()\n",
    "        return Response(status=204)\n",
    "\n",
    "# ...\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
