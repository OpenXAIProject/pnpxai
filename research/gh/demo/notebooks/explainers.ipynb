{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50aeda1c-235f-4d58-bdb8-72aab0c0e331",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Please make sure you have outputs from 'setup_for_notebooks.ipynb' on your current directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9392539-dde0-4c3b-8f6e-fb449a1107e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gkim/Projects/pnpxai-demo/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "model = torch.load(\"resnet50.pt\").eval()\n",
    "dataset = torch.load(\"imagenet_sample.pt\")\n",
    "dataloader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
    "x_batch, y_batch = next(iter(dataloader))\n",
    "p_batch = model(x_batch).argmax(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbac7bba-6f52-42d0-a124-a1e708be0fb9",
   "metadata": {},
   "source": [
    "Now we have 16 samples to be explained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62bf3bc4-c91f-4965-96b9-c9c5ecdcefed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_batch.shape torch.Size([16, 3, 224, 224])\n",
      "y_batch.shape torch.Size([16])\n",
      "p_batch.shape torch.Size([16])\n"
     ]
    }
   ],
   "source": [
    "print(\"x_batch.shape\", x_batch.shape)\n",
    "print(\"y_batch.shape\", y_batch.shape)\n",
    "print(\"p_batch.shape\", p_batch.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0b6845-e0e5-4db4-b033-992cbb7ca46c",
   "metadata": {},
   "source": [
    "## Explain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7f9cfb",
   "metadata": {},
   "source": [
    "In this demo, I've tried to design `ExplainerInterface` to be initialized with untunable parameters and run explanation with tunable parameters. I guess this should be replaced to a wrapper one without constraints on input params because this design unecessarily restricts user's customizability. By the way, let's see how the explainers in this demo work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0dcfb3e-2ef9-4e71-9058-fbf3881aa7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pnpxai.core.explainers.lrp import LRPEpsilonPlus\n",
    "from pnpxai.core.explainers.gradcam import GradCAMpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a88e2fc7-0c07-48de-a9ca-87eeea168d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lrp epsilon plus\n",
    "explainer = LRPEpsilonPlus(model=model)\n",
    "\n",
    "a_batch_lrpep_default = explainer.attribute(x_batch, p_batch) # default\n",
    "a_batch_lrpep = explainer.attribute(x_batch, p_batch, epsilon=.5) # set tunable parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "daef7797-2d81-4eaa-b557-d2b1f69d203c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:no value was provided for `target_layer`, thus set to 'layer4'.\n",
      "/home/gkim/Projects/pnpxai-demo/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# gradcampp\n",
    "explainer = GradCAMpp(model=model)\n",
    "a_batch_gcampp_default = explainer.attribute(inputs=x_batch, targets=p_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c1acef-0ea5-44ae-b596-4307704eac6c",
   "metadata": {},
   "source": [
    "I set the target layer as an untunable parameter for explainer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68dbef8f-6538-4ae1-ab2b-e1057bb702f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = GradCAMpp(model=model, target_layer=\"layer4\")\n",
    "a_batch_gcampp_tl = explainer.attribute(inputs=x_batch, targets=p_batch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
