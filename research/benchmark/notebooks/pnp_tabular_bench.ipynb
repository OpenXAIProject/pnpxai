{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 다양한 framework에서의 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os; os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cwl/miniconda3/envs/pnpenv/lib/python3.10/site-packages/xgboost/core.py:265: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc 2.28+) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import functools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Framework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenXAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from openxai.dataloader import ReturnLoaders\n",
    "from openxai import LoadModel\n",
    "from openxai import Explainer\n",
    "from openxai.experiment_utils import fill_param_dict\n",
    "from openxai.model import ArtificialNeuralNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explainers_dict = {\n",
    "#     'grad': Gradient,\n",
    "#     'sg': SmoothGrad,\n",
    "#     'itg': InputTimesGradient,\n",
    "#     'ig': IntegratedGradients,\n",
    "#     'shap': SHAPExplainerC,\n",
    "#     'lime': LIME,\n",
    "#     'control': RandomBaseline\n",
    "# }\n",
    "\n",
    "# loader_train, loader_test = ReturnLoaders(data_name='german', download=True)\n",
    "# # get an input instance from the test dataset\n",
    "# inputs, labels = next(iter(loader_test))\n",
    "\n",
    "# model = LoadModel(data_name= 'german', ml_model='ann', pretrained=True)\n",
    "# X_train = torch.tensor([d[0] for d in loader_train.dataset])\n",
    "\n",
    "# param_dict = fill_param_dict('lime', {}, X_train)\n",
    "# exp_method = Explainer(method='lime', model=model, param_dict=param_dict)\n",
    "# explanations= exp_method.get_explanations(inputs, label=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_nm = \"Adult\"\n",
    "X_train = np.load(f\"data/{dataset_nm}/X_train.npy\")\n",
    "y_train = np.load(f\"data/{dataset_nm}/y_train.npy\")\n",
    "\n",
    "X_test = np.load(f\"data/{dataset_nm}/X_test.npy\")\n",
    "y_test = np.load(f\"data/{dataset_nm}/y_test.npy\")\n",
    "\n",
    "feature_metadata = pickle.load(open(f\"data/{dataset_nm}/feature_metadata.pkl\", \"rb\"))\n",
    "\n",
    "model = ArtificialNeuralNetwork(input_dim=X_test.shape[1], hidden_layers=[100,100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = torch.tensor(X_train, dtype=torch.float32)\n",
    "input_data = torch.tensor(X_test, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_dict = fill_param_dict('lime', {}, train_data)\n",
    "# exp_method = Explainer(method='lime', model=model, param_dict=param_dict)\n",
    "\n",
    "# exp_method = Explainer(method='grad', model=model)\n",
    "# exp_method = Explainer(method='sg', model=model)\n",
    "# exp_method = Explainer(method='itg', model=model)\n",
    "\n",
    "# param_dict = fill_param_dict('ig', {}, train_data)\n",
    "# exp_method = Explainer(method='ig', model=model, param_dict=param_dict)\n",
    "\n",
    "\n",
    "exp_method = Explainer(method='shap', model=model)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 111])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model(input_data).detach().argmax(dim=1)\n",
    "total_exp = []\n",
    "dataset = TensorDataset(input_data, y_pred)\n",
    "loader = DataLoader(dataset, batch_size=10)\n",
    "for inputs, labels in loader:\n",
    "    explanations= exp_method.get_explanations(inputs, label=labels)\n",
    "    total_exp.append(explanations)\n",
    "    break\n",
    "\n",
    "explanations = torch.cat(total_exp, dim=0)\n",
    "explanations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 14])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_metadata\n",
    "\n",
    "_exp = []\n",
    "for nm, info in feature_metadata.items():\n",
    "    if info['type'] == 'categorical':\n",
    "        idx = info['index']\n",
    "        onehot = input_data[:10, idx]\n",
    "        val = explanations[:, idx]\n",
    "        cat_exp = (onehot * val).sum(dim=1)\n",
    "        _exp.append(cat_exp)\n",
    "    else:\n",
    "        _exp.append(explanations[:, info['index']])\n",
    "\n",
    "exp = torch.stack(_exp, dim=1)\n",
    "exp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3.7067e-03, -6.2093e-03, -1.7211e-03, -6.9594e-04,  3.8262e-04,\n",
       "          1.6946e-04, -6.6975e-04,  5.7893e-04, -8.1775e-04, -8.0424e-04,\n",
       "          4.6599e-04,  2.4125e-04,  1.9976e-04, -3.9700e-03],\n",
       "        [-4.3620e-03,  3.2987e-03,  1.5954e-03, -1.5827e-03,  1.3526e-03,\n",
       "         -1.8663e-03, -7.3954e-04, -2.4865e-03, -1.1802e-03,  1.9820e-03,\n",
       "         -3.5694e-04, -3.7238e-05,  5.9745e-04, -2.3326e-03],\n",
       "        [ 7.2948e-03,  1.5306e-04, -3.1804e-05,  8.6214e-05, -4.7309e-05,\n",
       "         -4.4448e-04,  1.8585e-03,  2.8437e-03, -3.4996e-04,  1.4028e-03,\n",
       "         -3.5091e-04,  2.0247e-04,  9.6643e-05, -2.3110e-03],\n",
       "        [ 8.5133e-04, -6.5700e-03, -1.1147e-03, -1.2950e-03, -7.8500e-05,\n",
       "          2.2973e-03, -5.1395e-04,  4.6578e-03, -1.3155e-03, -1.7015e-03,\n",
       "          1.0156e-04,  3.6321e-04, -1.1688e-04, -3.4267e-03],\n",
       "        [-4.9224e-04,  1.3795e-03,  8.7882e-04, -8.4938e-04,  1.4198e-04,\n",
       "          8.6840e-04,  1.8120e-03,  3.8192e-03,  1.7027e-03,  9.9984e-04,\n",
       "         -7.3003e-04,  1.1339e-04, -4.6058e-04, -3.1369e-03],\n",
       "        [ 3.4884e-03, -6.6009e-03, -1.0712e-04, -2.0186e-03,  4.3969e-04,\n",
       "          1.1950e-03,  1.4649e-03,  2.1984e-05,  2.8078e-03,  6.6468e-04,\n",
       "         -2.5591e-04,  2.5968e-04,  2.3459e-04, -2.0407e-03],\n",
       "        [-1.0040e-03,  2.7396e-03, -1.4150e-03,  4.0671e-03, -1.6836e-03,\n",
       "          1.0407e-03,  3.6487e-03,  2.7885e-03, -7.7993e-04,  1.5291e-03,\n",
       "         -7.6247e-04,  4.6092e-04, -3.9240e-03, -3.3392e-03],\n",
       "        [ 1.7380e-03, -5.9074e-03,  1.4052e-03, -3.8322e-04, -4.2855e-04,\n",
       "         -2.9504e-04, -1.2715e-03, -2.1535e-03, -9.3990e-04,  1.6524e-03,\n",
       "          1.1854e-05,  6.1930e-05, -5.5800e-05, -2.6152e-03],\n",
       "        [ 1.9445e-03, -6.6321e-03, -3.4607e-04, -9.4780e-04,  4.4004e-04,\n",
       "          2.3160e-03,  3.3592e-04,  3.0815e-03, -4.1009e-04, -1.3385e-03,\n",
       "         -1.7170e-04,  4.9107e-05, -2.2643e-06, -3.9729e-03],\n",
       "        [ 8.0915e-04, -5.3413e-03,  3.8066e-03, -1.8587e-03, -5.0314e-04,\n",
       "          9.6873e-04,  2.2051e-03,  4.6785e-03, -3.9506e-04, -3.6505e-04,\n",
       "         -6.4158e-04,  1.3363e-04,  2.1392e-04, -3.3463e-03]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(openxai.model.ArtificialNeuralNetwork,\n",
       " torch.Tensor,\n",
       " torch.Tensor,\n",
       " torch.Tensor,\n",
       " torch.Size([32, 60]),\n",
       " torch.Size([32]),\n",
       " torch.int64,\n",
       " torch.utils.data.dataloader.DataLoader)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model), type(inputs), type(labels), type(explanations), inputs.shape, labels.shape, labels.dtype, type(loader_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5909, 0.1146, 1.0000, 0.3333, 0.2000, 0.0000, 0.0000, 0.0000, 1.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        1.0000, 0.0000, 0.0000, 0.0000, 1.0000, 1.0000, 0.0000, 0.0000, 0.0000,\n",
       "        1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000,\n",
       "        0.0000, 0.0000, 0.0000, 1.0000, 1.0000, 0.0000], dtype=torch.float64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OmniXAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-13 14:48:57.608476: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-13 14:48:59.146516: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1741844939.815529   30461 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1741844939.977498   30461 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-13 14:49:01.687092: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from omnixai.data.tabular import Tabular\n",
    "from omnixai.preprocessing.tabular import TabularTransform\n",
    "from omnixai.explainers.tabular import TabularExplainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_nm = \"Adult\"\n",
    "X_train = np.load(f\"data/{dataset_nm}/X_train.npy\")\n",
    "y_train = np.load(f\"data/{dataset_nm}/y_train.npy\")\n",
    "\n",
    "X_test = np.load(f\"data/{dataset_nm}/X_test.npy\")\n",
    "y_test = np.load(f\"data/{dataset_nm}/y_test.npy\")\n",
    "\n",
    "feature_metadata = pickle.load(open(f\"data/{dataset_nm}/feature_metadata.pkl\", \"rb\"))\n",
    "raw_data = pd.read_csv(f\"data/{dataset_nm}/raw_data.csv\")\n",
    "\n",
    "\n",
    "xgb_model = xgb.XGBClassifier()\n",
    "xgb_model.load_model(f\"data/{dataset_nm}/xgb_model.json\")\n",
    "\n",
    "nn_model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(X_train.shape[1], 3),\n",
    "    torch.nn.Softmax(dim=1)\n",
    ")\n",
    "\n",
    "train_data = Tabular(raw_data, categorical_columns=[c for c in raw_data.columns if feature_metadata[c][\"type\"] == \"categorical\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _transform(X, feature_metadata):\n",
    "    input_data = []\n",
    "    for k, v in feature_metadata.items():\n",
    "        preprocessed = v['encoder'].transform(X[[k]].values)\n",
    "        if v['type'] == 'categorical':\n",
    "            preprocessed = preprocessed.toarray()\n",
    "        input_data.append(preprocessed)\n",
    "    \n",
    "    input_array = np.concatenate(input_data, axis=1)\n",
    "    return input_array\n",
    "\n",
    "def _invert_input_array(input_array, feature_metadata):\n",
    "    inverted_data = {}\n",
    "    \n",
    "    for col, meta in feature_metadata.items():\n",
    "        if meta['type'] == 'categorical':\n",
    "            # One-hot encoded 된 부분 추출\n",
    "            start_idx, end_idx = meta['index'][0], meta['index'][-1] + 1\n",
    "            cat_data = input_array[:, start_idx:end_idx]\n",
    "            # OneHotEncoder로 복원\n",
    "            inverted_col = meta['encoder'].inverse_transform(cat_data)\n",
    "            inverted_data[col] = inverted_col.flatten()\n",
    "        else:\n",
    "            # 수치형 데이터 복원\n",
    "            idx = meta['index']\n",
    "            num_data = input_array[:, idx].reshape(-1, 1)\n",
    "            inverted_col = meta['encoder'].inverse_transform(num_data)\n",
    "            inverted_data[col] = inverted_col.flatten()\n",
    "    \n",
    "    # 복원된 데이터를 DataFrame으로 변환\n",
    "    inverted_df = pd.DataFrame(inverted_data)\n",
    "    \n",
    "    return inverted_df\n",
    "        \n",
    "transform = functools.partial(_transform, feature_metadata=feature_metadata)\n",
    "invert_input_array = functools.partial(_invert_input_array, feature_metadata=feature_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = transform(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = TabularExplainer(\n",
    "  explainers=[\"LimeTabular\", \"ShapTabular\", \"lime\", \"shap\"], # The explainers to apply\n",
    "  mode=\"classification\",                             # The task type\n",
    "  data=train_data,\n",
    "  model=xgb_model.predict_proba,                                     # The ML model to explain\n",
    "  preprocess=lambda z: transform(z.data)\n",
    ")\n",
    "\n",
    "nn_explainer = TabularExplainer(\n",
    "  # explainers=[\"LimeTabular\", \"ShapTabular\", \"ig\"], # The explainers to apply\n",
    "  explainers=[\"LimeTabular\", \"ShapTabular\"], # The explainers to apply\n",
    "  mode=\"classification\",                             # The task type\n",
    "  data=train_data,\n",
    "  model=nn_model,                                       # The ML model to explain\n",
    "  preprocess=lambda z: torch.tensor(transform(z.data), dtype=torch.float32)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "396d565204bb409590f5cc6fb5992f92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff9181e6d68246a7af9352cdda0d6114",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1fcbf2d6f4e40678e4ebd61c515f656",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_instances = invert_input_array(X_test[:10])\n",
    "\n",
    "explanations = explainer.explain(test_instances)\n",
    "nn_explanations = nn_explainer.explain(test_instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['capital-gain',\n",
       "  'marital-status',\n",
       "  'capital-loss',\n",
       "  'hours-per-week',\n",
       "  'occupation',\n",
       "  'age',\n",
       "  'sex',\n",
       "  'native-country',\n",
       "  'fnlwgt',\n",
       "  'education-num'],\n",
       " [-0.6916381338688814,\n",
       "  0.12350883830059717,\n",
       "  -0.07013317629306902,\n",
       "  0.05951879371883744,\n",
       "  0.05440253382722002,\n",
       "  0.04146769210204393,\n",
       "  0.025463251237053054,\n",
       "  0.014590300825607144,\n",
       "  0.012842448468914323,\n",
       "  0.01055183746359225])"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = 4\n",
    "# explanations['LimeTabular'].get_explanations(idx)['features'], explanations['LimeTabular'].get_explanations(idx)['scores']\n",
    "# explanations['ShapTabular'].get_explanations(idx)['features'], explanations['ShapTabular'].get_explanations(idx)['scores']\n",
    "explanations['lime'].get_explanations(idx)['features'], explanations['lime'].get_explanations(idx)['scores']\n",
    "# explanations['shap'].get_explanations(idx)['features'], explanations['shap'].get_explanations(idx)['scores']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['capital-gain',\n",
       "  'capital-loss',\n",
       "  'hours-per-week',\n",
       "  'age',\n",
       "  'marital-status',\n",
       "  'native-country',\n",
       "  'sex',\n",
       "  'fnlwgt',\n",
       "  'race',\n",
       "  'occupation'],\n",
       " [0.7146692980670353,\n",
       "  0.09948085944391453,\n",
       "  0.09032331528379359,\n",
       "  -0.059015724128280496,\n",
       "  0.05270170754617013,\n",
       "  -0.029825946975223127,\n",
       "  -0.019937145021878502,\n",
       "  0.019450162959702547,\n",
       "  -0.016697319733481562,\n",
       "  0.01373394956749946])"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explanations['LimeTabular'].get_explanations(1)['features'], explanations['LimeTabular'].get_explanations(1)['scores']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['instance', 'features', 'values', 'scores', 'target_label'])"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explanations['LimeTabular'].get_explanations(0).keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'age': {'type': 'numerical', 'encoder': StandardScaler(), 'index': 0},\n",
       " 'workclass': {'type': 'categorical',\n",
       "  'encoder': OneHotEncoder(),\n",
       "  'cat_dist': array([3.75905983e-02, 2.93190287e-02, 6.42070349e-02, 2.04741821e-04,\n",
       "         6.94197617e-01, 3.47037386e-02, 7.90712911e-02, 4.05593547e-02,\n",
       "         4.29957823e-04, 1.97166373e-02]),\n",
       "  'index': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])},\n",
       " 'fnlwgt': {'type': 'numerical', 'encoder': StandardScaler(), 'index': 11},\n",
       " 'education': {'type': 'categorical',\n",
       "  'encoder': OneHotEncoder(),\n",
       "  'cat_dist': array([0.02843864, 0.03709922, 0.01345154, 0.00505712, 0.01042136,\n",
       "         0.01955284, 0.01547848, 0.03277917, 0.04219729, 0.16430531,\n",
       "         0.01216166, 0.32316449, 0.0543999 , 0.00169936, 0.01707547,\n",
       "         0.22271815]),\n",
       "  'index': array([12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27])},\n",
       " 'education-num': {'type': 'numerical',\n",
       "  'encoder': StandardScaler(),\n",
       "  'index': 28},\n",
       " 'marital-status': {'type': 'categorical',\n",
       "  'encoder': OneHotEncoder(),\n",
       "  'cat_dist': array([0.13580525, 0.00075754, 0.45819172, 0.01285779, 0.32998239,\n",
       "         0.0313255 , 0.03107981]),\n",
       "  'index': array([29, 30, 31, 32, 33, 34, 35])},\n",
       " 'occupation': {'type': 'categorical',\n",
       "  'encoder': OneHotEncoder(),\n",
       "  'cat_dist': array([0.03773392, 0.11488064, 0.00030711, 0.1251382 , 0.12460587,\n",
       "         0.03050653, 0.04242251, 0.06187298, 0.1007944 , 0.00495475,\n",
       "         0.12636665, 0.02012612, 0.1126899 , 0.02960567, 0.0482167 ,\n",
       "         0.01977806]),\n",
       "  'index': array([36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51])},\n",
       " 'relationship': {'type': 'categorical',\n",
       "  'encoder': OneHotEncoder(),\n",
       "  'cat_dist': array([0.40366897, 0.25762663, 0.03083412, 0.15521477, 0.10493018,\n",
       "         0.04772532]),\n",
       "  'index': array([52, 53, 54, 55, 56, 57])},\n",
       " 'race': {'type': 'categorical',\n",
       "  'encoder': OneHotEncoder(),\n",
       "  'cat_dist': array([0.00962287, 0.03110028, 0.09592154, 0.00831252, 0.85504279]),\n",
       "  'index': array([58, 59, 60, 61, 62])},\n",
       " 'sex': {'type': 'categorical',\n",
       "  'encoder': OneHotEncoder(),\n",
       "  'cat_dist': array([0.33151796, 0.66848204]),\n",
       "  'index': array([63, 64])},\n",
       " 'capital-gain': {'type': 'numerical',\n",
       "  'encoder': StandardScaler(),\n",
       "  'index': 65},\n",
       " 'capital-loss': {'type': 'numerical',\n",
       "  'encoder': StandardScaler(),\n",
       "  'index': 66},\n",
       " 'hours-per-week': {'type': 'numerical',\n",
       "  'encoder': StandardScaler(),\n",
       "  'index': 67},\n",
       " 'native-country': {'type': 'categorical',\n",
       "  'encoder': OneHotEncoder(),\n",
       "  'cat_dist': array([1.19364481e-02, 5.73277098e-04, 3.72630113e-03, 2.49785021e-03,\n",
       "         1.74030547e-03, 2.82543712e-03, 2.10884075e-03, 9.21338193e-04,\n",
       "         3.17349822e-03, 2.60022112e-03, 7.78018918e-04, 4.21768150e-03,\n",
       "         1.00323492e-03, 1.80172802e-03, 1.53556365e-03, 2.04741821e-05,\n",
       "         4.09483641e-04, 6.14225462e-04, 3.89009459e-04, 3.09160149e-03,\n",
       "         1.20797674e-03, 7.57544736e-04, 2.14978912e-03, 2.17026330e-03,\n",
       "         1.88362475e-03, 4.70906187e-04, 1.94709471e-02, 1.00323492e-03,\n",
       "         4.70906187e-04, 9.41812375e-04, 6.03988371e-03, 1.78125384e-03,\n",
       "         1.37177020e-03, 3.76724950e-03, 4.29957823e-04, 2.35453094e-03,\n",
       "         1.33082183e-03, 6.14225462e-04, 5.52802916e-04, 8.97424348e-01,\n",
       "         1.76077966e-03, 4.70906187e-04, 5.60992588e-03]),\n",
       "  'index': array([ 68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,\n",
       "          81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,  93,\n",
       "          94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106,\n",
       "         107, 108, 109, 110])}}"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'workclass', 'fnlwgt', 'education', 'education-num',\n",
       "       'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
       "       'capital-gain', 'capital-loss', 'hours-per-week', 'native-country'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cwl/miniconda3/envs/pnpenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1511: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "feature_names = [\n",
    "   \"Age\", \"Workclass\", \"fnlwgt\", \"Education\",\n",
    "   \"Education-Num\", \"Marital Status\", \"Occupation\",\n",
    "   \"Relationship\", \"Race\", \"Sex\", \"Capital Gain\",\n",
    "   \"Capital Loss\", \"Hours per week\", \"Country\", \"label\"\n",
    "]\n",
    "df = pd.DataFrame(\n",
    "  np.genfromtxt('adult.data', delimiter=', ', dtype=str),\n",
    "  columns=feature_names\n",
    ")\n",
    "tabular_data = Tabular(\n",
    "   df,\n",
    "   categorical_columns=[feature_names[i] for i in [1, 3, 5, 6, 7, 8, 9, 13]],\n",
    "   target_column='label'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32561, 15), (32561, 109))"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer = TabularTransform().fit(tabular_data)\n",
    "class_names = transformer.class_names\n",
    "x = transformer.transform(tabular_data)\n",
    "\n",
    "df.shape, x.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from omnixai.preprocessing.tabular import TabularTransform\n",
    "# Data preprocessing\n",
    "transformer = TabularTransform().fit(tabular_data)\n",
    "class_names = transformer.class_names\n",
    "x = transformer.transform(tabular_data)\n",
    "# Split into training and test datasets\n",
    "train, test, train_labels, test_labels = \\\n",
    "    train_test_split(x[:, :-1], x[:, -1], train_size=0.80)\n",
    "# Train an XGBoost model (the last column of `x` is the label column after transformation)\n",
    "model = xgboost.XGBClassifier(n_estimators=300, max_depth=5)\n",
    "model.fit(train, train_labels)\n",
    "# Convert the transformed data back to Tabular instances\n",
    "train_data = transformer.invert(train)\n",
    "test_data = transformer.invert(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.000e+00, 1.000e+00, 0.000e+00, ..., 0.000e+00, 0.000e+00,\n",
       "         6.000e+01],\n",
       "        [0.000e+00, 0.000e+00, 0.000e+00, ..., 0.000e+00, 0.000e+00,\n",
       "         5.000e+01],\n",
       "        [0.000e+00, 0.000e+00, 0.000e+00, ..., 0.000e+00, 0.000e+00,\n",
       "         4.000e+01],\n",
       "        ...,\n",
       "        [1.000e+00, 0.000e+00, 0.000e+00, ..., 7.688e+03, 0.000e+00,\n",
       "         5.000e+01],\n",
       "        [0.000e+00, 0.000e+00, 0.000e+00, ..., 0.000e+00, 0.000e+00,\n",
       "         5.000e+01],\n",
       "        [0.000e+00, 0.000e+00, 0.000e+00, ..., 0.000e+00, 0.000e+00,\n",
       "         4.000e+01]]),\n",
       " (26048, 108))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Explainer aaa is not found. Please choose explainers from dict_keys(['LimeTabular', 'ShapTabular', 'PartialDependenceTabular', 'ALE', 'SensitivityAnalysisTabular', 'L2XTabular', 'PermutationImportance', 'GlobalShapTabular', 'BiasAnalyzer', 'MACEExplainer', 'GPTExplainer', 'CounterfactualExplainer', 'KNNCounterfactualExplainer', 'IntegratedGradientTabular', 'LinearRegression', 'LogisticRegression', 'TreeRegressor', 'TreeClassifier', 'ShapTreeTabular', 'lime', 'shap', 'pdp', 'partial_dependence', 'ale', 'accumulated_local_effects', 'sa', 'sensitivity', 'l2x', 'L2X', 'permutation', 'shap_global', 'bias', 'mace', 'gpt', 'ce', 'counterfactual', 'ce_knn', 'knn_ce', 'ig', 'integrated_gradient', 'linear_regression', 'logistic_regression', 'tree_regressor', 'tree_classifier', 'shap_tree'])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01momnixai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexplainers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtabular\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TabularExplainer\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Initialize a TabularExplainer\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m explainer \u001b[38;5;241m=\u001b[39m \u001b[43mTabularExplainer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m  \u001b[49m\u001b[43mexplainers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlime\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshap\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmace\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpdp\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43male\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maaa\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# The explainers to apply\u001b[39;49;00m\n\u001b[1;32m      5\u001b[0m \u001b[43m  \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mclassification\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m                             \u001b[49m\u001b[38;5;66;43;03m# The task type\u001b[39;49;00m\n\u001b[1;32m      6\u001b[0m \u001b[43m  \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m                                   \u001b[49m\u001b[38;5;66;43;03m# The data for initializing the explainers\u001b[39;49;00m\n\u001b[1;32m      7\u001b[0m \u001b[43m  \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m                                       \u001b[49m\u001b[38;5;66;43;03m# The ML model to explain\u001b[39;49;00m\n\u001b[1;32m      8\u001b[0m \u001b[43m  \u001b[49m\u001b[43mpreprocess\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mz\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m     \u001b[49m\u001b[38;5;66;43;03m# Converts raw features into the model inputs\u001b[39;49;00m\n\u001b[1;32m      9\u001b[0m \u001b[43m  \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m     \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmace\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mignored_features\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSex\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mRace\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mRelationship\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCapital Loss\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m  \u001b[49m\u001b[43m}\u001b[49m\u001b[43m                                                  \u001b[49m\u001b[38;5;66;43;03m# Additional parameters\u001b[39;49;00m\n\u001b[1;32m     12\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pnpenv/lib/python3.10/site-packages/omnixai/explainers/tabular/auto.py:68\u001b[0m, in \u001b[0;36mTabularExplainer.__init__\u001b[0;34m(self, explainers, mode, data, model, preprocess, postprocess, params)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     43\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     44\u001b[0m         explainers: Collection,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     50\u001b[0m         params: Dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     51\u001b[0m ):\n\u001b[1;32m     52\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;124;03m    :param explainers: The names or alias of the explainers to use.\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;124;03m    :param mode: The task type, e.g. `classification` or `regression`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;124;03m        e.g., `params[\"lime\"] = {\"param_1\": param_1, ...}`.\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 68\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexplainers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexplainers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreprocess\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreprocess\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpostprocess\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpostprocess\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     78\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_info \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     79\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategorical_columns\u001b[39m\u001b[38;5;124m\"\u001b[39m: data\u001b[38;5;241m.\u001b[39mcategorical_columns,\n\u001b[1;32m     80\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget_column\u001b[39m\u001b[38;5;124m\"\u001b[39m: data\u001b[38;5;241m.\u001b[39mtarget_column,\n\u001b[1;32m     81\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeature_columns\u001b[39m\u001b[38;5;124m\"\u001b[39m: data\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[1;32m     82\u001b[0m         }\n",
      "File \u001b[0;32m~/miniconda3/envs/pnpenv/lib/python3.10/site-packages/omnixai/explainers/base.py:154\u001b[0m, in \u001b[0;36mAutoExplainerBase.__init__\u001b[0;34m(self, explainers, mode, data, model, preprocess, postprocess, params)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m explainers:\n\u001b[1;32m    152\u001b[0m     name \u001b[38;5;241m=\u001b[39m name\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    153\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[0;32m--> 154\u001b[0m         name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_NAME_TO_CLASS\n\u001b[1;32m    155\u001b[0m     ), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExplainer \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not found. Please choose explainers from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_NAME_TO_CLASS\u001b[38;5;241m.\u001b[39mkeys()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnames \u001b[38;5;241m=\u001b[39m explainers\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m=\u001b[39m mode\n",
      "\u001b[0;31mAssertionError\u001b[0m: Explainer aaa is not found. Please choose explainers from dict_keys(['LimeTabular', 'ShapTabular', 'PartialDependenceTabular', 'ALE', 'SensitivityAnalysisTabular', 'L2XTabular', 'PermutationImportance', 'GlobalShapTabular', 'BiasAnalyzer', 'MACEExplainer', 'GPTExplainer', 'CounterfactualExplainer', 'KNNCounterfactualExplainer', 'IntegratedGradientTabular', 'LinearRegression', 'LogisticRegression', 'TreeRegressor', 'TreeClassifier', 'ShapTreeTabular', 'lime', 'shap', 'pdp', 'partial_dependence', 'ale', 'accumulated_local_effects', 'sa', 'sensitivity', 'l2x', 'L2X', 'permutation', 'shap_global', 'bias', 'mace', 'gpt', 'ce', 'counterfactual', 'ce_knn', 'knn_ce', 'ig', 'integrated_gradient', 'linear_regression', 'logistic_regression', 'tree_regressor', 'tree_classifier', 'shap_tree'])"
     ]
    }
   ],
   "source": [
    "# OmniXAI는 LIME, SHAP, TreeSHAP, IG를 갖추고 있다.\n",
    "from omnixai.explainers.tabular import TabularExplainer\n",
    "# Initialize a TabularExplainer\n",
    "explainer = TabularExplainer(\n",
    "  explainers=[\"lime\", \"shap\", \"mace\", \"pdp\", \"ale\", \"aaa\"], # The explainers to apply\n",
    "  mode=\"classification\",                             # The task type\n",
    "  data=train_data,                                   # The data for initializing the explainers\n",
    "  model=model,                                       # The ML model to explain\n",
    "  preprocess=lambda z: transformer.transform(z),     # Converts raw features into the model inputs\n",
    "  params={\n",
    "     \"mace\": {\"ignored_features\": [\"Sex\", \"Race\", \"Relationship\", \"Capital Loss\"]}\n",
    "  }                                                  # Additional parameters\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "912a3adb554c416eb8cce4a8f53d0d00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('predict',\n",
       "              <omnixai.explanations.base.PredictedResults at 0x7f949ee72a10>),\n",
       "             ('lime',\n",
       "              [{'instance':     Age Workclass    fnlwgt     Education  Education-Num Marital Status  \\\n",
       "              0  20.0   Private  110998.0  Some-college           10.0  Never-married   \n",
       "              \n",
       "                   Occupation Relationship                Race     Sex  Capital Gain  \\\n",
       "              0  Adm-clerical    Own-child  Asian-Pac-Islander  Female           0.0   \n",
       "              \n",
       "                 Capital Loss  Hours per week        Country  \n",
       "              0           0.0            30.0  United-States  , 'features': ['Capital Gain', 'Age', 'Marital Status', 'Hours per week', 'Capital Loss', 'Sex', 'fnlwgt', 'Occupation', 'Relationship', 'Race'], 'values': [0.0, 20.0, 'Never-married', 30.0, 0.0, 'Female', 110998.0, 'Adm-clerical', 'Own-child', 'Asian-Pac-Islander'], 'scores': [0.7098656386832946, 0.0986917834142603, 0.09079057400844752, 0.08627590231720923, 0.08572035980061805, 0.026468281375671122, 0.020150077226355142, 0.016527966979101773, 0.012575063460454554, -0.0117097220354036], 'target_label': 0}, {'instance':     Age Workclass    fnlwgt Education  Education-Num Marital Status  \\\n",
       "              1  18.0         ?  120243.0      11th            7.0  Never-married   \n",
       "              \n",
       "                Occupation Relationship   Race   Sex  Capital Gain  Capital Loss  \\\n",
       "              1          ?    Own-child  White  Male           0.0           0.0   \n",
       "              \n",
       "                 Hours per week        Country  \n",
       "              1            27.0  United-States  , 'features': ['Capital Gain', 'Age', 'Marital Status', 'Hours per week', 'Education-Num', 'Occupation', 'Capital Loss', 'Race', 'Sex', 'Relationship'], 'values': [0.0, 18.0, 'Never-married', 27.0, 7.0, '?', 0.0, 'White', 'Male', 'Own-child'], 'scores': [0.7090524277878573, 0.1003275855623939, 0.08638455437086137, 0.06821804853736921, 0.06510423724484057, 0.046334152039778136, 0.030295790663142252, -0.029545474050139728, -0.024968268738142275, 0.019654032638692743], 'target_label': 0}, {'instance':     Age Workclass    fnlwgt  Education  Education-Num      Marital Status  \\\n",
       "              2  44.0   Private  145160.0  Doctorate           16.0  Married-civ-spouse   \n",
       "              \n",
       "                     Occupation Relationship   Race   Sex  Capital Gain  Capital Loss  \\\n",
       "              2  Prof-specialty      Husband  White  Male           0.0           0.0   \n",
       "              \n",
       "                 Hours per week        Country  \n",
       "              2            40.0  United-States  , 'features': ['Capital Gain', 'Marital Status', 'Education-Num', 'Hours per week', 'Capital Loss', 'Age', 'Occupation', 'Sex', 'Education', 'Race'], 'values': [0.0, 'Married-civ-spouse', 16.0, 40.0, 0.0, 44.0, 'Prof-specialty', 'Male', 'Doctorate', 'White'], 'scores': [-0.710991728171513, 0.12959306198640586, 0.08616408648942103, -0.08201452993464242, -0.07636508995437756, 0.06771270420283163, 0.058932045514993266, 0.03560462266393449, 0.020225307163675862, 0.019273499178806715], 'target_label': 1}, {'instance':     Age  Workclass    fnlwgt Education  Education-Num Marital Status  \\\n",
       "              3  64.0  Local-gov  190660.0   HS-grad            9.0       Divorced   \n",
       "              \n",
       "                   Occupation   Relationship   Race   Sex  Capital Gain  Capital Loss  \\\n",
       "              3  Craft-repair  Not-in-family  White  Male           0.0           0.0   \n",
       "              \n",
       "                 Hours per week        Country  \n",
       "              3            40.0  United-States  , 'features': ['Capital Gain', 'Hours per week', 'Education-Num', 'Marital Status', 'Capital Loss', 'Age', 'Sex', 'Workclass', 'Race', 'fnlwgt'], 'values': [0.0, 40.0, 9.0, 'Divorced', 0.0, 64.0, 'Male', 'Local-gov', 'White', 190660.0], 'scores': [0.7198091371583134, 0.08321620077079614, 0.07533508506889734, 0.06646758355206978, 0.06047291934214548, -0.0533561319531523, -0.02735279124354831, 0.011805904662298323, -0.011532648134842553, -0.009964229903903223], 'target_label': 0}, {'instance':     Age Workclass    fnlwgt Education  Education-Num      Marital Status  \\\n",
       "              4  31.0         ?  233371.0   HS-grad            9.0  Married-civ-spouse   \n",
       "              \n",
       "                Occupation Relationship   Race     Sex  Capital Gain  Capital Loss  \\\n",
       "              4          ?         Wife  Black  Female           0.0           0.0   \n",
       "              \n",
       "                 Hours per week        Country  \n",
       "              4            45.0  United-States  , 'features': ['Capital Gain', 'Marital Status', 'Education-Num', 'Capital Loss', 'Relationship', 'Hours per week', 'Occupation', 'Sex', 'Workclass', 'Race'], 'values': [0.0, 'Married-civ-spouse', 9.0, 0.0, 'Wife', 45.0, '?', 'Female', '?', 'Black'], 'scores': [0.7180871095338015, -0.12065959355737099, 0.07574458916176399, 0.05394884448669542, -0.04908756888961463, -0.048859341765735254, 0.03849209420338807, 0.033499105131228495, 0.010750149697384725, 0.008657066209454762], 'target_label': 0}]),\n",
       "             ('shap',\n",
       "              [{'instance':     Age Workclass    fnlwgt     Education  Education-Num Marital Status  \\\n",
       "              0  20.0   Private  110998.0  Some-college           10.0  Never-married   \n",
       "              \n",
       "                   Occupation Relationship                Race     Sex  Capital Gain  \\\n",
       "              0  Adm-clerical    Own-child  Asian-Pac-Islander  Female           0.0   \n",
       "              \n",
       "                 Capital Loss  Hours per week        Country  \n",
       "              0           0.0            30.0  United-States  , 'features': ['Workclass', 'Education'], 'values': ['Private', 'Some-college'], 'scores': [0.06921174170097814, -0.06917107931417837], 'target_label': 0}, {'instance':     Age Workclass    fnlwgt Education  Education-Num Marital Status  \\\n",
       "              1  18.0         ?  120243.0      11th            7.0  Never-married   \n",
       "              \n",
       "                Occupation Relationship   Race   Sex  Capital Gain  Capital Loss  \\\n",
       "              1          ?    Own-child  White  Male           0.0           0.0   \n",
       "              \n",
       "                 Hours per week        Country  \n",
       "              1            27.0  United-States  , 'features': ['Workclass', 'Education'], 'values': ['?', '11th'], 'scores': [0.0, 0.0], 'target_label': 0}, {'instance':     Age Workclass    fnlwgt  Education  Education-Num      Marital Status  \\\n",
       "              2  44.0   Private  145160.0  Doctorate           16.0  Married-civ-spouse   \n",
       "              \n",
       "                     Occupation Relationship   Race   Sex  Capital Gain  Capital Loss  \\\n",
       "              2  Prof-specialty      Husband  White  Male           0.0           0.0   \n",
       "              \n",
       "                 Hours per week        Country  \n",
       "              2            40.0  United-States  , 'features': ['Workclass', 'Education'], 'values': ['Private', 'Doctorate'], 'scores': [1.2819989119573547, -1.2819151090458614], 'target_label': 1}, {'instance':     Age  Workclass    fnlwgt Education  Education-Num Marital Status  \\\n",
       "              3  64.0  Local-gov  190660.0   HS-grad            9.0       Divorced   \n",
       "              \n",
       "                   Occupation   Relationship   Race   Sex  Capital Gain  Capital Loss  \\\n",
       "              3  Craft-repair  Not-in-family  White  Male           0.0           0.0   \n",
       "              \n",
       "                 Hours per week        Country  \n",
       "              3            40.0  United-States  , 'features': ['Workclass', 'Education'], 'values': ['Local-gov', 'HS-grad'], 'scores': [0.5568852080206841, -0.556796864293976], 'target_label': 0}, {'instance':     Age Workclass    fnlwgt Education  Education-Num      Marital Status  \\\n",
       "              4  31.0         ?  233371.0   HS-grad            9.0  Married-civ-spouse   \n",
       "              \n",
       "                Occupation Relationship   Race     Sex  Capital Gain  Capital Loss  \\\n",
       "              4          ?         Wife  Black  Female           0.0           0.0   \n",
       "              \n",
       "                 Hours per week        Country  \n",
       "              4            45.0  United-States  , 'features': ['Workclass', 'Education'], 'values': ['?', 'HS-grad'], 'scores': [0.4936640042221331, -0.49358347660893637], 'target_label': 0}]),\n",
       "             ('mace',\n",
       "              [{'query':     Age Workclass    fnlwgt     Education  Education-Num Marital Status  \\\n",
       "              0  20.0   Private  110998.0  Some-college           10.0  Never-married   \n",
       "              \n",
       "                   Occupation Relationship                Race     Sex  Capital Gain  \\\n",
       "              0  Adm-clerical    Own-child  Asian-Pac-Islander  Female           0.0   \n",
       "              \n",
       "                 Capital Loss  Hours per week        Country  label  \n",
       "              0           0.0            30.0  United-States      0  , 'counterfactual':         Age Workclass    fnlwgt     Education  Education-Num Marital Status  \\\n",
       "              0  22.34375   Private  110998.0  Some-college           10.0  Never-married   \n",
       "              \n",
       "                   Occupation Relationship                Race     Sex  Capital Gain  \\\n",
       "              0  Adm-clerical    Own-child  Asian-Pac-Islander  Female     12499.875   \n",
       "              \n",
       "                 Capital Loss  Hours per week        Country  label  \n",
       "              0           0.0            30.0  United-States      1  }, {'query':     Age Workclass    fnlwgt Education  Education-Num Marital Status  \\\n",
       "              1  18.0         ?  120243.0      11th            7.0  Never-married   \n",
       "              \n",
       "                Occupation Relationship   Race   Sex  Capital Gain  Capital Loss  \\\n",
       "              1          ?    Own-child  White  Male           0.0           0.0   \n",
       "              \n",
       "                 Hours per week        Country  label  \n",
       "              1            27.0  United-States      0  , 'counterfactual':       Age Workclass    fnlwgt Education  Education-Num Marital Status  \\\n",
       "              1  22.375         ?  120243.0      11th            7.0  Never-married   \n",
       "              \n",
       "                Occupation Relationship   Race   Sex  Capital Gain  Capital Loss  \\\n",
       "              1          ?    Own-child  White  Male       8696.25           0.0   \n",
       "              \n",
       "                 Hours per week        Country  label  \n",
       "              1            27.0  United-States      1  }, {'query':     Age Workclass    fnlwgt  Education  Education-Num      Marital Status  \\\n",
       "              2  44.0   Private  145160.0  Doctorate           16.0  Married-civ-spouse   \n",
       "              \n",
       "                     Occupation Relationship   Race   Sex  Capital Gain  Capital Loss  \\\n",
       "              2  Prof-specialty      Husband  White  Male           0.0           0.0   \n",
       "              \n",
       "                 Hours per week        Country  label  \n",
       "              2            40.0  United-States      1  , 'counterfactual':      Age  Workclass        fnlwgt  Education  Education-Num  \\\n",
       "              1  38.75    Private  145160.00000  Doctorate        14.8750   \n",
       "              0  38.75    Private  144865.59375  Doctorate        14.8750   \n",
       "              1  38.75  State-gov  145160.00000  Doctorate        12.9375   \n",
       "              1  44.00  State-gov  142811.50000  Doctorate        16.0000   \n",
       "              4  44.00    Private  145160.00000  Assoc-voc        16.0000   \n",
       "              \n",
       "                     Marital Status         Occupation Relationship   Race   Sex  \\\n",
       "              1  Married-civ-spouse  Machine-op-inspct      Husband  White  Male   \n",
       "              0  Married-civ-spouse       Craft-repair      Husband  White  Male   \n",
       "              1  Married-civ-spouse     Prof-specialty      Husband  White  Male   \n",
       "              1  Married-civ-spouse     Prof-specialty      Husband  White  Male   \n",
       "              4  Married-civ-spouse       Adm-clerical      Husband  White  Male   \n",
       "              \n",
       "                 Capital Gain  Capital Loss  Hours per week        Country  label  \n",
       "              1        0.0000           0.0            40.0  United-States      0  \n",
       "              0        0.0000           0.0            40.0  United-States      0  \n",
       "              1        0.0000           0.0            40.0  United-States      0  \n",
       "              1      196.0625           0.0            40.0  United-States      0  \n",
       "              4      196.0625           0.0            40.0  United-States      0  }, {'query':     Age  Workclass    fnlwgt Education  Education-Num Marital Status  \\\n",
       "              3  64.0  Local-gov  190660.0   HS-grad            9.0       Divorced   \n",
       "              \n",
       "                   Occupation   Relationship   Race   Sex  Capital Gain  Capital Loss  \\\n",
       "              3  Craft-repair  Not-in-family  White  Male           0.0           0.0   \n",
       "              \n",
       "                 Hours per week        Country  label  \n",
       "              3            40.0  United-States      0  , 'counterfactual':        Age     Workclass      fnlwgt Education  Education-Num  \\\n",
       "              0  64.0000  Self-emp-inc  206992.375   HS-grad         9.0000   \n",
       "              1  64.0000  Self-emp-inc  206992.375   HS-grad         9.0625   \n",
       "              0  64.0000  Self-emp-inc  201548.250   HS-grad         9.0000   \n",
       "              3  64.0000     Local-gov  190660.000   HS-grad         9.0000   \n",
       "              2  62.8125     Local-gov  190660.000   HS-grad         9.0625   \n",
       "              \n",
       "                     Marital Status    Occupation   Relationship   Race   Sex  Capital Gain  \\\n",
       "              0  Married-civ-spouse  Craft-repair  Not-in-family  White  Male           0.0   \n",
       "              1  Married-civ-spouse  Craft-repair  Not-in-family  White  Male           0.0   \n",
       "              0  Married-civ-spouse  Craft-repair  Not-in-family  White  Male           0.0   \n",
       "              3            Divorced  Craft-repair  Not-in-family  White  Male        3103.0   \n",
       "              2            Divorced  Craft-repair  Not-in-family  White  Male        7312.5   \n",
       "              \n",
       "                 Capital Loss  Hours per week        Country  label  \n",
       "              0           0.0         40.0000  United-States      1  \n",
       "              1           0.0         40.0000  United-States      1  \n",
       "              0           0.0         42.1875  United-States      1  \n",
       "              3           0.0         40.0000  United-States      1  \n",
       "              2           0.0         40.3125  United-States      1  }, {'query':     Age Workclass    fnlwgt Education  Education-Num      Marital Status  \\\n",
       "              4  31.0         ?  233371.0   HS-grad            9.0  Married-civ-spouse   \n",
       "              \n",
       "                Occupation Relationship   Race     Sex  Capital Gain  Capital Loss  \\\n",
       "              4          ?         Wife  Black  Female           0.0           0.0   \n",
       "              \n",
       "                 Hours per week        Country  label  \n",
       "              4            45.0  United-States      0  , 'counterfactual':        Age  Workclass        fnlwgt     Education  Education-Num  \\\n",
       "              1  31.0000          ?  233371.00000       HS-grad         9.0000   \n",
       "              0  31.0000          ?  233829.78125       HS-grad         9.0000   \n",
       "              0  31.0000          ?  233371.00000       HS-grad         9.0625   \n",
       "              0  37.1875          ?  233371.00000  Some-college        10.0000   \n",
       "              1  40.0000  Local-gov  233371.00000       HS-grad        10.0000   \n",
       "              \n",
       "                     Marital Status Occupation Relationship   Race     Sex  Capital Gain  \\\n",
       "              1  Married-civ-spouse          ?         Wife  Black  Female           0.0   \n",
       "              0  Married-civ-spouse          ?         Wife  Black  Female           0.0   \n",
       "              0  Married-civ-spouse          ?         Wife  Black  Female           0.0   \n",
       "              0  Married-civ-spouse          ?         Wife  Black  Female           0.0   \n",
       "              1  Married-civ-spouse          ?         Wife  Black  Female           0.0   \n",
       "              \n",
       "                 Capital Loss  Hours per week        Country  label  \n",
       "              1           0.0            54.0  United-States      1  \n",
       "              0           0.0            54.0  United-States      1  \n",
       "              0           0.0            54.0  United-States      1  \n",
       "              0           0.0            45.0  United-States      1  \n",
       "              1           0.0            45.0  United-States      1  }])])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate explanations\n",
    "test_instances = test_data[:5]\n",
    "local_explanations = explainer.explain(X=test_instances)\n",
    "\n",
    "\n",
    "\n",
    "local_explanations\n",
    "# global_explanations = explainer.explain_global(\n",
    "#     params={\"pdp\": {\"features\": [\"Age\", \"Education-Num\", \"Capital Gain\",\n",
    "#                                  \"Capital Loss\", \"Hours per week\", \"Education\",\n",
    "#                                  \"Marital Status\", \"Occupation\"]}}\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instance':     Age         Workclass    fnlwgt  Education  Education-Num  \\\n",
       " 1  48.0  Self-emp-not-inc  160724.0  Bachelors           13.0   \n",
       " \n",
       "        Marital Status       Occupation Relationship                Race   Sex  \\\n",
       " 1  Married-civ-spouse  Exec-managerial      Husband  Asian-Pac-Islander  Male   \n",
       " \n",
       "    Capital Gain  Capital Loss  Hours per week Country  \n",
       " 1           0.0           0.0            40.0   Japan  ,\n",
       " 'features': ['Capital Gain',\n",
       "  'Marital Status',\n",
       "  'Hours per week',\n",
       "  'Education-Num',\n",
       "  'Age',\n",
       "  'Occupation',\n",
       "  'Country',\n",
       "  'Capital Loss',\n",
       "  'Sex',\n",
       "  'Race'],\n",
       " 'values': [0.0,\n",
       "  'Married-civ-spouse',\n",
       "  40.0,\n",
       "  13.0,\n",
       "  48.0,\n",
       "  'Exec-managerial',\n",
       "  'Japan',\n",
       "  0.0,\n",
       "  'Male',\n",
       "  'Asian-Pac-Islander'],\n",
       " 'scores': [-0.7174269202573026,\n",
       "  0.12373506933540021,\n",
       "  -0.08009449263879101,\n",
       "  0.07463333708307905,\n",
       "  0.07408962211553939,\n",
       "  0.07013468779567734,\n",
       "  -0.0497145992611175,\n",
       "  -0.042112685273002576,\n",
       "  0.030125166776901604,\n",
       "  0.009174592742435584],\n",
       " 'target_label': 1}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_explanations['lime'].get_explanations(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.load(\"data/Wine Quality/X_test.npy\")\n",
    "y_test = np.load(\"data/Wine Quality/y_test.npy\")\n",
    "\n",
    "input_data = np.concatenate((X_test, y_test.reshape(-1, 1)), axis=1)\n",
    "tabular_data = Tabular(\n",
    "   input_data,\n",
    "   categorical_columns=[],\n",
    "   target_column=input_data.shape[1] - 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Explainer lime -- training_data should be an instance of Tabular.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/pnpenv/lib/python3.10/site-packages/omnixai/explainers/base.py:214\u001b[0m, in \u001b[0;36mAutoExplainerBase._build_explainers\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredict_function\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m _signature:\n\u001b[0;32m--> 214\u001b[0m     explainer \u001b[38;5;241m=\u001b[39m \u001b[43m_class\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpredict_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_param\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m _signature:\n",
      "File \u001b[0;32m~/miniconda3/envs/pnpenv/lib/python3.10/site-packages/omnixai/explainers/tabular/agnostic/lime.py:52\u001b[0m, in \u001b[0;36mLimeTabular.__init__\u001b[0;34m(self, training_data, predict_function, mode, ignored_features, **kwargs)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;124;03m:param training_data: The data used to train local explainers in LIME. ``training_data``\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;124;03m    can be the training dataset for training the machine learning model. If the training\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;124;03m    `lime_tabular.LimeTabularExplainer`.\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m---> 52\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtraining_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredict_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpredict_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mignored_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(ignored_features) \u001b[38;5;28;01mif\u001b[39;00m ignored_features \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/pnpenv/lib/python3.10/site-packages/omnixai/explainers/tabular/base.py:95\u001b[0m, in \u001b[0;36mTabularExplainer.__init__\u001b[0;34m(self, training_data, predict_function, mode, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[0;32m---> 95\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(training_data, Tabular), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining_data should be an instance of Tabular.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcategorical_columns \u001b[38;5;241m=\u001b[39m training_data\u001b[38;5;241m.\u001b[39mcategorical_columns\n",
      "\u001b[0;31mAssertionError\u001b[0m: training_data should be an instance of Tabular.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m train_data \u001b[38;5;241m=\u001b[39m transformer\u001b[38;5;241m.\u001b[39minvert(torch\u001b[38;5;241m.\u001b[39mtensor(train))\n\u001b[1;32m     12\u001b[0m test_data \u001b[38;5;241m=\u001b[39m transformer\u001b[38;5;241m.\u001b[39minvert(torch\u001b[38;5;241m.\u001b[39mtensor(test))\n\u001b[0;32m---> 14\u001b[0m explainer \u001b[38;5;241m=\u001b[39m \u001b[43mTabularExplainer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m  \u001b[49m\u001b[43mexplainers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlime\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshap\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mig\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# The explainers to apply\u001b[39;49;00m\n\u001b[1;32m     16\u001b[0m \u001b[43m  \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mclassification\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m                             \u001b[49m\u001b[38;5;66;43;03m# The task type\u001b[39;49;00m\n\u001b[1;32m     17\u001b[0m \u001b[43m  \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m  \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnn_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m                                       \u001b[49m\u001b[38;5;66;43;03m# The ML model to explain\u001b[39;49;00m\n\u001b[1;32m     19\u001b[0m \u001b[43m  \u001b[49m\u001b[43mpreprocess\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mz\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m     \u001b[49m\u001b[38;5;66;43;03m# Converts raw features into the model inputs\u001b[39;49;00m\n\u001b[1;32m     20\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pnpenv/lib/python3.10/site-packages/omnixai/explainers/tabular/auto.py:68\u001b[0m, in \u001b[0;36mTabularExplainer.__init__\u001b[0;34m(self, explainers, mode, data, model, preprocess, postprocess, params)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     43\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     44\u001b[0m         explainers: Collection,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     50\u001b[0m         params: Dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     51\u001b[0m ):\n\u001b[1;32m     52\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;124;03m    :param explainers: The names or alias of the explainers to use.\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;124;03m    :param mode: The task type, e.g. `classification` or `regression`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;124;03m        e.g., `params[\"lime\"] = {\"param_1\": param_1, ...}`.\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 68\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexplainers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexplainers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreprocess\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreprocess\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpostprocess\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpostprocess\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     78\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_info \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     79\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategorical_columns\u001b[39m\u001b[38;5;124m\"\u001b[39m: data\u001b[38;5;241m.\u001b[39mcategorical_columns,\n\u001b[1;32m     80\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget_column\u001b[39m\u001b[38;5;124m\"\u001b[39m: data\u001b[38;5;241m.\u001b[39mtarget_column,\n\u001b[1;32m     81\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeature_columns\u001b[39m\u001b[38;5;124m\"\u001b[39m: data\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[1;32m     82\u001b[0m         }\n",
      "File \u001b[0;32m~/miniconda3/envs/pnpenv/lib/python3.10/site-packages/omnixai/explainers/base.py:165\u001b[0m, in \u001b[0;36mAutoExplainerBase.__init__\u001b[0;34m(self, explainers, mode, data, model, preprocess, postprocess, params)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams \u001b[38;5;241m=\u001b[39m params\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 165\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexplainers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_explainers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_info \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m~/miniconda3/envs/pnpenv/lib/python3.10/site-packages/omnixai/explainers/base.py:237\u001b[0m, in \u001b[0;36mAutoExplainerBase._build_explainers\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m    235\u001b[0m         explainers[name] \u001b[38;5;241m=\u001b[39m explainer\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 237\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(e)(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExplainer \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m -- \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m explainers\n",
      "\u001b[0;31mAssertionError\u001b[0m: Explainer lime -- training_data should be an instance of Tabular."
     ]
    }
   ],
   "source": [
    "nn_model = torch.nn.Linear(X_test.shape[1], 2)\n",
    "\n",
    "transformer = TabularTransform().fit(tabular_data)\n",
    "class_names = transformer.class_names\n",
    "x = transformer.transform(tabular_data)\n",
    "# Split into training and test datasets\n",
    "train, test, train_labels, test_labels = \\\n",
    "    train_test_split(x[:, :-1], x[:, -1], train_size=0.80)\n",
    "# Train an XGBoost model (the last column of `x` is the label column after transformation)\n",
    "# Convert the transformed data back to Tabular instances\n",
    "train_data = transformer.invert(torch.tensor(train))\n",
    "test_data = transformer.invert(torch.tensor(test))\n",
    "\n",
    "explainer = TabularExplainer(\n",
    "  explainers=[\"lime\", \"shap\", \"ig\"], # The explainers to apply\n",
    "  mode=\"classification\",                             # The task type\n",
    "  data=torch.randn(100,2),\n",
    "  model=nn_model,                                       # The ML model to explain\n",
    "  preprocess=lambda z: transformer.transform(z),     # Converts raw features into the model inputs\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenXAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from openxai.dataloader import ReturnLoaders\n",
    "loader_train, loader_test = ReturnLoaders(data_name='german', download=True)\n",
    "# get an input instance from the test dataset\n",
    "inputs, labels = next(iter(loader_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openxai import LoadModel\n",
    "model = LoadModel(data_name= 'german', ml_model='ann', pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.tensor([d[0] for d in loader_train.dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openxai import Explainer\n",
    "from openxai.experiment_utils import fill_param_dict\n",
    "param_dict = fill_param_dict('lime', {}, X_train)\n",
    "exp_method = Explainer(method='lime', model=model, param_dict=param_dict)\n",
    "explanations= exp_method.get_explanations(inputs, label=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 60])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 60])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explanations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openxai import Evaluator\n",
    "from openxai.explainers.perturbation_methods import NormalPerturbation\n",
    "import numpy as np\n",
    "\n",
    "feature_metadata = np.where((inputs.numpy() == 0.0) | (inputs.numpy() == 1.0), 'd', 'c')[0].tolist()\n",
    "\n",
    "metric_evaluator = Evaluator(model, metric='PGI')\n",
    "kwargs = {\n",
    "    \"explanations\": explanations,\n",
    "    \"inputs\": inputs,\n",
    "    \"k\": 0.1,\n",
    "    \"perturb_method\": NormalPerturbation('tabular'),\n",
    "    \"feature_metadata\": feature_metadata\n",
    "}\n",
    "\n",
    "score = metric_evaluator.evaluate(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.61782783, 0.20031753, 0.17158128, 0.32372916, 0.4453343 ,\n",
       "        0.00382134, 0.1159284 , 0.01427623, 0.41874745, 0.15988487,\n",
       "        0.00148061, 0.52968276, 0.19574705, 0.08563896, 0.26961112,\n",
       "        0.19825181, 0.39603913, 0.26493934, 0.10648002, 0.48599267,\n",
       "        0.01620395, 0.16462477, 0.14538735, 0.3685585 , 0.29140532,\n",
       "        0.49489924, 0.01769307, 0.07826665, 0.35052273, 0.4042034 ,\n",
       "        0.1675385 , 0.06326002], dtype=float32),\n",
       " 0.2364961)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [\"AbPC\"]\n",
    "FRAMEWORK = [\"PnPXAI\", \"OmniXAI\", \"OpenXAI\"]\n",
    "MODEL = [\"LogisticRegression\", \"XGBoost\", \"TabResNet\", \"TabTransformer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "model = torch.nn.Linear(10, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pnpxai.evaluator.metrics.pixel_flipping import AbPC\n",
    "metric_obj = AbPC(model)\n",
    "inputs = {\"input\" : torch.randn(20, 10)}\n",
    "explanations = torch.randn(20, 10)\n",
    "labels = torch.randint(0, 2, (20,))\n",
    "evals = metric_obj.evaluate(inputs, labels, explanations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-0.0181,  0.0345,  0.0346,  0.0213,  0.0264, -0.1871,  0.0195, -0.1951,\n",
       "         -0.1298,  0.0007, -0.1259,  0.0353, -0.0921,  0.0799,  0.0821, -0.0270,\n",
       "         -0.0424, -0.0208, -0.1354, -0.2065]),\n",
       " torch.Size([20]))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evals, evals.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pnpenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
