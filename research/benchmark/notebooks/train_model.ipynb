{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os; os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cwl/miniconda3/envs/pnpenv/lib/python3.10/site-packages/xgboost/core.py:265: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc 2.28+) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "from models.tab_resnet import TabResNet, LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f3f41508030>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set seeds\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X, y, model, loss_fn, optimizer, num_epochs):\n",
    "    for epoch in range(num_epochs):\n",
    "        # Forward pass\n",
    "        y_pred = model.network(X)\n",
    "        \n",
    "        # Compute Loss\n",
    "        loss = loss_fn(y_pred.squeeze(), y)\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if epoch % 100 == 0:\n",
    "            print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\"Adult\", \"Bank Marketing\", \"Statlog (German Credit Data)\", \"Wine Quality\"]\n",
    "\n",
    "dataset = datasets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Accuracy: 0.8780837342614393\n",
      "Epoch 1/1000, Loss: 0.6880693435668945\n",
      "Epoch 101/1000, Loss: 0.4647754728794098\n",
      "Epoch 201/1000, Loss: 0.421127587556839\n",
      "Epoch 301/1000, Loss: 0.3997373580932617\n",
      "Epoch 401/1000, Loss: 0.3869837522506714\n",
      "Epoch 501/1000, Loss: 0.3784954249858856\n",
      "Epoch 601/1000, Loss: 0.37239620089530945\n",
      "Epoch 701/1000, Loss: 0.36776065826416016\n",
      "Epoch 801/1000, Loss: 0.3640848398208618\n",
      "Epoch 901/1000, Loss: 0.36107316613197327\n",
      "Epoch 1/1000, Loss: 0.7633286714553833\n",
      "Epoch 101/1000, Loss: 0.3724764883518219\n",
      "Epoch 201/1000, Loss: 0.3484494984149933\n",
      "Epoch 301/1000, Loss: 0.3389897644519806\n",
      "Epoch 401/1000, Loss: 0.3328791856765747\n",
      "Epoch 501/1000, Loss: 0.32813552021980286\n",
      "Epoch 601/1000, Loss: 0.32393258810043335\n",
      "Epoch 701/1000, Loss: 0.3214186131954193\n",
      "Epoch 801/1000, Loss: 0.3201175630092621\n",
      "Epoch 901/1000, Loss: 0.31839215755462646\n",
      "Logistic Regression Accuracy: 0.8283345275872659\n",
      "ResNet Accuracy: 0.8535162247927116\n",
      "XGBoost Accuracy: 0.9064469755612076\n",
      "Epoch 1/1000, Loss: 0.7467601895332336\n",
      "Epoch 101/1000, Loss: 0.3254789412021637\n",
      "Epoch 201/1000, Loss: 0.30042150616645813\n",
      "Epoch 301/1000, Loss: 0.2901251018047333\n",
      "Epoch 401/1000, Loss: 0.28367879986763\n",
      "Epoch 501/1000, Loss: 0.27915865182876587\n",
      "Epoch 601/1000, Loss: 0.27578651905059814\n",
      "Epoch 701/1000, Loss: 0.2731527090072632\n",
      "Epoch 801/1000, Loss: 0.27102020382881165\n",
      "Epoch 901/1000, Loss: 0.2692439556121826\n",
      "Epoch 1/1000, Loss: 0.9167707562446594\n",
      "Epoch 101/1000, Loss: 0.29720956087112427\n",
      "Epoch 201/1000, Loss: 0.271156907081604\n",
      "Epoch 301/1000, Loss: 0.2597217857837677\n",
      "Epoch 401/1000, Loss: 0.25250065326690674\n",
      "Epoch 501/1000, Loss: 0.24751992523670197\n",
      "Epoch 601/1000, Loss: 0.24400146305561066\n",
      "Epoch 701/1000, Loss: 0.2407485544681549\n",
      "Epoch 801/1000, Loss: 0.2371625006198883\n",
      "Epoch 901/1000, Loss: 0.23551194369792938\n",
      "Logistic Regression Accuracy: 0.8890854804821409\n",
      "ResNet Accuracy: 0.900807254229791\n",
      "XGBoost Accuracy: 0.745\n",
      "Epoch 1/1000, Loss: 0.7725822925567627\n",
      "Epoch 101/1000, Loss: 0.5763692259788513\n",
      "Epoch 201/1000, Loss: 0.546511173248291\n",
      "Epoch 301/1000, Loss: 0.5281729698181152\n",
      "Epoch 401/1000, Loss: 0.5155391097068787\n",
      "Epoch 501/1000, Loss: 0.506294846534729\n",
      "Epoch 601/1000, Loss: 0.49926310777664185\n",
      "Epoch 701/1000, Loss: 0.49375858902931213\n",
      "Epoch 801/1000, Loss: 0.489349365234375\n",
      "Epoch 901/1000, Loss: 0.4857485890388489\n",
      "Epoch 1/1000, Loss: 0.7338818311691284\n",
      "Epoch 101/1000, Loss: 0.5194866061210632\n",
      "Epoch 201/1000, Loss: 0.4699023962020874\n",
      "Epoch 301/1000, Loss: 0.4368572235107422\n",
      "Epoch 401/1000, Loss: 0.4166969656944275\n",
      "Epoch 501/1000, Loss: 0.3887394964694977\n",
      "Epoch 601/1000, Loss: 0.35759830474853516\n",
      "Epoch 701/1000, Loss: 0.34468135237693787\n",
      "Epoch 801/1000, Loss: 0.3169495463371277\n",
      "Epoch 901/1000, Loss: 0.3001194894313812\n",
      "Logistic Regression Accuracy: 0.76\n",
      "ResNet Accuracy: 0.79\n",
      "XGBoost Accuracy: 0.8869230769230769\n",
      "Epoch 1/1000, Loss: 0.746457576751709\n",
      "Epoch 101/1000, Loss: 0.5320580005645752\n",
      "Epoch 201/1000, Loss: 0.4714508056640625\n",
      "Epoch 301/1000, Loss: 0.4443418085575104\n",
      "Epoch 401/1000, Loss: 0.4293774962425232\n",
      "Epoch 501/1000, Loss: 0.42017847299575806\n",
      "Epoch 601/1000, Loss: 0.41409602761268616\n",
      "Epoch 701/1000, Loss: 0.4098512828350067\n",
      "Epoch 801/1000, Loss: 0.40676403045654297\n",
      "Epoch 901/1000, Loss: 0.40444475412368774\n",
      "Epoch 1/1000, Loss: 0.7088010907173157\n",
      "Epoch 101/1000, Loss: 0.4167401194572449\n",
      "Epoch 201/1000, Loss: 0.39795127511024475\n",
      "Epoch 301/1000, Loss: 0.3867080509662628\n",
      "Epoch 401/1000, Loss: 0.38142311573028564\n",
      "Epoch 501/1000, Loss: 0.37606295943260193\n",
      "Epoch 601/1000, Loss: 0.3753664195537567\n",
      "Epoch 701/1000, Loss: 0.37168723344802856\n",
      "Epoch 801/1000, Loss: 0.37117838859558105\n",
      "Epoch 901/1000, Loss: 0.3689049780368805\n",
      "Logistic Regression Accuracy: 0.823076923076923\n",
      "ResNet Accuracy: 0.83\n"
     ]
    }
   ],
   "source": [
    "for dataset in datasets:\n",
    "    path = f\"data/{dataset}\"\n",
    "\n",
    "    X_train = np.load(f\"{path}/X_train.npy\")\n",
    "    y_train = np.load(f\"{path}/y_train.npy\")\n",
    "    X_test = np.load(f\"{path}/X_test.npy\")\n",
    "    y_test = np.load(f\"{path}/y_test.npy\")\n",
    "\n",
    "    xgb_clf = xgb.XGBClassifier()\n",
    "    xgb_clf.fit(X_train, y_train)\n",
    "\n",
    "    xgb_y_pred = xgb_clf.predict(X_test)\n",
    "    xgb_accuracy = np.mean(xgb_y_pred == y_test)\n",
    "    print(f\"XGBoost Accuracy: {xgb_accuracy}\")\n",
    "\n",
    "    X_train = torch.from_numpy(X_train).float()\n",
    "    y_train = torch.from_numpy(y_train).long()\n",
    "    X_test = torch.from_numpy(X_test).float()\n",
    "\n",
    "    feature_metadata = pickle.load(open(f\"{path}/feature_metadata.pkl\", \"rb\"))\n",
    "    xgb_clf.save_model(f\"{path}/xgb_model.json\")\n",
    "\n",
    "\n",
    "    input_dim = X_train.shape[1]\n",
    "    output_dim = 2\n",
    "\n",
    "    lr_model = LogisticRegression(input_dim, output_dim)\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(lr_model.parameters(), lr=0.01, weight_decay=0.01)\n",
    "\n",
    "    train_model(X_train, y_train, lr_model, loss_fn, optimizer, 1000)\n",
    "\n",
    "    resnet_model = TabResNet(input_dim, output_dim, num_blocks=1)\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(resnet_model.parameters(), lr=0.01, weight_decay=0.01)\n",
    "\n",
    "    train_model(X_train, y_train, resnet_model, loss_fn, optimizer, 1000)\n",
    "\n",
    "    lr_y_pred = lr_model(X_test).detach().argmax(dim=1).numpy()\n",
    "    lr_accuracy = np.mean(lr_y_pred == y_test)\n",
    "    print(f\"Logistic Regression Accuracy: {lr_accuracy}\")\n",
    "\n",
    "    resnet_y_pred = resnet_model(X_test).detach().argmax(dim=1).numpy()\n",
    "    resnet_accuracy = np.mean(resnet_y_pred == y_test)\n",
    "    print(f\"ResNet Accuracy: {resnet_accuracy}\")\n",
    "\n",
    "    torch.save(lr_model.state_dict(), f\"{path}/lr_model.pth\")\n",
    "    torch.save(resnet_model.state_dict(), f\"{path}/resnet_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pnpenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
