{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a147685",
   "metadata": {},
   "source": [
    "# Captum에서 XAI benchmark를 계산하는 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cedfea58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os; os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23a6c16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cwl/miniconda3/envs/pnpenv/lib/python3.10/site-packages/xgboost/core.py:377: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc >= 2.28) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/home/cwl/.local/lib/python3.10/site-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator StandardScaler from version 1.1.3 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[xgb] calculating lime …\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 419/1300 [10:32<20:15,  1.38s/it]"
     ]
    }
   ],
   "source": [
    "# xai_benchmark_captum.py\n",
    "import argparse, pickle, random, yaml, logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch, torch.nn as nn\n",
    "import xgboost as xgb\n",
    "from tqdm import tqdm\n",
    "from captum.attr import (\n",
    "    KernelShap, Lime, IntegratedGradients, Saliency, InputXGradient, NoiseTunnel, LRP\n",
    ")\n",
    "from captum.attr._utils.lrp_rules import EpsilonRule\n",
    "# ---------------- utils ----------------\n",
    "\n",
    "# class TorchModelForXGBoost(nn.Module):\n",
    "#     \"\"\"Captum-friendly wrapper around XGBoost predict_proba.\"\"\"\n",
    "#     def __init__(self, xgb_model):\n",
    "#         super().__init__()\n",
    "#         self.xgb_model = xgb_model\n",
    "#         self._dummy = nn.Linear(1, 1)  # Dummy layer for device handling\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         if x.ndim == 3:\n",
    "#             x = x.squeeze(0)\n",
    "#         x_np = x.detach().cpu().numpy()\n",
    "#         out = self.xgb_model.predict_proba(x_np)\n",
    "#         out_tensor = torch.from_numpy(out).to(x.device)  # (N, 2)\n",
    "#         return out_tensor[:, 1]  # (N,)\n",
    "    \n",
    "class TorchModelForXGBoost(nn.Module):\n",
    "    def __init__(self, xgb_model):\n",
    "        super().__init__()\n",
    "        self.xgb_model = xgb_model\n",
    "        self._dummy_layer = nn.Linear(1, 1)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        if x.ndim >= 3:\n",
    "            x = x.squeeze(0)\n",
    "        out = self.xgb_model.predict_proba(x.cpu().numpy())\n",
    "        return torch.from_numpy(out)\n",
    "\n",
    "\n",
    "def load_data(dataset_nm):\n",
    "    X_train = np.load(f\"data/{dataset_nm}/X_train.npy\")\n",
    "    y_train = np.load(f\"data/{dataset_nm}/y_train.npy\")\n",
    "    X_test  = np.load(f\"data/{dataset_nm}/X_test.npy\")\n",
    "    y_test  = np.load(f\"data/{dataset_nm}/y_test.npy\")\n",
    "    feature_metadata = pickle.load(open(f\"data/{dataset_nm}/feature_metadata.pkl\",\"rb\"))\n",
    "    return X_train, y_train, X_test, y_test, feature_metadata\n",
    "\n",
    "# --------------- main ------------------\n",
    "dataset_nm=\"Wine Quality\"\n",
    "seed=42\n",
    "random.seed(seed); np.random.seed(seed); torch.manual_seed(seed)\n",
    "os.makedirs(\"results\", exist_ok=True)\n",
    "\n",
    "# 1. load data\n",
    "X_tr, y_tr, X_te, y_te, _ = load_data(dataset_nm)\n",
    "X_te_t = torch.tensor(X_te, dtype=torch.float32)\n",
    "\n",
    "# 2. load models\n",
    "models_cfg = {\n",
    "    \"xgb\": {\n",
    "        \"model\": TorchModelForXGBoost(xgb.XGBClassifier()),\n",
    "        \"attr\": [\"lime\", \"kernelshap\"]\n",
    "        # \"attr\": [\"kernelshap\",\"lime\"]\n",
    "    },\n",
    "    \"tab_resnet\": {\n",
    "        \"model\": None,   # load below\n",
    "        \"attr\": [\"gradient\",\"gradxinput\",\"ig\",\"smoothgrad\",\"lrp\"]\n",
    "    },\n",
    "}\n",
    "# XGB load\n",
    "xgb_raw = xgb.XGBClassifier()\n",
    "xgb_raw.load_model(f\"data/{dataset_nm}/xgb_model.json\")\n",
    "models_cfg[\"xgb\"][\"model\"].xgb_model = xgb_raw\n",
    "\n",
    "# TabResNet load\n",
    "from models.tab_resnet import TabResNet\n",
    "resnet = TabResNet(X_tr.shape[1], 2, num_blocks=1)\n",
    "resnet.load_state_dict(torch.load(f\"data/{dataset_nm}/resnet_model.pth\"))\n",
    "resnet.eval()\n",
    "models_cfg[\"tab_resnet\"][\"model\"] = resnet\n",
    "\n",
    "# 3. explainer factory\n",
    "def make_explainer(tag, model):\n",
    "    if tag==\"kernelshap\": return KernelShap(model)\n",
    "    if tag==\"lime\":       return Lime(model, interpretable_model=None)\n",
    "    if tag==\"gradient\":   return Saliency(model)\n",
    "    if tag==\"gradxinput\": return InputXGradient(model)\n",
    "    if tag==\"ig\":         return IntegratedGradients(model, multiply_by_inputs=True)\n",
    "    if tag==\"smoothgrad\": return NoiseTunnel(Saliency(model))          # default stdev, nt_type='smoothgrad'\n",
    "    if tag==\"lrp\":        \n",
    "        model.res_blocks[0].bn.rule = EpsilonRule()\n",
    "        model.bn.rule = EpsilonRule()\n",
    "        return LRP(model)                       # for simple feed-forward nets\n",
    "        # return LayerLRP(model, layer=model.embedding)                       # for simple feed-forward nets\n",
    "    raise ValueError(tag)\n",
    "\n",
    "# 4. loop over models / explainers\n",
    "results = {}\n",
    "for model_key, cfg in models_cfg.items():\n",
    "    mdl = cfg[\"model\"]\n",
    "    mdl.to(\"cpu\")\n",
    "    results[model_key] = {}\n",
    "    for tag in cfg[\"attr\"]:\n",
    "        print(f\"[{model_key}] calculating {tag} …\")\n",
    "        explainer = make_explainer(tag, mdl)\n",
    "        target = mdl(X_te_t).argmax(dim=1)\n",
    "        # target = mdl(X_te_t).argmax(dim=1)  if model_key==\"tab_resnet\" else mdl(X_te_t) > 0.5\n",
    "        if tag==\"ig\":     \n",
    "            attrs = explainer.attribute(X_te_t, target=target, n_steps=50).detach().numpy()\n",
    "        elif tag==\"smoothgrad\":\n",
    "            attrs = explainer.attribute(X_te_t, target=target, nt_samples=50, nt_type='smoothgrad').detach().numpy()\n",
    "        elif tag in (\"kernelshap\",\"lime\"):\n",
    "            attrs_list = []\n",
    "            for i in tqdm(range(len(X_te_t))):\n",
    "                baseline = torch.tensor(X_tr[np.random.choice(len(X_tr), 1)], dtype=torch.float32)  # (1, feature_dim)\n",
    "                input_i = X_te_t[i].unsqueeze(0)  # (1, feature_dim)\n",
    "                attr_i = explainer.attribute(input_i, target=target[i], baselines=baseline)\n",
    "                attrs_list.append(attr_i.detach().cpu().numpy())\n",
    "\n",
    "            attrs = np.concatenate(attrs_list, axis=0)  # (batch_size, feature_dim)\n",
    "\n",
    "        else:             \n",
    "            attrs = explainer.attribute(X_te_t, target=target).detach().numpy()\n",
    "\n",
    "        results[model_key][tag] = attrs\n",
    "        # 저장 npy (필요하면 변경)\n",
    "        np.save(f\"results/{dataset_nm.replace(' ','_')}_{model_key}_{tag}.npy\", attrs)\n",
    "\n",
    "# 5. 요약 yaml (구조만 기록)\n",
    "yaml.safe_dump(\n",
    "    {k:list(v.keys()) for k,v in results.items()},\n",
    "    open(f\"results/summary_{dataset_nm.replace(' ','_')}.yml\",\"w\")\n",
    ")\n",
    "print(\"Done!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a48a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cddb45d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-29 09:10:59.835773: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-29 09:10:59.857606: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1745885459.892123 3272799 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1745885459.900882 3272799 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-29 09:10:59.927896: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from sklearn.cluster import KMeans as SklearnKMeans\n",
    "\n",
    "from pnpxai import Experiment, AutoExplanation\n",
    "from pnpxai.core.modality.modality import Modality\n",
    "from pnpxai.explainers import KernelShap\n",
    "from pnpxai.evaluator.metrics import AbPC, Metric, Complexity, Sensitivity\n",
    "from pnpxai.explainers.utils.baselines import BaselineFunction\n",
    "from pnpxai.explainers.base import Tunable\n",
    "from pnpxai.explainers.types import TunableParameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d2f35e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[xgb] calculating lime abpc …\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for tensor of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 134\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m model_key \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxgb\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    132\u001b[0m         targets \u001b[38;5;241m=\u001b[39m targets\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m--> 134\u001b[0m     evals \u001b[38;5;241m=\u001b[39m \u001b[43mmetric\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_explainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdummy_exp\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    137\u001b[0m     res\u001b[38;5;241m.\u001b[39mappend(evals\u001b[38;5;241m.\u001b[39mitem())\n\u001b[1;32m    138\u001b[0m res \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(res)\n",
      "File \u001b[0;32m~/repo/pnpxai/pnpxai/evaluator/metrics/pixel_flipping.py:418\u001b[0m, in \u001b[0;36mAbPC.evaluate\u001b[0;34m(self, inputs, targets, attributions, attention_mask, return_pf)\u001b[0m\n\u001b[1;32m    403\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    404\u001b[0m \u001b[38;5;124;03mEvaluate the explainer's correctness using the AbPC technique by observing changes in model predictions.\u001b[39;00m\n\u001b[1;32m    405\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[38;5;124;03m        indicating the impact of perturbing the most and least relevant features.\u001b[39;00m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;66;03m# pf by ascending order: lerf\u001b[39;00m\n\u001b[0;32m--> 418\u001b[0m pf_ascs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    419\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattributions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    420\u001b[0m pf_ascs \u001b[38;5;241m=\u001b[39m format_into_tuple(pf_ascs)\n\u001b[1;32m    422\u001b[0m \u001b[38;5;66;03m# pf by descending order: morf\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/pnpenv/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/repo/pnpxai/pnpxai/evaluator/metrics/pixel_flipping.py:136\u001b[0m, in \u001b[0;36mPixelFlipping.evaluate\u001b[0;34m(self, inputs, targets, attributions, attention_mask, descending)\u001b[0m\n\u001b[1;32m    130\u001b[0m n_flipped_per_step \u001b[38;5;241m=\u001b[39m n_flipped_per_step\u001b[38;5;241m.\u001b[39mclamp(\u001b[38;5;28mmin\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    131\u001b[0m sorted_indices \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margsort(\n\u001b[1;32m    132\u001b[0m     attrs,\n\u001b[1;32m    133\u001b[0m     descending\u001b[38;5;241m=\u001b[39mdescending,\n\u001b[1;32m    134\u001b[0m     stable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    135\u001b[0m )\n\u001b[0;32m--> 136\u001b[0m probs \u001b[38;5;241m=\u001b[39m [\u001b[43m_extract_target_probs\u001b[49m\u001b[43m(\u001b[49m\u001b[43minit_probs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[1;32m    137\u001b[0m preds \u001b[38;5;241m=\u001b[39m [init_preds]\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_steps):\n",
      "File \u001b[0;32m~/repo/pnpxai/pnpxai/evaluator/metrics/pixel_flipping.py:441\u001b[0m, in \u001b[0;36m_extract_target_probs\u001b[0;34m(probs, targets)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_extract_target_probs\u001b[39m(probs, targets):\n\u001b[1;32m    440\u001b[0m     \u001b[38;5;66;03m# please ensure probs.size() == (batch_size, n_classes)\u001b[39;00m\n\u001b[0;32m--> 441\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mprobs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprobs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for tensor of dimension 1"
     ]
    }
   ],
   "source": [
    "total_res = []\n",
    "test_input = torch.tensor(X_te, dtype=torch.float32).unsqueeze(1)\n",
    "test_loader = DataLoader(\n",
    "    test_input,\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "sample_batch = next(iter(test_loader))\n",
    "modality = Modality(\n",
    "    dtype=sample_batch[0].dtype,\n",
    "    ndims=2,\n",
    "    pooling_dim=1\n",
    ")\n",
    "\n",
    "class CompoundMetric(Metric):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        cmpd_metrics,\n",
    "        weights, \n",
    "        explainer=None,\n",
    "        target_input_keys=None,\n",
    "        additional_input_keys=None,\n",
    "        output_modifier=None,\n",
    "    ):\n",
    "        super().__init__(\n",
    "            model, explainer, target_input_keys,\n",
    "            additional_input_keys, output_modifier,\n",
    "        )\n",
    "        assert len(cmpd_metrics) == len(weights)\n",
    "        self.cmpd_metrics = cmpd_metrics\n",
    "        self.weights = weights\n",
    "\n",
    "    def evaluate(self, inputs, targets, attrs):\n",
    "        values = torch.zeros(attrs.size(0)).to(attrs.device)\n",
    "        for weight, metric in zip(self.weights, self.cmpd_metrics):\n",
    "            values += weight * metric.set_explainer(self.explainer).evaluate(inputs, targets, attrs)\n",
    "        return values\n",
    "    \n",
    "for model_key, cfg in models_cfg.items():\n",
    "    model = cfg[\"model\"]\n",
    "    if model_key == \"tab_resnet\":\n",
    "        expr = AutoExplanation(\n",
    "            model=model,\n",
    "            data=test_loader,\n",
    "            modality=modality,\n",
    "            target_input_keys=[0], # Current test_loader batches data as tuple of (inputs, targets). 0 means the location of inputs in the tuple\n",
    "            target_class_extractor=lambda outputs: outputs.argmax(-1),\n",
    "            label_key='labels',\n",
    "            target_labels=False, # Gets attributions on the prediction for all explainer if False.\n",
    "        )\n",
    "    elif model_key == \"xgb\":\n",
    "        class KMeans(BaselineFunction, Tunable):\n",
    "            def __init__(self, background_data, n_clusters=8):\n",
    "                self.background_data = background_data\n",
    "                self.n_clusters = TunableParameter(\n",
    "                    name='n_clusters',\n",
    "                    current_value=n_clusters,\n",
    "                    dtype=int,\n",
    "                    is_leaf=True,\n",
    "                    space={'low': 8, 'high': len(background_data)//10, 'step': 10},\n",
    "                )\n",
    "                self.kmeans_ = SklearnKMeans(n_clusters).fit(background_data)\n",
    "                BaselineFunction.__init__(self)\n",
    "                Tunable.__init__(self)\n",
    "                self.register_tunable_params([self.n_clusters])\n",
    "\n",
    "            def __call__(self, inputs):\n",
    "                if inputs.ndim == 3:\n",
    "                    inputs = inputs.squeeze(1)\n",
    "                cluster_ids = self.kmeans_.predict(inputs.to(torch.float64).numpy())\n",
    "                cluster_centers = self.kmeans_.cluster_centers_[cluster_ids]\n",
    "                return torch.from_numpy(cluster_centers).to(inputs.device)\n",
    "            \n",
    "        expr = Experiment(\n",
    "            model=model,\n",
    "            data=test_loader,\n",
    "            modality=modality,\n",
    "            target_input_keys=[0],  # feature location in batch from dataloader\n",
    "            target_class_extractor=lambda outputs: outputs.argmax(-1),  # extract target class from output batch\n",
    "            label_key=-1,  # label location in input batch from dataloader\n",
    "        )\n",
    "\n",
    "        # add metrics\n",
    "        expr.metrics.add('abpc', AbPC)\n",
    "\n",
    "        # add explainers\n",
    "        expr.explainers.add('kernel_shap', KernelShap)\n",
    "\n",
    "        # remove unused baseline functions\n",
    "        expr.modality.util_functions['baseline_fn'].delete('zeros')\n",
    "        expr.modality.util_functions['baseline_fn'].delete('mean')\n",
    "\n",
    "        # add new baseline functions\n",
    "        expr.modality.util_functions['baseline_fn'].add('kmeans', KMeans)\n",
    "        expr.modality.util_functions['baseline_fn'].add_default_kwargs(\n",
    "            'background_data', X_te)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid model\")\n",
    "\n",
    "    expr.metrics.add('cmpx', Complexity)\n",
    "    expr.metrics.add('cmpd', CompoundMetric)\n",
    "\n",
    "    for tag in cfg[\"attr\"]:\n",
    "        for metric in ['abpc', 'cmpx', 'cmpd']:\n",
    "            print(f\"[{model_key}] calculating {tag} {metric} …\")\n",
    "            metric_options = {}\n",
    "            if metric == \"cmpd\":\n",
    "                metric_options = {\n",
    "                    'cmpd_metrics': [expr.create_metric('abpc'), expr.create_metric('cmpx')],\n",
    "                    'weights': [.8, -.2]\n",
    "                }\n",
    "\n",
    "            explanation = np.load(f\"results/{dataset_nm.replace(' ','_')}_{model_key}_{tag}.npy\")\n",
    "            explanation = torch.tensor(explanation, dtype=torch.float32)\n",
    "            metric = expr.create_metric(metric_key=metric, **metric_options)\n",
    "            dummy_exp = expr.create_explainer(explainer_key=\"kernel_shap\")\n",
    "\n",
    "            res = []\n",
    "            for i in range(explanation.shape[0]):\n",
    "                inputs = {0: test_input[i].unsqueeze(0)}\n",
    "                targets = model(test_input[i]).argmax(-1)\n",
    "                exp = explanation[i].unsqueeze(0)\n",
    "\n",
    "                # if torch.all(exp == 0):\n",
    "                #     exp = torch.rand_like(explanation) * 1e-8\n",
    "                # if model_key == \"xgb\":\n",
    "                #     targets = targets.unsqueeze(0)\n",
    "                    \n",
    "                evals = metric.set_explainer(dummy_exp).evaluate(\n",
    "                    inputs, targets, exp,\n",
    "                )\n",
    "                res.append(evals.item())\n",
    "            res = np.array(res)\n",
    "            total_res.append({\n",
    "                \"model\": model_key,\n",
    "                \"tag\": tag,\n",
    "                \"metric\": metric,\n",
    "                \"res\": res\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21cad014",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856811a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd79de87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a5331a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755d24cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pnpenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
